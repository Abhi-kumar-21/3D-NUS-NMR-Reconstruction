{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhi-kumar-21/3D-NUS-NMR-Reconstruction/blob/main/Dense_U_Net_3D_NUS_NMR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39GH7nr55DBa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "from time import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from sklearn import preprocessing\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Conv3D, MaxPooling3D\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "#Parallelization library\n",
        "from multiprocessing import Pool, Manager, Process\n",
        "import threading\n",
        "\n",
        "from warnings import filterwarnings\n",
        "filterwarnings(action='ignore', category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Y0EXkT_RRLh"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgiznRkb5Z2w",
        "outputId": "26f9352a-b9a2-4139-ed94-e728122a4b13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = pd.read_excel('/content/drive/My Drive/Scheduler.xlsx')\n",
        "\n",
        "arr = df.to_numpy().astype('int')\n",
        "\n",
        "mul_arr = np.zeros((128,32),'float')\n",
        "for d in arr:\n",
        "  mul_arr[d[0],d[1]] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcasTPVn5ir3"
      },
      "outputs": [],
      "source": [
        "mul_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4blF8c7A5qsr"
      },
      "outputs": [],
      "source": [
        "def make_fid(freqs, freqs1, freqs2, r2s, ints, noise=False):\n",
        "    \n",
        "  retval=np.zeros( (NP, NP1, NP2) , dtype=np.complex)\n",
        "  \n",
        "  # Time samples\n",
        "  samp_time = np.linspace(0.,(NP-1.)/SW,NP)\n",
        "  samp_time1 = np.linspace(0.,(NP1-1.)/SW1,NP1)\n",
        "  samp_time2 = np.linspace(0.,(NP2-1.)/SW2,NP2)\n",
        "  \n",
        "  K = np.max([len(freqs), len(freqs2), len(freqs2), len(r2s), len(ints)])\n",
        "  for n in range(NP):\n",
        "    for n1 in range(NP1):\n",
        "      for n2 in range(NP2):\n",
        "        val = 0.\n",
        "        for s in range(K):\n",
        "          val+= (np.exp((1j*2*np.pi*freqs[s] - r2s[s])*samp_time[n])*\n",
        "                  np.exp((1j*2*np.pi*freqs1[s] - r2s[s])*samp_time1[n1])*\n",
        "                  np.exp((1j*2*np.pi*freqs2[s] - r2s[s])*samp_time2[n2])*\n",
        "                  ints[s])\n",
        "        retval[n,n1,n2]=val\n",
        "\n",
        "  return retval\n",
        "\n",
        "\n",
        "def make_sine_combinations():\n",
        "\n",
        "  # Number of Signals\n",
        "  nSignals = random.randint(50,NSignals+1)  \n",
        "  # print(nSignals)\n",
        "\n",
        "  # Frequencies\n",
        "  freqs = np.random.random(nSignals)*SW\n",
        "  freqs1 = np.random.random(nSignals)*SW1\n",
        "  freqs2 = np.random.random(nSignals)*SW2\n",
        "\n",
        "  # Transverse relaxation rate\n",
        "  r2s = np.random.random(nSignals)*(5) + (1/100)\n",
        "\n",
        "  #Intensity = amplitude\n",
        "  ints = np.random.random(nSignals)*600000 + 100000\n",
        "\n",
        "  # FID creation\n",
        "  ff = make_fid(freqs,freqs1,freqs2,r2s,ints,NoiseLevel)\n",
        "\n",
        "  temp_realPart = np.real(ff)\n",
        "  temp = np.abs(temp_realPart[0,0,0])\n",
        "  ff = ff/temp\n",
        "\n",
        "  return ff\n",
        "\n",
        "\n",
        "def make_2d_mat(b_size):\n",
        "    \n",
        "  # Training matrix\n",
        "  target = np.zeros([b_size*NP, NP1*NP2], dtype=np.float)       # For Target\n",
        "  train = np.zeros([b_size*NP, NP1, NP2], dtype=np.float)      # For CNN\n",
        "  train1 = np.zeros([b_size*NP, NP1, NP2], dtype=np.float)     # For test_fft\n",
        "  train_1 = np.zeros([b_size*NP, NP1*NP2], dtype=np.float)      # For DNN\n",
        "\n",
        "  # Matix concatenation (training)\n",
        "  for i in range(b_size):\n",
        "    ff = make_sine_combinations()\n",
        "    train_ff = ff\n",
        "\n",
        "    ff = np.fft.fft(ff,axis=0)\n",
        "    ff = np.fft.fft(ff,axis=1)\n",
        "    ff = np.fft.fft(ff,axis=2)\n",
        "\n",
        "    ff = ff/np.max(np.abs(ff))\n",
        "\n",
        "    train1[i*NP:(i+1)*NP,:,:] = np.real(ff)\n",
        "    # train1[i*NP:(i+1)*NP,1,:,:] = np.imag(ff)\n",
        "\n",
        "    for j in range(NP):\n",
        "      train_ff[j,:,:] = np.multiply(train_ff[j,:,:],mul_arr)\n",
        "      # index = (i*(j+1))+j\n",
        "      index = (i*NP)+j\n",
        "      # till_index = NP1*NP2\n",
        "      target[index,:] = np.real(ff[j]).reshape(NP1*NP2)\n",
        "      # target[index,till_index:2*till_index] = np.imag(ff[j]).reshape(NP1*NP2)\n",
        "    \n",
        "    train_ff = np.fft.fft(train_ff,axis=0)\n",
        "    train_ff = np.fft.fft(train_ff,axis=1)\n",
        "    train_ff = np.fft.fft(train_ff,axis=2)\n",
        "\n",
        "    train_ff = train_ff/np.max(np.abs(train_ff))\n",
        "\n",
        "    train[i*NP:(i+1)*NP,:,:] = np.real(train_ff)\n",
        "    # train[i*NP:(i+1)*NP,1,:,:] = np.imag(train_ff)\n",
        "    \n",
        "    for j in range(NP):\n",
        "      index = (i*NP)+j\n",
        "      # till_index = NP1*NP2\n",
        "      train_1[index,:] = np.real(train_ff[j]).reshape(NP1*NP2)\n",
        "      # train_1[index,till_index:2*till_index] = np.imag(train_ff[j]).reshape(NP1*NP2)\n",
        "\n",
        "  return train, train1, target\n",
        "\n",
        "N = 5000\n",
        "NP = 2        # Direct dimension\n",
        "NP1 = 128     # Indirect Dimension 1\n",
        "NP2 = 32      # Indirect Dimension 1\n",
        "SW = 1000\n",
        "SW1 = 10000\n",
        "SW2 = 4000\n",
        "NoiseLevel = 0\n",
        "NSignals = 200\n",
        "dataIn = []\n",
        "dataOut = []\n",
        "epochs = 12\n",
        "batch_size = 32\n",
        "val_split = 0.05\n",
        "\n",
        "\n",
        "\n",
        "# train_r, train_i = make_sine_combinations()\n",
        "# train, train_test, train_1, target = make_2d_mat(1)\n",
        "# print(train.shape, target.shape, train_1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrpwk99L5xzI"
      },
      "outputs": [],
      "source": [
        "\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Conv2D, Conv3D, DepthwiseConv2D, SeparableConv2D, Conv3DTranspose\n",
        "from keras.layers import Flatten, MaxPool2D, AvgPool2D, GlobalAvgPool2D, UpSampling2D, BatchNormalization, GlobalMaxPool2D\n",
        "from keras.layers import Concatenate, Add, Dropout, ReLU, Lambda, Activation, LeakyReLU, PReLU \n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "from time import time\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJ1ND-pdt5zh"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "\n",
        "# Dense U-Net Network Architecture\n",
        "\n",
        "\n",
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = tf.keras.activations.tanh(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = tf.keras.activations.tanh(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def encoder_block(input, num_filters):\n",
        "    x = conv_block(input, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_unet(input_shape):\n",
        "    # inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(input_shape, 16)\n",
        "    s2, p2 = encoder_block(p1, 32)\n",
        "\n",
        "    b1 = conv_block(p2, 64)\n",
        "\n",
        "    d3 = decoder_block(b1, s2, 32)\n",
        "    d4 = decoder_block(d3, s1, 16)\n",
        "\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"tanh\")(d4)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def densenet(img_shape, f=32):\n",
        "  repetitions = 6, 12, 24,\n",
        "  \n",
        "  def bn_rl_conv(x, f, k=1, s=1, p='same'):\n",
        "    # x = BatchNormalization()(x)\n",
        "    x = tf.keras.activations.tanh(x)\n",
        "    # x = LeakyReLU()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    # x = Conv2D(f, k, strides=s, padding=p)(x)\n",
        "    x = build_unet(x)\n",
        "\n",
        "    return x\n",
        "  \n",
        "  \n",
        "  def dense_block(tensor, r):\n",
        "    for _ in range(r):\n",
        "      x = bn_rl_conv(tensor, 4*f)\n",
        "      # x = model = build_unet(input_shape)\n",
        "      x = bn_rl_conv(x, f, 3)\n",
        "      tensor = Concatenate()([tensor, x])\n",
        "    return tensor\n",
        "  \n",
        "  \n",
        "  def transition_block(x):\n",
        "    x = bn_rl_conv(x, K.int_shape(x)[-1] // 2)\n",
        "    x = AvgPool2D(2, strides=1, padding='same')(x)\n",
        "    return x\n",
        "  \n",
        "  \n",
        "  input = Input(img_shape)\n",
        "  \n",
        "  x = Conv2D(64, 3, strides=1, padding='same')(input)\n",
        "  x = MaxPool2D(3, strides=1, padding='same')(x)\n",
        "  \n",
        "  for r in repetitions:\n",
        "    d = dense_block(x, r)\n",
        "    x = transition_block(d)\n",
        "\n",
        "  \n",
        "  output = Conv2D(1, 1, activation='tanh')(d)\n",
        "  \n",
        "  model = Model(input, output)\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "input_shape = (128, 32, 1)\n",
        "n_classes = 4096\n",
        "\n",
        "K.clear_session()\n",
        "model = densenet(input_shape)\n",
        "model.summary()\n",
        "\n",
        "#===============================================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNUGOLiyE3Jg"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils.vis_utils import plot_model\n",
        "# model = Sequential()\n",
        "# model.add(Dense(2, input_dim=1, activation='relu'))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvL3ZMc0Rpkw"
      },
      "outputs": [],
      "source": [
        "\n",
        "# def densenet(img_shape, n_classes, f=32):\n",
        "#   repetitions = 6, 12, 24, 16\n",
        "  \n",
        "#   def bn_rl_conv(x, f, k=1, s=1, p='same'):\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = tf.keras.activations.tanh(x)\n",
        "#     # x = ReLU()(x)\n",
        "#     x = Conv2D(f, k, strides=s, padding=p)(x)\n",
        "#     return x\n",
        "  \n",
        "  \n",
        "#   def dense_block(tensor, r):\n",
        "#     for _ in range(r):\n",
        "#       x = bn_rl_conv(tensor, 4*f)\n",
        "#       x = bn_rl_conv(x, f, 3)\n",
        "#       tensor = Concatenate()([tensor, x])\n",
        "#     return tensor\n",
        "  \n",
        "  \n",
        "#   def transition_block(x):\n",
        "#     x = bn_rl_conv(x, K.int_shape(x)[-1] // 2)\n",
        "#     x = AvgPool2D(2, strides=1, padding='same')(x)\n",
        "#     return x\n",
        "  \n",
        "  \n",
        "#   input = Input(img_shape)\n",
        "  \n",
        "#   x = Conv2D(64, 3, strides=1, padding='same')(input)\n",
        "#   x = MaxPool2D(3, strides=1, padding='same')(x)\n",
        "  \n",
        "#   for r in repetitions:\n",
        "#     d = dense_block(x, r)\n",
        "#     x = transition_block(d)\n",
        "  \n",
        "#   # # x = GlobalAvgPool2D()(d)\n",
        "  \n",
        "#   # \"\"\" Output \"\"\"\n",
        "#   # outputs = Conv2D(1, 1, padding=\"same\", activation=\"tanh\")(x)\n",
        "\n",
        "#   # model = Model(input, outputs, name=\"Dense-Net\")\n",
        "#   # return model\n",
        "# # def densenet(img_shape, n_classes, f=32):\n",
        "# #   repetitions = 6, 12, 24, 16\n",
        "  \n",
        "# #   def bn_rl_conv(x, f, k=1, p='same'):\n",
        "# #     x = BatchNormalization()(x)\n",
        "# #     x = tf.keras.activations.tanh(x)\n",
        "# #     # x = ReLU()(x)\n",
        "# #     x = Conv2D(f, k, padding=p)(x)\n",
        "# #     return x\n",
        "  \n",
        "  \n",
        "# #   def dense_block(tensor, r):\n",
        "# #     for _ in range(r):\n",
        "# #       x = bn_rl_conv(tensor, 4*f)\n",
        "# #       x = bn_rl_conv(x, f, 3)\n",
        "# #       tensor = Concatenate()([tensor, x])\n",
        "# #     return tensor\n",
        "  \n",
        "  \n",
        "# #   def transition_block(x):\n",
        "# #     x = bn_rl_conv(x, K.int_shape(x)[-1])\n",
        "# #     x = AvgPool2D(2, strides = 1, padding='same')(x)\n",
        "# #     return x\n",
        "  \n",
        "  \n",
        "# #   input = Input(img_shape)\n",
        "  \n",
        "# #   x = Conv2D(64, 5 , padding='same')(input)\n",
        "# #   x = MaxPool2D(2, strides = 1, padding='same')(x)\n",
        "  \n",
        "# #   for r in repetitions:\n",
        "# #     d = dense_block(x, r)\n",
        "# #     x = transition_block(d)\n",
        "  \n",
        "#   # x = GlobalAvgPool2D()(d)\n",
        "#   # x = Flatten()(d)\n",
        "  \n",
        "#   output = Conv2D(1, 1, activation='tanh')(d)\n",
        "  \n",
        "#   model = Model(input, output)\n",
        "#   return model\n",
        "# #   \"\"\" Output \"\"\"\n",
        "# #   outputs = Conv2D(1, 1, padding=\"same\", activation=\"tanh\")(x)\n",
        "\n",
        "# #   model = Model(input, outputs, name=\"Dense-Net\")\n",
        "# #   return model\n",
        "\n",
        "\n",
        "\n",
        "# input_shape = 128, 64, 1\n",
        "# n_classes = 4096\n",
        "\n",
        "# K.clear_session()\n",
        "# model = densenet(input_shape, n_classes)\n",
        "# model.summary()\n",
        "\n",
        "# Compile the model\n",
        "def get_lr_metric(optimizer):\n",
        "    def lr(y_true, y_pred):\n",
        "        return optimizer.lr\n",
        "    return lr\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
        "lr_metric = get_lr_metric(optimizer)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"loss\",\n",
        "                              factor=0.8,\n",
        "                              patience=9,\n",
        "                              min_lr=0.0001\n",
        ")\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3VcrGaNRpfy"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZMkS5r95008"
      },
      "outputs": [],
      "source": [
        "# # def densenet(img_shape, n_classes, f=32):\n",
        "# #   repetitions = 6, 12, 24\n",
        "  \n",
        "# #   def bn_rl_conv(x, f, k=1, s=1, p='same'):\n",
        "# #     x = BatchNormalization()(x)\n",
        "# #     x = tf.keras.activations.tanh(x)\n",
        "# #     # x = ReLU()(x)\n",
        "# #     x = Conv2D(f, k, strides=s, padding=p)(x)\n",
        "# #     return x\n",
        "  \n",
        "  \n",
        "# #   def dense_block(tensor, r):\n",
        "# #     for _ in range(r):\n",
        "# #       x = bn_rl_conv(tensor, 4*f)\n",
        "# #       x = bn_rl_conv(x, f, 3)\n",
        "# #       tensor = Concatenate()([tensor, x])\n",
        "# #     return tensor\n",
        "  \n",
        "  \n",
        "# #   def transition_block(x):\n",
        "# #     x = bn_rl_conv(x, K.int_shape(x)[-1] // 2)\n",
        "# #     x = AvgPool2D(2, strides=2, padding='same')(x)\n",
        "# #     return x\n",
        "  \n",
        "  \n",
        "# #   input = Input(img_shape)\n",
        "  \n",
        "# #   x = Conv2D(64, 3, strides=1, padding='same')(input)\n",
        "# #   x = MaxPool2D(3, strides=1, padding='same')(x)\n",
        "  \n",
        "# #   for r in repetitions:\n",
        "# #     d = dense_block(x, r)\n",
        "# #     x = transition_block(d)\n",
        "  \n",
        "# #   x = GlobalMaxPool2D()(d)\n",
        "  \n",
        "# #   output = Dense(n_classes, activation='softmax')(x)\n",
        "  \n",
        "# #   model = Model(input, output)\n",
        "# #   return model\n",
        "\n",
        "# def unet(input_shape=(572, 572, 1), f=64, steps=3, n_classes=2):\n",
        "  \n",
        "#   def downstream(x, f):\n",
        "#     x = Conv2D(f, 3, activation='relu')(x)\n",
        "#     d = Conv2D(f, 3, activation='relu')(x)\n",
        "#     x = MaxPool2D(2, strides=1, padding='same')(d)\n",
        "#     return d, x\n",
        "  \n",
        "  \n",
        "#   def crop_merge(x, d):\n",
        "#     _, xw, xh, _ = K.int_shape(x)\n",
        "#     _, dw, dh, _ = K.int_shape(d)\n",
        "#     mw, mh = (dw-xw)//2, (dh-xh)//2\n",
        "    \n",
        "#     d = Lambda(lambda x: x[:, mw: dw-mw, mh: dh-mh, :])(d)\n",
        "#     x = Concatenate()([d, x])\n",
        "#     return x\n",
        "    \n",
        "  \n",
        "#   def upstream(x, f, d):\n",
        "#     x = UpSampling2D()(x)\n",
        "#     x = Conv2D(f, 2, padding='same')(x)\n",
        "#     x = crop_merge(x, d)\n",
        "#     x = Conv2D(f, 3, activation='relu')(x)\n",
        "#     x = Conv2D(f, 3, activation='relu')(x)\n",
        "#     return x\n",
        "    \n",
        "  \n",
        "#   input = Input(input_shape)\n",
        "#   x = input\n",
        "  \n",
        "#   downsampled = []\n",
        "#   for i in range(steps+1):\n",
        "#     d, x = downstream(x, f*2**i)\n",
        "#     downsampled.append(d)\n",
        "#   x = downsampled.pop()\n",
        "  \n",
        "#   for i in range(steps-1, -1, -1):\n",
        "#     x = upstream(x, f*2**i, downsampled[i])\n",
        "  \n",
        "#   output = Conv2D(n_classes, 1)(x)\n",
        "#   model = Model(input, output)\n",
        "  \n",
        "#   return model\n",
        "\n",
        "\n",
        "# input_shape = 572, 572, 1\n",
        "# n_classes = 4096\n",
        "\n",
        "# K.clear_session()\n",
        "# # model = densenet(input_shape, n_classes)\n",
        "# model = unet(input_shape, f=64, steps=4, n_classes=2)\n",
        "# model.summary()\n",
        "\n",
        "# # Compile the model\n",
        "# def get_lr_metric(optimizer):\n",
        "#     def lr(y_true, y_pred):\n",
        "#         return optimizer.lr\n",
        "#     return lr\n",
        "\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
        "# lr_metric = get_lr_metric(optimizer)\n",
        "\n",
        "# reduce_lr = ReduceLROnPlateau(monitor=\"loss\",\n",
        "#                               factor=0.8,\n",
        "#                               patience=9,\n",
        "#                               min_lr=0.0001\n",
        "# )\n",
        "# model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7QTB-Au6hzz"
      },
      "outputs": [],
      "source": [
        "def dothing(x1_train, fids, fids_flat, i):\n",
        "    x1, fids_1, fids_2 = make_2d_mat(16)\n",
        "    print(\"yolo\")\n",
        "    # print(x1[0,:,:,:], fids_2[0,:])\n",
        "    # print(x1.shape, fids_1.shape)\n",
        "    fids.append(fids_1)\n",
        "    x1_train.append(x1)\n",
        "    fids_flat.append(fids_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rey-wWOxhc2b"
      },
      "outputs": [],
      "source": [
        "num_threads = 16\n",
        "\n",
        "for n_datasets in range(100):\n",
        "    # print(n_datasets)\n",
        "    with Manager() as manager:\n",
        "        # L = manager.list()  # <-- can be shared between processes.\n",
        "        x1_train = manager.list()\n",
        "        fids = manager.list()\n",
        "        fids_flat = manager.list()\n",
        "        processes = []\n",
        "        for i in range(num_threads):\n",
        "            p = Process(target=dothing, args=(x1_train, fids, fids_flat, i))  # Passing the list\n",
        "            # p = threading.Thread(target=dothing, args=(x1_train, fids, fids_flat, i))\n",
        "            # print(p)\n",
        "            # processes.append(p)\n",
        "            p.start()\n",
        "            processes.append(p)\n",
        "        for p in processes:\n",
        "            p.join()\n",
        "        x1_train = np.vstack(x1_train)\n",
        "        fids = np.vstack(fids)\n",
        "        fids_flat = np.vstack(fids_flat)\n",
        "      \n",
        "    print(f\"This is the iteration number{n_datasets}\")\n",
        "    print(x1_train.shape, fids.shape)\n",
        "    print(x1_train[0,:,:], fids[0,:,:])\n",
        "\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x1_train, fids, test_size=0.2)\n",
        "\n",
        "    history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), batch_size=10)\n",
        "\n",
        "    # history = model.fit(train, fid, epochs=200, batch_size=200)\n",
        "\n",
        "    loss = np.log10(history.history[\"loss\"])\n",
        "    val_loss = np.log10(history.history['val_loss'])\n",
        "    epochs = range(1, len(loss) + 1)\n",
        "    plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    print(loss)\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    plt.plot(epochs, acc, 'y', label='Training acc')\n",
        "    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    del x1_train, fids, fids_flat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k95q2_cChqJ7",
        "outputId": "a83d3d7d-6fef-4d43-eee5-af15eddd9321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90wA9QnbEo1O",
        "outputId": "a2259926-65bf-41a6-8cc7-066ecaa2e9d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.getcwd()\n",
        "\n",
        "os.chdir('drive')\n",
        "\n",
        "os.chdir('MyDrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8KqG4EcEoyo"
      },
      "outputs": [],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZz2M8ImEov_",
        "outputId": "16ce2c34-6bad-4874-c4c7-ddca03b0afe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model_ud_12_ff/my_model_ud_12/assets\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p saved_model_ud_12_ff\n",
        "model.save('saved_model_ud_12_ff/my_model_ud_12') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cg5uYeQzEor6"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('saved_model_ud_12/my_model_ud_12')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQFbjyIXEokY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MajiGgjYEoRN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Dense_U-Net_3D_NUS_NMR.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMHQetqWVF6KLOXx0MiXr8J",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}