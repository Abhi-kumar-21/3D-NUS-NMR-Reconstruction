{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhi-kumar-21/3D-NUS-NMR-Reconstruction/blob/main/real_3D_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_CjXFnejdnc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YutEYcTpkTif"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "from time import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from sklearn import preprocessing\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Conv3D, MaxPooling3D\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "#Parallelization library\n",
        "from multiprocessing import Pool, Manager, Process\n",
        "import threading\n",
        "\n",
        "from warnings import filterwarnings\n",
        "filterwarnings(action='ignore', category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "316GjOQvkY1o",
        "outputId": "b8a974fe-daa0-4036-e121-6f7d89a3d320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = pd.read_excel('/content/drive/My Drive/Scheduler.xlsx')\n",
        "\n",
        "arr = df.to_numpy().astype('int')\n",
        "\n",
        "mul_arr = np.zeros((128,32),'float')\n",
        "for d in arr:\n",
        "  mul_arr[d[0],d[1]] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDeedybekY-q",
        "outputId": "8d4cb1e4-e9bd-45a7-9d5c-61c78e928d74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., ..., 0., 1., 0.],\n",
              "       [1., 1., 0., ..., 0., 1., 0.],\n",
              "       [1., 1., 1., ..., 0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "mul_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxRia8pIkZBz"
      },
      "outputs": [],
      "source": [
        "def make_fid(freqs, freqs1, freqs2, r2s, ints, noise=False):\n",
        "    \n",
        "  retval=np.zeros( (NP, NP1, NP2) , dtype=np.complex)\n",
        "  \n",
        "  # Time samples\n",
        "  samp_time = np.linspace(0.,(NP-1.)/SW,NP)\n",
        "  samp_time1 = np.linspace(0.,(NP1-1.)/SW1,NP1)\n",
        "  samp_time2 = np.linspace(0.,(NP2-1.)/SW2,NP2)\n",
        "  \n",
        "  K = np.max([len(freqs), len(freqs2), len(freqs2), len(r2s), len(ints)])\n",
        "  for n in range(NP):\n",
        "    for n1 in range(NP1):\n",
        "      for n2 in range(NP2):\n",
        "        val = 0.\n",
        "        for s in range(K):\n",
        "          val+= (np.exp((1j*2*np.pi*freqs[s] - r2s[s])*samp_time[n])*\n",
        "                  np.exp((1j*2*np.pi*freqs1[s] - r2s[s])*samp_time1[n1])*\n",
        "                  np.exp((1j*2*np.pi*freqs2[s] - r2s[s])*samp_time2[n2])*\n",
        "                  ints[s])\n",
        "        retval[n,n1,n2]=val\n",
        "\n",
        "  return retval\n",
        "\n",
        "\n",
        "def make_sine_combinations():\n",
        "\n",
        "  # Number of Signals\n",
        "  nSignals = random.randint(50,NSignals+1)  \n",
        "  # print(nSignals)\n",
        "\n",
        "  # Frequencies\n",
        "  freqs = np.random.random(nSignals)*SW\n",
        "  freqs1 = np.random.random(nSignals)*SW1\n",
        "  freqs2 = np.random.random(nSignals)*SW2\n",
        "\n",
        "  # Transverse relaxation rate\n",
        "  r2s = np.random.random(nSignals)*(5) + (1/100)\n",
        "\n",
        "  #Intensity = amplitude\n",
        "  ints = np.random.random(nSignals)*5 + 1\n",
        "\n",
        "  # FID creation\n",
        "  ff = make_fid(freqs,freqs1,freqs2,r2s,ints,NoiseLevel)\n",
        "\n",
        "  temp_realPart = np.real(ff)\n",
        "  temp = np.abs(temp_realPart[0,0,0])\n",
        "  ff = ff/temp\n",
        "\n",
        "  return ff\n",
        "\n",
        "\n",
        "def make_2d_mat(b_size):\n",
        "    \n",
        "  # Training matrix\n",
        "  target = np.zeros([b_size*NP, NP1*NP2], dtype=np.float)       # For Target\n",
        "  train = np.zeros([b_size*NP, NP1, NP2], dtype=np.float)      # For CNN\n",
        "  train1 = np.zeros([b_size*NP, NP1, NP2], dtype=np.float)     # For test_fft\n",
        "  train_1 = np.zeros([b_size*NP, NP1*NP2], dtype=np.float)      # For DNN\n",
        "\n",
        "  # Matix concatenation (training)\n",
        "  for i in range(b_size):\n",
        "    ff = make_sine_combinations()\n",
        "    train_ff = ff\n",
        "\n",
        "    ff = np.fft.fft(ff,axis=0)\n",
        "    ff = np.fft.fft(ff,axis=1)\n",
        "    ff = np.fft.fft(ff,axis=2)\n",
        "\n",
        "    ff = ff/np.max(np.abs(ff))\n",
        "\n",
        "    train1[i*NP:(i+1)*NP,:,:] = np.real(ff)\n",
        "\n",
        "    for j in range(NP):\n",
        "      train_ff[j,:,:] = np.multiply(train_ff[j,:,:],mul_arr)\n",
        "      index = (i*NP)+j\n",
        "      target[index,:] = np.real(ff[j]).reshape(NP1*NP2)\n",
        "    \n",
        "    train_ff = np.fft.fft(train_ff,axis=0)\n",
        "    train_ff = np.fft.fft(train_ff,axis=1)\n",
        "    train_ff = np.fft.fft(train_ff,axis=2)\n",
        "\n",
        "    train_ff = train_ff/np.max(np.abs(train_ff))\n",
        "\n",
        "    train[i*NP:(i+1)*NP,:,:] = np.real(train_ff)\n",
        "    \n",
        "    for j in range(NP):\n",
        "      index = (i*NP)+j\n",
        "      train_1[index,:] = np.real(train_ff[j]).reshape(NP1*NP2)\n",
        "\n",
        "  return train, train1, target\n",
        "\n",
        "N = 5000\n",
        "NP = 2        # Direct dimension\n",
        "NP1 = 128     # Indirect Dimension 1\n",
        "NP2 = 64      # Indirect Dimension 1\n",
        "SW = 1000\n",
        "SW1 = 10000\n",
        "SW2 = 4000\n",
        "NoiseLevel = 0\n",
        "NSignals = 25\n",
        "dataIn = []\n",
        "dataOut = []\n",
        "epochs = 12\n",
        "batch_size = 32\n",
        "val_split = 0.05\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bISDK5mQkIiV"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Conv2D, Conv3D, DepthwiseConv2D, SeparableConv2D, Conv3DTranspose\n",
        "from keras.layers import Flatten, MaxPool2D, AvgPool2D, GlobalAvgPool2D, UpSampling2D, BatchNormalization\n",
        "from keras.layers import Concatenate, Add, Dropout, ReLU, Lambda, Activation, LeakyReLU, PReLU \n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "from time import time\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sCPZ15McfE-",
        "outputId": "6200e677-d58e-40c0-9616-f06b5a2a95e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 128, 64, 1)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 128, 64, 64)  640         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 64, 64)  0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 128, 64, 64)  256        ['max_pooling2d[0][0]']          \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " tf.math.tanh (TFOpLambda)      (None, 128, 64, 64)  0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 128, 64, 128  8320        ['tf.math.tanh[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 128, 64, 128  512        ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_1 (TFOpLambda)    (None, 128, 64, 128  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 64, 32)  36896       ['tf.math.tanh_1[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 128, 64, 96)  0           ['max_pooling2d[0][0]',          \n",
            "                                                                  'conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 128, 64, 96)  384        ['concatenate[0][0]']            \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.math.tanh_2 (TFOpLambda)    (None, 128, 64, 96)  0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 64, 128  12416       ['tf.math.tanh_2[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 128, 64, 128  512        ['conv2d_3[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_3 (TFOpLambda)    (None, 128, 64, 128  0           ['batch_normalization_3[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 128, 64, 32)  36896       ['tf.math.tanh_3[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 128, 64, 128  0           ['concatenate[0][0]',            \n",
            "                                )                                 'conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 128, 64, 128  512        ['concatenate_1[0][0]']          \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_4 (TFOpLambda)    (None, 128, 64, 128  0           ['batch_normalization_4[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 128, 64, 128  16512       ['tf.math.tanh_4[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 128, 64, 128  512        ['conv2d_5[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_5 (TFOpLambda)    (None, 128, 64, 128  0           ['batch_normalization_5[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 128, 64, 32)  36896       ['tf.math.tanh_5[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 128, 64, 160  0           ['concatenate_1[0][0]',          \n",
            "                                )                                 'conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 128, 64, 160  640        ['concatenate_2[0][0]']          \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_6 (TFOpLambda)    (None, 128, 64, 160  0           ['batch_normalization_6[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 128, 64, 128  20608       ['tf.math.tanh_6[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 128, 64, 128  512        ['conv2d_7[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_7 (TFOpLambda)    (None, 128, 64, 128  0           ['batch_normalization_7[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 128, 64, 32)  36896       ['tf.math.tanh_7[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 128, 64, 192  0           ['concatenate_2[0][0]',          \n",
            "                                )                                 'conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 128, 64, 192  768        ['concatenate_3[0][0]']          \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_8 (TFOpLambda)    (None, 128, 64, 192  0           ['batch_normalization_8[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 128, 64, 128  24704       ['tf.math.tanh_8[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 128, 64, 128  512        ['conv2d_9[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_9 (TFOpLambda)    (None, 128, 64, 128  0           ['batch_normalization_9[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_9[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 128, 64, 224  0           ['concatenate_3[0][0]',          \n",
            "                                )                                 'conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 128, 64, 224  896        ['concatenate_4[0][0]']          \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_10 (TFOpLambda)   (None, 128, 64, 224  0           ['batch_normalization_10[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 128, 64, 128  28800       ['tf.math.tanh_10[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 128, 64, 128  512        ['conv2d_11[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_11 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_11[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_11[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 128, 64, 256  0           ['concatenate_4[0][0]',          \n",
            "                                )                                 'conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 128, 64, 256  1024       ['concatenate_5[0][0]']          \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_12 (TFOpLambda)   (None, 128, 64, 256  0           ['batch_normalization_12[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 128, 64, 128  32896       ['tf.math.tanh_12[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 128, 64, 128  0          ['conv2d_13[0][0]']              \n",
            " ing2D)                         )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 128, 64, 128  512        ['average_pooling2d[0][0]']      \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_13 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_13[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 128, 64, 128  16512       ['tf.math.tanh_13[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 128, 64, 128  512        ['conv2d_14[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_14 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_14[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_14[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 128, 64, 160  0           ['average_pooling2d[0][0]',      \n",
            "                                )                                 'conv2d_15[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 128, 64, 160  640        ['concatenate_6[0][0]']          \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_15 (TFOpLambda)   (None, 128, 64, 160  0           ['batch_normalization_15[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 128, 64, 128  20608       ['tf.math.tanh_15[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 128, 64, 128  512        ['conv2d_16[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_16 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_16[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_16[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 128, 64, 192  0           ['concatenate_6[0][0]',          \n",
            "                                )                                 'conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 128, 64, 192  768        ['concatenate_7[0][0]']          \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_17 (TFOpLambda)   (None, 128, 64, 192  0           ['batch_normalization_17[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 128, 64, 128  24704       ['tf.math.tanh_17[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 128, 64, 128  512        ['conv2d_18[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_18 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_18[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_18[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 128, 64, 224  0           ['concatenate_7[0][0]',          \n",
            "                                )                                 'conv2d_19[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 128, 64, 224  896        ['concatenate_8[0][0]']          \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_19 (TFOpLambda)   (None, 128, 64, 224  0           ['batch_normalization_19[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 128, 64, 128  28800       ['tf.math.tanh_19[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 128, 64, 128  512        ['conv2d_20[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_20 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_20[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_20[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 128, 64, 256  0           ['concatenate_8[0][0]',          \n",
            "                                )                                 'conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 128, 64, 256  1024       ['concatenate_9[0][0]']          \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_21 (TFOpLambda)   (None, 128, 64, 256  0           ['batch_normalization_21[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 128, 64, 128  32896       ['tf.math.tanh_21[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 128, 64, 128  512        ['conv2d_22[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_22 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_22[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_22[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 128, 64, 288  0           ['concatenate_9[0][0]',          \n",
            "                                )                                 'conv2d_23[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 128, 64, 288  1152       ['concatenate_10[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_23 (TFOpLambda)   (None, 128, 64, 288  0           ['batch_normalization_23[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 128, 64, 128  36992       ['tf.math.tanh_23[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 128, 64, 128  512        ['conv2d_24[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_24 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_24[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_24[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenate)   (None, 128, 64, 320  0           ['concatenate_10[0][0]',         \n",
            "                                )                                 'conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 128, 64, 320  1280       ['concatenate_11[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_25 (TFOpLambda)   (None, 128, 64, 320  0           ['batch_normalization_25[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 128, 64, 128  41088       ['tf.math.tanh_25[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 128, 64, 128  512        ['conv2d_26[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_26 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_26[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_26[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenate)   (None, 128, 64, 352  0           ['concatenate_11[0][0]',         \n",
            "                                )                                 'conv2d_27[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 128, 64, 352  1408       ['concatenate_12[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_27 (TFOpLambda)   (None, 128, 64, 352  0           ['batch_normalization_27[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 128, 64, 128  45184       ['tf.math.tanh_27[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 128, 64, 128  512        ['conv2d_28[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_28 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_28[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_28[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenate)   (None, 128, 64, 384  0           ['concatenate_12[0][0]',         \n",
            "                                )                                 'conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 128, 64, 384  1536       ['concatenate_13[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_29 (TFOpLambda)   (None, 128, 64, 384  0           ['batch_normalization_29[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 128, 64, 128  49280       ['tf.math.tanh_29[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 128, 64, 128  512        ['conv2d_30[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_30 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_30[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_30[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenate)   (None, 128, 64, 416  0           ['concatenate_13[0][0]',         \n",
            "                                )                                 'conv2d_31[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 128, 64, 416  1664       ['concatenate_14[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_31 (TFOpLambda)   (None, 128, 64, 416  0           ['batch_normalization_31[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 128, 64, 128  53376       ['tf.math.tanh_31[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 128, 64, 128  512        ['conv2d_32[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_32 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_32[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_32[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenate)   (None, 128, 64, 448  0           ['concatenate_14[0][0]',         \n",
            "                                )                                 'conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 128, 64, 448  1792       ['concatenate_15[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_33 (TFOpLambda)   (None, 128, 64, 448  0           ['batch_normalization_33[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 128, 64, 128  57472       ['tf.math.tanh_33[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 128, 64, 128  512        ['conv2d_34[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_34 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_34[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_34[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_16 (Concatenate)   (None, 128, 64, 480  0           ['concatenate_15[0][0]',         \n",
            "                                )                                 'conv2d_35[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 128, 64, 480  1920       ['concatenate_16[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_35 (TFOpLambda)   (None, 128, 64, 480  0           ['batch_normalization_35[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 128, 64, 128  61568       ['tf.math.tanh_35[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 128, 64, 128  512        ['conv2d_36[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_36 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_36[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_36[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_17 (Concatenate)   (None, 128, 64, 512  0           ['concatenate_16[0][0]',         \n",
            "                                )                                 'conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 128, 64, 512  2048       ['concatenate_17[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_37 (TFOpLambda)   (None, 128, 64, 512  0           ['batch_normalization_37[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 128, 64, 256  131328      ['tf.math.tanh_37[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 128, 64, 256  0          ['conv2d_38[0][0]']              \n",
            " oling2D)                       )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 128, 64, 256  1024       ['average_pooling2d_1[0][0]']    \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_38 (TFOpLambda)   (None, 128, 64, 256  0           ['batch_normalization_38[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 128, 64, 128  32896       ['tf.math.tanh_38[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 128, 64, 128  512        ['conv2d_39[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_39 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_39[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_39[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_18 (Concatenate)   (None, 128, 64, 288  0           ['average_pooling2d_1[0][0]',    \n",
            "                                )                                 'conv2d_40[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 128, 64, 288  1152       ['concatenate_18[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_40 (TFOpLambda)   (None, 128, 64, 288  0           ['batch_normalization_40[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 128, 64, 128  36992       ['tf.math.tanh_40[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 128, 64, 128  512        ['conv2d_41[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_41 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_41[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_41[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_19 (Concatenate)   (None, 128, 64, 320  0           ['concatenate_18[0][0]',         \n",
            "                                )                                 'conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 128, 64, 320  1280       ['concatenate_19[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_42 (TFOpLambda)   (None, 128, 64, 320  0           ['batch_normalization_42[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 128, 64, 128  41088       ['tf.math.tanh_42[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 128, 64, 128  512        ['conv2d_43[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_43 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_43[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_43[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_20 (Concatenate)   (None, 128, 64, 352  0           ['concatenate_19[0][0]',         \n",
            "                                )                                 'conv2d_44[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 128, 64, 352  1408       ['concatenate_20[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_44 (TFOpLambda)   (None, 128, 64, 352  0           ['batch_normalization_44[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 128, 64, 128  45184       ['tf.math.tanh_44[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 128, 64, 128  512        ['conv2d_45[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_45 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_45[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_45[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_21 (Concatenate)   (None, 128, 64, 384  0           ['concatenate_20[0][0]',         \n",
            "                                )                                 'conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 128, 64, 384  1536       ['concatenate_21[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_46 (TFOpLambda)   (None, 128, 64, 384  0           ['batch_normalization_46[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 128, 64, 128  49280       ['tf.math.tanh_46[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 128, 64, 128  512        ['conv2d_47[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_47 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_47[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_47[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_22 (Concatenate)   (None, 128, 64, 416  0           ['concatenate_21[0][0]',         \n",
            "                                )                                 'conv2d_48[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 128, 64, 416  1664       ['concatenate_22[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_48 (TFOpLambda)   (None, 128, 64, 416  0           ['batch_normalization_48[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 128, 64, 128  53376       ['tf.math.tanh_48[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 128, 64, 128  512        ['conv2d_49[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_49 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_49[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_49[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_23 (Concatenate)   (None, 128, 64, 448  0           ['concatenate_22[0][0]',         \n",
            "                                )                                 'conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 128, 64, 448  1792       ['concatenate_23[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_50 (TFOpLambda)   (None, 128, 64, 448  0           ['batch_normalization_50[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 128, 64, 128  57472       ['tf.math.tanh_50[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 128, 64, 128  512        ['conv2d_51[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_51 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_51[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_51[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_24 (Concatenate)   (None, 128, 64, 480  0           ['concatenate_23[0][0]',         \n",
            "                                )                                 'conv2d_52[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 128, 64, 480  1920       ['concatenate_24[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_52 (TFOpLambda)   (None, 128, 64, 480  0           ['batch_normalization_52[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 128, 64, 128  61568       ['tf.math.tanh_52[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 128, 64, 128  512        ['conv2d_53[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_53 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_53[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_53[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_25 (Concatenate)   (None, 128, 64, 512  0           ['concatenate_24[0][0]',         \n",
            "                                )                                 'conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 128, 64, 512  2048       ['concatenate_25[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_54 (TFOpLambda)   (None, 128, 64, 512  0           ['batch_normalization_54[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 128, 64, 128  65664       ['tf.math.tanh_54[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 128, 64, 128  512        ['conv2d_55[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_55 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_55[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_55[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_26 (Concatenate)   (None, 128, 64, 544  0           ['concatenate_25[0][0]',         \n",
            "                                )                                 'conv2d_56[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 128, 64, 544  2176       ['concatenate_26[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_56 (TFOpLambda)   (None, 128, 64, 544  0           ['batch_normalization_56[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 128, 64, 128  69760       ['tf.math.tanh_56[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 128, 64, 128  512        ['conv2d_57[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_57 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_57[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_57[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_27 (Concatenate)   (None, 128, 64, 576  0           ['concatenate_26[0][0]',         \n",
            "                                )                                 'conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 128, 64, 576  2304       ['concatenate_27[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_58 (TFOpLambda)   (None, 128, 64, 576  0           ['batch_normalization_58[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 128, 64, 128  73856       ['tf.math.tanh_58[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 128, 64, 128  512        ['conv2d_59[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_59 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_59[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_59[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_28 (Concatenate)   (None, 128, 64, 608  0           ['concatenate_27[0][0]',         \n",
            "                                )                                 'conv2d_60[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 128, 64, 608  2432       ['concatenate_28[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_60 (TFOpLambda)   (None, 128, 64, 608  0           ['batch_normalization_60[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 128, 64, 128  77952       ['tf.math.tanh_60[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 128, 64, 128  512        ['conv2d_61[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_61 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_61[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_61[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_29 (Concatenate)   (None, 128, 64, 640  0           ['concatenate_28[0][0]',         \n",
            "                                )                                 'conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 128, 64, 640  2560       ['concatenate_29[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_62 (TFOpLambda)   (None, 128, 64, 640  0           ['batch_normalization_62[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 128, 64, 128  82048       ['tf.math.tanh_62[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 128, 64, 128  512        ['conv2d_63[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_63 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_63[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_63[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_30 (Concatenate)   (None, 128, 64, 672  0           ['concatenate_29[0][0]',         \n",
            "                                )                                 'conv2d_64[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 128, 64, 672  2688       ['concatenate_30[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_64 (TFOpLambda)   (None, 128, 64, 672  0           ['batch_normalization_64[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 128, 64, 128  86144       ['tf.math.tanh_64[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 128, 64, 128  512        ['conv2d_65[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_65 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_65[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_65[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_31 (Concatenate)   (None, 128, 64, 704  0           ['concatenate_30[0][0]',         \n",
            "                                )                                 'conv2d_66[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 128, 64, 704  2816       ['concatenate_31[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_66 (TFOpLambda)   (None, 128, 64, 704  0           ['batch_normalization_66[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 128, 64, 128  90240       ['tf.math.tanh_66[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 128, 64, 128  512        ['conv2d_67[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_67 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_67[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_67[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_32 (Concatenate)   (None, 128, 64, 736  0           ['concatenate_31[0][0]',         \n",
            "                                )                                 'conv2d_68[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 128, 64, 736  2944       ['concatenate_32[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_68 (TFOpLambda)   (None, 128, 64, 736  0           ['batch_normalization_68[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 128, 64, 128  94336       ['tf.math.tanh_68[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 128, 64, 128  512        ['conv2d_69[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_69 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_69[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_69[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_33 (Concatenate)   (None, 128, 64, 768  0           ['concatenate_32[0][0]',         \n",
            "                                )                                 'conv2d_70[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 128, 64, 768  3072       ['concatenate_33[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_70 (TFOpLambda)   (None, 128, 64, 768  0           ['batch_normalization_70[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 128, 64, 128  98432       ['tf.math.tanh_70[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 128, 64, 128  512        ['conv2d_71[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_71 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_71[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_71[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_34 (Concatenate)   (None, 128, 64, 800  0           ['concatenate_33[0][0]',         \n",
            "                                )                                 'conv2d_72[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 128, 64, 800  3200       ['concatenate_34[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_72 (TFOpLambda)   (None, 128, 64, 800  0           ['batch_normalization_72[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 128, 64, 128  102528      ['tf.math.tanh_72[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 128, 64, 128  512        ['conv2d_73[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_73 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_73[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_73[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_35 (Concatenate)   (None, 128, 64, 832  0           ['concatenate_34[0][0]',         \n",
            "                                )                                 'conv2d_74[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 128, 64, 832  3328       ['concatenate_35[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_74 (TFOpLambda)   (None, 128, 64, 832  0           ['batch_normalization_74[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 128, 64, 128  106624      ['tf.math.tanh_74[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 128, 64, 128  512        ['conv2d_75[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_75 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_75[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_75[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_36 (Concatenate)   (None, 128, 64, 864  0           ['concatenate_35[0][0]',         \n",
            "                                )                                 'conv2d_76[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 128, 64, 864  3456       ['concatenate_36[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_76 (TFOpLambda)   (None, 128, 64, 864  0           ['batch_normalization_76[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 128, 64, 128  110720      ['tf.math.tanh_76[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 128, 64, 128  512        ['conv2d_77[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_77 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_77[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_77[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_37 (Concatenate)   (None, 128, 64, 896  0           ['concatenate_36[0][0]',         \n",
            "                                )                                 'conv2d_78[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 128, 64, 896  3584       ['concatenate_37[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_78 (TFOpLambda)   (None, 128, 64, 896  0           ['batch_normalization_78[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 128, 64, 128  114816      ['tf.math.tanh_78[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 128, 64, 128  512        ['conv2d_79[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_79 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_79[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_79[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_38 (Concatenate)   (None, 128, 64, 928  0           ['concatenate_37[0][0]',         \n",
            "                                )                                 'conv2d_80[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 128, 64, 928  3712       ['concatenate_38[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_80 (TFOpLambda)   (None, 128, 64, 928  0           ['batch_normalization_80[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 128, 64, 128  118912      ['tf.math.tanh_80[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 128, 64, 128  512        ['conv2d_81[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_81 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_81[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_81[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_39 (Concatenate)   (None, 128, 64, 960  0           ['concatenate_38[0][0]',         \n",
            "                                )                                 'conv2d_82[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 128, 64, 960  3840       ['concatenate_39[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_82 (TFOpLambda)   (None, 128, 64, 960  0           ['batch_normalization_82[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 128, 64, 128  123008      ['tf.math.tanh_82[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 128, 64, 128  512        ['conv2d_83[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_83 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_83[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_83[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_40 (Concatenate)   (None, 128, 64, 992  0           ['concatenate_39[0][0]',         \n",
            "                                )                                 'conv2d_84[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 128, 64, 992  3968       ['concatenate_40[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_84 (TFOpLambda)   (None, 128, 64, 992  0           ['batch_normalization_84[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 128, 64, 128  127104      ['tf.math.tanh_84[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 128, 64, 128  512        ['conv2d_85[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_85 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_85[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_85[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_41 (Concatenate)   (None, 128, 64, 102  0           ['concatenate_40[0][0]',         \n",
            "                                4)                                'conv2d_86[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 128, 64, 102  4096       ['concatenate_41[0][0]']         \n",
            " ormalization)                  4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_86 (TFOpLambda)   (None, 128, 64, 102  0           ['batch_normalization_86[0][0]'] \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 128, 64, 512  524800      ['tf.math.tanh_86[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 128, 64, 512  0          ['conv2d_87[0][0]']              \n",
            " oling2D)                       )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 128, 64, 512  2048       ['average_pooling2d_2[0][0]']    \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_87 (TFOpLambda)   (None, 128, 64, 512  0           ['batch_normalization_87[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 128, 64, 128  65664       ['tf.math.tanh_87[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 128, 64, 128  512        ['conv2d_88[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_88 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_88[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_88[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_42 (Concatenate)   (None, 128, 64, 544  0           ['average_pooling2d_2[0][0]',    \n",
            "                                )                                 'conv2d_89[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 128, 64, 544  2176       ['concatenate_42[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_89 (TFOpLambda)   (None, 128, 64, 544  0           ['batch_normalization_89[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 128, 64, 128  69760       ['tf.math.tanh_89[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 128, 64, 128  512        ['conv2d_90[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_90 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_90[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_90[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_43 (Concatenate)   (None, 128, 64, 576  0           ['concatenate_42[0][0]',         \n",
            "                                )                                 'conv2d_91[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 128, 64, 576  2304       ['concatenate_43[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_91 (TFOpLambda)   (None, 128, 64, 576  0           ['batch_normalization_91[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 128, 64, 128  73856       ['tf.math.tanh_91[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 128, 64, 128  512        ['conv2d_92[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_92 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_92[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_92[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_44 (Concatenate)   (None, 128, 64, 608  0           ['concatenate_43[0][0]',         \n",
            "                                )                                 'conv2d_93[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 128, 64, 608  2432       ['concatenate_44[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_93 (TFOpLambda)   (None, 128, 64, 608  0           ['batch_normalization_93[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 128, 64, 128  77952       ['tf.math.tanh_93[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_94 (BatchN  (None, 128, 64, 128  512        ['conv2d_94[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_94 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_94[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_94[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_45 (Concatenate)   (None, 128, 64, 640  0           ['concatenate_44[0][0]',         \n",
            "                                )                                 'conv2d_95[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_95 (BatchN  (None, 128, 64, 640  2560       ['concatenate_45[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_95 (TFOpLambda)   (None, 128, 64, 640  0           ['batch_normalization_95[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 128, 64, 128  82048       ['tf.math.tanh_95[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_96 (BatchN  (None, 128, 64, 128  512        ['conv2d_96[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_96 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_96[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_96[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_46 (Concatenate)   (None, 128, 64, 672  0           ['concatenate_45[0][0]',         \n",
            "                                )                                 'conv2d_97[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_97 (BatchN  (None, 128, 64, 672  2688       ['concatenate_46[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_97 (TFOpLambda)   (None, 128, 64, 672  0           ['batch_normalization_97[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 128, 64, 128  86144       ['tf.math.tanh_97[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_98 (BatchN  (None, 128, 64, 128  512        ['conv2d_98[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_98 (TFOpLambda)   (None, 128, 64, 128  0           ['batch_normalization_98[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, 128, 64, 32)  36896       ['tf.math.tanh_98[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_47 (Concatenate)   (None, 128, 64, 704  0           ['concatenate_46[0][0]',         \n",
            "                                )                                 'conv2d_99[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_99 (BatchN  (None, 128, 64, 704  2816       ['concatenate_47[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_99 (TFOpLambda)   (None, 128, 64, 704  0           ['batch_normalization_99[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, 128, 64, 128  90240       ['tf.math.tanh_99[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_100 (Batch  (None, 128, 64, 128  512        ['conv2d_100[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_100 (TFOpLambda)  (None, 128, 64, 128  0           ['batch_normalization_100[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, 128, 64, 32)  36896       ['tf.math.tanh_100[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_48 (Concatenate)   (None, 128, 64, 736  0           ['concatenate_47[0][0]',         \n",
            "                                )                                 'conv2d_101[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_101 (Batch  (None, 128, 64, 736  2944       ['concatenate_48[0][0]']         \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_101 (TFOpLambda)  (None, 128, 64, 736  0           ['batch_normalization_101[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 128, 64, 128  94336       ['tf.math.tanh_101[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_102 (Batch  (None, 128, 64, 128  512        ['conv2d_102[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_102 (TFOpLambda)  (None, 128, 64, 128  0           ['batch_normalization_102[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, 128, 64, 32)  36896       ['tf.math.tanh_102[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_49 (Concatenate)   (None, 128, 64, 768  0           ['concatenate_48[0][0]',         \n",
            "                                )                                 'conv2d_103[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_103 (Batch  (None, 128, 64, 768  3072       ['concatenate_49[0][0]']         \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_103 (TFOpLambda)  (None, 128, 64, 768  0           ['batch_normalization_103[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)            (None, 128, 64, 128  98432       ['tf.math.tanh_103[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_104 (Batch  (None, 128, 64, 128  512        ['conv2d_104[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_104 (TFOpLambda)  (None, 128, 64, 128  0           ['batch_normalization_104[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)            (None, 128, 64, 32)  36896       ['tf.math.tanh_104[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_50 (Concatenate)   (None, 128, 64, 800  0           ['concatenate_49[0][0]',         \n",
            "                                )                                 'conv2d_105[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_105 (Batch  (None, 128, 64, 800  3200       ['concatenate_50[0][0]']         \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_105 (TFOpLambda)  (None, 128, 64, 800  0           ['batch_normalization_105[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)            (None, 128, 64, 128  102528      ['tf.math.tanh_105[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_106 (Batch  (None, 128, 64, 128  512        ['conv2d_106[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_106 (TFOpLambda)  (None, 128, 64, 128  0           ['batch_normalization_106[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)            (None, 128, 64, 32)  36896       ['tf.math.tanh_106[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_51 (Concatenate)   (None, 128, 64, 832  0           ['concatenate_50[0][0]',         \n",
            "                                )                                 'conv2d_107[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_107 (Batch  (None, 128, 64, 832  3328       ['concatenate_51[0][0]']         \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_107 (TFOpLambda)  (None, 128, 64, 832  0           ['batch_normalization_107[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)            (None, 128, 64, 128  106624      ['tf.math.tanh_107[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_108 (Batch  (None, 128, 64, 128  512        ['conv2d_108[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_108 (TFOpLambda)  (None, 128, 64, 128  0           ['batch_normalization_108[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)            (None, 128, 64, 32)  36896       ['tf.math.tanh_108[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_52 (Concatenate)   (None, 128, 64, 864  0           ['concatenate_51[0][0]',         \n",
            "                                )                                 'conv2d_109[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_109 (Batch  (None, 128, 64, 864  3456       ['concatenate_52[0][0]']         \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_109 (TFOpLambda)  (None, 128, 64, 864  0           ['batch_normalization_109[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)            (None, 128, 64, 128  110720      ['tf.math.tanh_109[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_110 (Batch  (None, 128, 64, 128  512        ['conv2d_110[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_110 (TFOpLambda)  (None, 128, 64, 128  0           ['batch_normalization_110[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)            (None, 128, 64, 32)  36896       ['tf.math.tanh_110[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_53 (Concatenate)   (None, 128, 64, 896  0           ['concatenate_52[0][0]',         \n",
            "                                )                                 'conv2d_111[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_111 (Batch  (None, 128, 64, 896  3584       ['concatenate_53[0][0]']         \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_111 (TFOpLambda)  (None, 128, 64, 896  0           ['batch_normalization_111[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)            (None, 128, 64, 128  114816      ['tf.math.tanh_111[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_112 (Batch  (None, 128, 64, 128  512        ['conv2d_112[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_112 (TFOpLambda)  (None, 128, 64, 128  0           ['batch_normalization_112[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (None, 128, 64, 32)  36896       ['tf.math.tanh_112[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_54 (Concatenate)   (None, 128, 64, 928  0           ['concatenate_53[0][0]',         \n",
            "                                )                                 'conv2d_113[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_113 (Batch  (None, 128, 64, 928  3712       ['concatenate_54[0][0]']         \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_113 (TFOpLambda)  (None, 128, 64, 928  0           ['batch_normalization_113[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)            (None, 128, 64, 128  118912      ['tf.math.tanh_113[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_114 (Batch  (None, 128, 64, 128  512        ['conv2d_114[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_114 (TFOpLambda)  (None, 128, 64, 128  0           ['batch_normalization_114[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)            (None, 128, 64, 32)  36896       ['tf.math.tanh_114[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_55 (Concatenate)   (None, 128, 64, 960  0           ['concatenate_54[0][0]',         \n",
            "                                )                                 'conv2d_115[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_115 (Batch  (None, 128, 64, 960  3840       ['concatenate_55[0][0]']         \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_115 (TFOpLambda)  (None, 128, 64, 960  0           ['batch_normalization_115[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)            (None, 128, 64, 128  123008      ['tf.math.tanh_115[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_116 (Batch  (None, 128, 64, 128  512        ['conv2d_116[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_116 (TFOpLambda)  (None, 128, 64, 128  0           ['batch_normalization_116[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)            (None, 128, 64, 32)  36896       ['tf.math.tanh_116[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_56 (Concatenate)   (None, 128, 64, 992  0           ['concatenate_55[0][0]',         \n",
            "                                )                                 'conv2d_117[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_117 (Batch  (None, 128, 64, 992  3968       ['concatenate_56[0][0]']         \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_117 (TFOpLambda)  (None, 128, 64, 992  0           ['batch_normalization_117[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_118 (Conv2D)            (None, 128, 64, 128  127104      ['tf.math.tanh_117[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_118 (Batch  (None, 128, 64, 128  512        ['conv2d_118[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_118 (TFOpLambda)  (None, 128, 64, 128  0           ['batch_normalization_118[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_119 (Conv2D)            (None, 128, 64, 32)  36896       ['tf.math.tanh_118[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_57 (Concatenate)   (None, 128, 64, 102  0           ['concatenate_56[0][0]',         \n",
            "                                4)                                'conv2d_119[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_121 (Conv2D)            (None, 128, 64, 1)   1025        ['concatenate_57[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,035,585\n",
            "Trainable params: 6,954,113\n",
            "Non-trainable params: 81,472\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#===============================================================================\n",
        "# Densenet Network Architecture\n",
        "\n",
        "def densenet(img_shape, n_classes, f=32):\n",
        "  repetitions = 6, 12, 24, 16\n",
        "  \n",
        "  def bn_rl_conv(x, f, k=1, s=1, p='same'):\n",
        "    x = BatchNormalization()(x)\n",
        "    x = tf.keras.activations.tanh(x)\n",
        "    # x = ReLU()(x)\n",
        "    x = Conv2D(f, k, strides=s, padding=p)(x)\n",
        "    return x\n",
        "  \n",
        "  \n",
        "  def dense_block(tensor, r):\n",
        "    for _ in range(r):\n",
        "      x = bn_rl_conv(tensor, 4*f)\n",
        "      x = bn_rl_conv(x, f, 3)\n",
        "      tensor = Concatenate()([tensor, x])\n",
        "    return tensor\n",
        "  \n",
        "  \n",
        "  def transition_block(x):\n",
        "    x = bn_rl_conv(x, K.int_shape(x)[-1] // 2)\n",
        "    x = AvgPool2D(2, strides=1, padding='same')(x)\n",
        "    return x\n",
        "  \n",
        "  \n",
        "  input = Input(img_shape)\n",
        "  \n",
        "  x = Conv2D(64, 3, strides=1, padding='same')(input)\n",
        "  x = MaxPool2D(3, strides=1, padding='same')(x)\n",
        "  \n",
        "  for r in repetitions:\n",
        "    d = dense_block(x, r)\n",
        "    x = transition_block(d)\n",
        "\n",
        "  \n",
        "  output = Conv2D(1, 1, activation='tanh')(d)\n",
        "  \n",
        "  model = Model(input, output)\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "input_shape = 128, 64, 1\n",
        "n_classes = 4096\n",
        "\n",
        "K.clear_session()\n",
        "model = densenet(input_shape, n_classes)\n",
        "model.summary()\n",
        "\n",
        "# Compile the model\n",
        "def get_lr_metric(optimizer):\n",
        "    def lr(y_true, y_pred):\n",
        "        return optimizer.lr\n",
        "    return lr\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
        "lr_metric = get_lr_metric(optimizer)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"loss\",\n",
        "                              factor=0.8,\n",
        "                              patience=9,\n",
        "                              min_lr=0.0001\n",
        ")\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QasXvcPkZEv"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbcFdyH0l14q"
      },
      "outputs": [],
      "source": [
        "def dothing(x1_train, fids, fids_flat, i):\n",
        "    x1, fids_1, fids_2 = make_2d_mat(16)\n",
        "    print(\"yolo\")\n",
        "    # print(x1[0,:,:,:], fids_2[0,:])\n",
        "    # print(x1.shape, fids_1.shape)\n",
        "    fids.append(fids_1)\n",
        "    x1_train.append(x1)\n",
        "    fids_flat.append(fids_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V0O3e8E5l174",
        "outputId": "d61b1820-7b88-4e08-ca7b-58ccc826610e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-28:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-32df37c93b60>\", line 2, in dothing\n",
            "    x1, fids_1, fids_2 = make_2d_mat(16)\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 62, in make_2d_mat\n",
            "    ff = make_sine_combinations()\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 28, in make_sine_combinations\n",
            "    nSignals = random.randint(50,NSignals+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 222, in randint\n",
            "    return self.randrange(a, b+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 200, in randrange\n",
            "    raise ValueError(\"empty range for randrange() (%d,%d, %d)\" % (istart, istop, width))\n",
            "ValueError: empty range for randrange() (50,27, -23)\n",
            "\n",
            "Exception in thread Thread-29:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-32df37c93b60>\", line 2, in dothing\n",
            "    x1, fids_1, fids_2 = make_2d_mat(16)\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 62, in make_2d_mat\n",
            "    ff = make_sine_combinations()\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 28, in make_sine_combinations\n",
            "    nSignals = random.randint(50,NSignals+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 222, in randint\n",
            "    return self.randrange(a, b+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 200, in randrange\n",
            "    raise ValueError(\"empty range for randrange() (%d,%d, %d)\" % (istart, istop, width))\n",
            "ValueError: empty range for randrange() (50,27, -23)\n",
            "\n",
            "Exception in thread Thread-30:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-32df37c93b60>\", line 2, in dothing\n",
            "    x1, fids_1, fids_2 = make_2d_mat(16)\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 62, in make_2d_mat\n",
            "    ff = make_sine_combinations()\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 28, in make_sine_combinations\n",
            "    nSignals = random.randint(50,NSignals+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 222, in randint\n",
            "    return self.randrange(a, b+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 200, in randrange\n",
            "    raise ValueError(\"empty range for randrange() (%d,%d, %d)\" % (istart, istop, width))\n",
            "ValueError: empty range for randrange() (50,27, -23)\n",
            "\n",
            "Exception in thread Thread-31:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-32df37c93b60>\", line 2, in dothing\n",
            "    x1, fids_1, fids_2 = make_2d_mat(16)\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 62, in make_2d_mat\n",
            "    ff = make_sine_combinations()\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 28, in make_sine_combinations\n",
            "    nSignals = random.randint(50,NSignals+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 222, in randint\n",
            "    return self.randrange(a, b+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 200, in randrange\n",
            "    raise ValueError(\"empty range for randrange() (%d,%d, %d)\" % (istart, istop, width))\n",
            "ValueError: empty range for randrange() (50,27, -23)\n",
            "\n",
            "Exception in thread Thread-33:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-32df37c93b60>\", line 2, in dothing\n",
            "    x1, fids_1, fids_2 = make_2d_mat(16)\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 62, in make_2d_mat\n",
            "    ff = make_sine_combinations()\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 28, in make_sine_combinations\n",
            "    nSignals = random.randint(50,NSignals+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 222, in randint\n",
            "    return self.randrange(a, b+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 200, in randrange\n",
            "    raise ValueError(\"empty range for randrange() (%d,%d, %d)\" % (istart, istop, width))\n",
            "ValueError: empty range for randrange() (50,27, -23)\n",
            "\n",
            "Exception in thread Thread-32:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-32df37c93b60>\", line 2, in dothing\n",
            "    x1, fids_1, fids_2 = make_2d_mat(16)\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 62, in make_2d_mat\n",
            "    ff = make_sine_combinations()\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 28, in make_sine_combinations\n",
            "    nSignals = random.randint(50,NSignals+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 222, in randint\n",
            "    return self.randrange(a, b+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 200, in randrange\n",
            "    raise ValueError(\"empty range for randrange() (%d,%d, %d)\" % (istart, istop, width))\n",
            "ValueError: empty range for randrange() (50,27, -23)\n",
            "\n",
            "Exception in thread Thread-34:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-32df37c93b60>\", line 2, in dothing\n",
            "    x1, fids_1, fids_2 = make_2d_mat(16)\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 62, in make_2d_mat\n",
            "    ff = make_sine_combinations()\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 28, in make_sine_combinations\n",
            "    nSignals = random.randint(50,NSignals+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 222, in randint\n",
            "    return self.randrange(a, b+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 200, in randrange\n",
            "    raise ValueError(\"empty range for randrange() (%d,%d, %d)\" % (istart, istop, width))\n",
            "ValueError: empty range for randrange() (50,27, -23)\n",
            "\n",
            "Exception in thread Thread-35:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-32df37c93b60>\", line 2, in dothing\n",
            "    x1, fids_1, fids_2 = make_2d_mat(16)\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 62, in make_2d_mat\n",
            "    ff = make_sine_combinations()\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 28, in make_sine_combinations\n",
            "    nSignals = random.randint(50,NSignals+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 222, in randint\n",
            "    return self.randrange(a, b+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 200, in randrange\n",
            "    raise ValueError(\"empty range for randrange() (%d,%d, %d)\" % (istart, istop, width))\n",
            "ValueError: empty range for randrange() (50,27, -23)\n",
            "\n",
            "Exception in thread Thread-36:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-32df37c93b60>\", line 2, in dothing\n",
            "    x1, fids_1, fids_2 = make_2d_mat(16)\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 62, in make_2d_mat\n",
            "    ff = make_sine_combinations()\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 28, in make_sine_combinations\n",
            "    nSignals = random.randint(50,NSignals+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 222, in randint\n",
            "    return self.randrange(a, b+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 200, in randrange\n",
            "    raise ValueError(\"empty range for randrange() (%d,%d, %d)\" % (istart, istop, width))\n",
            "ValueError: empty range for randrange() (50,27, -23)\n",
            "\n",
            "Exception in thread Thread-37:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-32df37c93b60>\", line 2, in dothing\n",
            "    x1, fids_1, fids_2 = make_2d_mat(16)\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 62, in make_2d_mat\n",
            "    ff = make_sine_combinations()\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 28, in make_sine_combinations\n",
            "    nSignals = random.randint(50,NSignals+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 222, in randint\n",
            "    return self.randrange(a, b+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 200, in randrange\n",
            "    raise ValueError(\"empty range for randrange() (%d,%d, %d)\" % (istart, istop, width))\n",
            "ValueError: empty range for randrange() (50,27, -23)\n",
            "\n",
            "Exception in thread Thread-38:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-32df37c93b60>\", line 2, in dothing\n",
            "    x1, fids_1, fids_2 = make_2d_mat(16)\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 62, in make_2d_mat\n",
            "    ff = make_sine_combinations()\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 28, in make_sine_combinations\n",
            "    nSignals = random.randint(50,NSignals+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 222, in randint\n",
            "    return self.randrange(a, b+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 200, in randrange\n",
            "    raise ValueError(\"empty range for randrange() (%d,%d, %d)\" % (istart, istop, width))\n",
            "ValueError: empty range for randrange() (50,27, -23)\n",
            "\n",
            "Exception in thread Thread-40:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-32df37c93b60>\", line 2, in dothing\n",
            "    x1, fids_1, fids_2 = make_2d_mat(16)\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 62, in make_2d_mat\n",
            "    ff = make_sine_combinations()\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 28, in make_sine_combinations\n",
            "    nSignals = random.randint(50,NSignals+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 222, in randint\n",
            "    return self.randrange(a, b+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 200, in randrange\n",
            "    raise ValueError(\"empty range for randrange() (%d,%d, %d)\" % (istart, istop, width))\n",
            "ValueError: empty range for randrange() (50,27, -23)\n",
            "Exception in thread Thread-39:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-32df37c93b60>\", line 2, in dothing\n",
            "    x1, fids_1, fids_2 = make_2d_mat(16)\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 62, in make_2d_mat\n",
            "    ff = make_sine_combinations()\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 28, in make_sine_combinations\n",
            "    nSignals = random.randint(50,NSignals+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 222, in randint\n",
            "    return self.randrange(a, b+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 200, in randrange\n",
            "    raise ValueError(\"empty range for randrange() (%d,%d, %d)\" % (istart, istop, width))\n",
            "ValueError: empty range for randrange() (50,27, -23)\n",
            "\n",
            "\n",
            "Exception in thread Thread-42:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-32df37c93b60>\", line 2, in dothing\n",
            "    x1, fids_1, fids_2 = make_2d_mat(16)\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 62, in make_2d_mat\n",
            "    ff = make_sine_combinations()\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 28, in make_sine_combinations\n",
            "    nSignals = random.randint(50,NSignals+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 222, in randint\n",
            "    return self.randrange(a, b+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 200, in randrange\n",
            "    raise ValueError(\"empty range for randrange() (%d,%d, %d)\" % (istart, istop, width))\n",
            "ValueError: empty range for randrange() (50,27, -23)\n",
            "Exception in thread Thread-41:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-32df37c93b60>\", line 2, in dothing\n",
            "    x1, fids_1, fids_2 = make_2d_mat(16)\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 62, in make_2d_mat\n",
            "    ff = make_sine_combinations()\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 28, in make_sine_combinations\n",
            "    nSignals = random.randint(50,NSignals+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 222, in randint\n",
            "    return self.randrange(a, b+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 200, in randrange\n",
            "    raise ValueError(\"empty range for randrange() (%d,%d, %d)\" % (istart, istop, width))\n",
            "ValueError: empty range for randrange() (50,27, -23)\n",
            "\n",
            "\n",
            "Exception in thread Thread-43:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-9-32df37c93b60>\", line 2, in dothing\n",
            "    x1, fids_1, fids_2 = make_2d_mat(16)\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 62, in make_2d_mat\n",
            "    ff = make_sine_combinations()\n",
            "  File \"<ipython-input-6-aa03a4e7a277>\", line 28, in make_sine_combinations\n",
            "    nSignals = random.randint(50,NSignals+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 222, in randint\n",
            "    return self.randrange(a, b+1)\n",
            "  File \"/usr/lib/python3.7/random.py\", line 200, in randrange\n",
            "    raise ValueError(\"empty range for randrange() (%d,%d, %d)\" % (istart, istop, width))\n",
            "ValueError: empty range for randrange() (50,27, -23)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7921fb2caad5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mx1_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mfids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mfids_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfids_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
          ]
        }
      ],
      "source": [
        "num_threads = 16\n",
        "\n",
        "for n_datasets in range(100):\n",
        "    # print(n_datasets)\n",
        "    with Manager() as manager:\n",
        "        # L = manager.list()  # <-- can be shared between processes.\n",
        "        x1_train = manager.list()\n",
        "        fids = manager.list()\n",
        "        fids_flat = manager.list()\n",
        "        processes = []\n",
        "        for i in range(num_threads):\n",
        "            # p = Process(target=dothing, args=(x1_train, fids, fids_flat, i))  # Passing the list\n",
        "            p = threading.Thread(target=dothing, args=(x1_train, fids, fids_flat, i))\n",
        "            # print(p)\n",
        "            # processes.append(p)\n",
        "            p.start()\n",
        "            processes.append(p)\n",
        "        for p in processes:\n",
        "            p.join()\n",
        "        x1_train = np.vstack(x1_train)\n",
        "        fids = np.vstack(fids)\n",
        "        fids_flat = np.vstack(fids_flat)\n",
        "      \n",
        "    print(f\"This is the iteration number{n_datasets}\")\n",
        "    print(x1_train.shape, fids.shape)\n",
        "    print(x1_train[0,:,:], fids[0,:,:])\n",
        "\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x1_train, fids, test_size=0.2)\n",
        "\n",
        "    history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), batch_size=10)\n",
        "\n",
        "    loss = np.log10(history.history[\"loss\"])\n",
        "    val_loss = np.log10(history.history['val_loss'])\n",
        "    epochs = range(1, len(loss) + 1)\n",
        "    plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    print(loss)\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    plt.plot(epochs, acc, 'y', label='Training acc')\n",
        "    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    del x1_train, fids, fids_flat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGbMufwgl1-1",
        "outputId": "cc11dd62-0480-4ff5-ec7e-f97687897457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uKF1itnl4wj",
        "outputId": "1dea7a46-db29-47b9-f7ee-3da681ef96e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.getcwd()\n",
        "\n",
        "os.chdir('drive')\n",
        "\n",
        "os.chdir('MyDrive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaLFDyDFl7OY",
        "outputId": "561cab9e-56e1-4f3b-9617-0245a767d005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'120100094 - 1.pdf'\n",
            " \u001b[0m\u001b[01;34m3Dexpts\u001b[0m/\n",
            "'Aadhar and Gas Connection Bill.pdf'\n",
            " Abhishek_Kumar_02.pdf\n",
            " Abhishek_Kumar_Blank_Template-18.pdf\n",
            "'Abhishek_Kumar_CDS (1).pdf'\n",
            "'Abhishek_Kumar_CDS (2).pdf'\n",
            " Abhishek_Kumar_CDS.pdf\n",
            "'Abhishek_Kumar_Resume (1).pdf'\n",
            " Abhishek_Kumar_resume.pdf\n",
            " Abhishek_Kumar_Resume.pdf\n",
            "'abhishek one page 1.pdf'\n",
            "'BPCL Resume_Part A_Engineers.DOCX'\n",
            "'BPCL Resume_Part A_Engineers.DOCX.gdoc'\n",
            "\u001b[01;34m'Colab Notebooks'\u001b[0m/\n",
            "\u001b[01;36m'Copy of hnco_3d'\u001b[0m@\n",
            " \u001b[01;34mDAV\u001b[0m/\n",
            " EDHRN_3D.h5\n",
            " Event.gsite\n",
            "\u001b[01;34m'Forms for use.GT(M)'\u001b[0m/\n",
            "'Forms for use.GT(M).rar'\n",
            " \u001b[01;34mhncacb_3d\u001b[0m/\n",
            " \u001b[01;34mhncaco_3d\u001b[0m/\n",
            " \u001b[01;36mhnco_3d\u001b[0m@\n",
            " \u001b[01;34mhnco_3d_1\u001b[0m/\n",
            " \u001b[01;34mhnco_3d_h\u001b[0m/\n",
            " \u001b[01;34mhncocacb_3d\u001b[0m/\n",
            "'IISc_Abhishek_Kumar_CDS (1).pdf'\n",
            "'IISc_Abhishek_Kumar_CDS (2).pdf'\n",
            "'IISc_Abhishek_Kumar_CDS (3).pdf'\n",
            "'IISc_Abhishek_Kumar_CDS (4).pdf'\n",
            " IISc_Abhishek_Kumar_CDS.pdf\n",
            " IISC_ID.pdf\n",
            " Introduction_to_RBMs.pdf\n",
            " lec1-handout.pdf\n",
            " lec25-handout.pdf\n",
            "\"Master's_Project_Abstarct.docx\"\n",
            " model_plot.png\n",
            "'New Doc 5_5.pdf'\n",
            "\u001b[01;34m'Night drive'\u001b[0m/\n",
            "\u001b[01;34m'pawna lake camping'\u001b[0m/\n",
            " Portfolio.gsite\n",
            "'proposal(17830_&_18208).pdf'\n",
            " proposal.pdf\n",
            " rec_spec.mat\n",
            "'Relieving Formalities   RESIGNATION - MR.ABHISHEK KUMAR (22146) MANAGEMENT TRAINEE MYSURU DEPOT. .msg'\n",
            " \u001b[01;34mresume\u001b[0m/\n",
            " \u001b[01;34msaved_model\u001b[0m/\n",
            " \u001b[01;34msaved_model_01\u001b[0m/\n",
            " \u001b[01;34msaved_model_1\u001b[0m/\n",
            " \u001b[01;34msaved_model_10\u001b[0m/\n",
            " \u001b[01;34msaved_model_10_1\u001b[0m/\n",
            " \u001b[01;34msaved_model_12\u001b[0m/\n",
            " \u001b[01;34msaved_model_ud_12\u001b[0m/\n",
            " \u001b[01;34msaved_model_ud_12_f\u001b[0m/\n",
            " \u001b[01;34msaved_model_ud_12_ff\u001b[0m/\n",
            " \u001b[01;34msaved_model_ud_12_final\u001b[0m/\n",
            " \u001b[01;34msaved_model_ud_25\u001b[0m/\n",
            " \u001b[01;34msaved_model_ud_25_1\u001b[0m/\n",
            " \u001b[01;34msaved_model_ud_25_f\u001b[0m/\n",
            " \u001b[01;34msaved_model_unet_25\u001b[0m/\n",
            " \u001b[01;34msaved_model_unet_25_1\u001b[0m/\n",
            " Scan_20190927_151104_001.jpg\n",
            " Scheduler_10.xlsx\n",
            " Scheduler_125.xlsx\n",
            " Scheduler_128x64.xlsx\n",
            " Scheduler_12.xlsx\n",
            " Scheduler_1.xlsx\n",
            " Scheduler.xlsx\n",
            "\u001b[01;34m'sk Mondal '\u001b[0m/\n",
            "'[Solutions Manual] Mechanics Of Materials - (3Rd Ed , By Beer, Johnston, & Dewolf).pdf'\n",
            "'Student Portfolio.gsite'\n",
            "'System for monitoring moving threads in textile machinery.gdoc'\n",
            " undersampled_Azurin.mat\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUFOKWL-EZu9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDpGo0nsDXwH"
      },
      "outputs": [],
      "source": [
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return NMSE(y_true, y_pred)\n",
        "\n",
        "def NMSE(y_true, y_pred):\n",
        "    a = K.sqrt(K.sum(K.square(y_true - y_pred)))\n",
        "    b = K.sqrt(K.sum(K.square(y_true)))\n",
        "    return a / b\n",
        "model = tf.keras.models.load_model(os.path.join( \"EDHRN_3D.h5\"), custom_objects={'bce_dice_loss':bce_dice_loss, 'NMSE':NMSE})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JDLbPZDl9fm"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOMBoC7OmqYl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "7da87322-28f2-4ea3-f105-2396485664c0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-48fdc14437de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved_model_1/my_model_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'No file or directory found at {filepath_str}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at saved_model_1/my_model_1"
          ]
        }
      ],
      "source": [
        "new_model = tf.keras.models.load_model('saved_model_1/my_model_1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPoMtsiHm05W",
        "outputId": "0a878729-7201-4b7f-9277-9211dd269618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 128, 32, 1)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 128, 32, 64)  1664        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 32, 64)  0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 128, 32, 64)  256        ['max_pooling2d[0][0]']          \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " tf.math.tanh (TFOpLambda)      (None, 128, 32, 64)  0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 128, 32, 128  8320        ['tf.math.tanh[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 128, 32, 128  512        ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_1 (TFOpLambda)    (None, 128, 32, 128  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 32, 32)  36896       ['tf.math.tanh_1[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 128, 32, 96)  0           ['max_pooling2d[0][0]',          \n",
            "                                                                  'conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 128, 32, 96)  384        ['concatenate[0][0]']            \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.math.tanh_2 (TFOpLambda)    (None, 128, 32, 96)  0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 32, 128  12416       ['tf.math.tanh_2[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 128, 32, 128  512        ['conv2d_3[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_3 (TFOpLambda)    (None, 128, 32, 128  0           ['batch_normalization_3[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 128, 32, 32)  36896       ['tf.math.tanh_3[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 128, 32, 128  0           ['concatenate[0][0]',            \n",
            "                                )                                 'conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 128, 32, 128  512        ['concatenate_1[0][0]']          \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_4 (TFOpLambda)    (None, 128, 32, 128  0           ['batch_normalization_4[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 128, 32, 128  16512       ['tf.math.tanh_4[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 128, 32, 128  512        ['conv2d_5[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_5 (TFOpLambda)    (None, 128, 32, 128  0           ['batch_normalization_5[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 128, 32, 32)  36896       ['tf.math.tanh_5[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 128, 32, 160  0           ['concatenate_1[0][0]',          \n",
            "                                )                                 'conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 128, 32, 160  640        ['concatenate_2[0][0]']          \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_6 (TFOpLambda)    (None, 128, 32, 160  0           ['batch_normalization_6[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 128, 32, 128  20608       ['tf.math.tanh_6[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 128, 32, 128  512        ['conv2d_7[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_7 (TFOpLambda)    (None, 128, 32, 128  0           ['batch_normalization_7[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 128, 32, 32)  36896       ['tf.math.tanh_7[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 128, 32, 192  0           ['concatenate_2[0][0]',          \n",
            "                                )                                 'conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 128, 32, 192  768        ['concatenate_3[0][0]']          \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_8 (TFOpLambda)    (None, 128, 32, 192  0           ['batch_normalization_8[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 128, 32, 128  24704       ['tf.math.tanh_8[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 128, 32, 128  512        ['conv2d_9[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_9 (TFOpLambda)    (None, 128, 32, 128  0           ['batch_normalization_9[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_9[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 128, 32, 224  0           ['concatenate_3[0][0]',          \n",
            "                                )                                 'conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 128, 32, 224  896        ['concatenate_4[0][0]']          \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_10 (TFOpLambda)   (None, 128, 32, 224  0           ['batch_normalization_10[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 128, 32, 128  28800       ['tf.math.tanh_10[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 128, 32, 128  512        ['conv2d_11[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_11 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_11[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_11[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 128, 32, 256  0           ['concatenate_4[0][0]',          \n",
            "                                )                                 'conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 128, 32, 256  1024       ['concatenate_5[0][0]']          \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_12 (TFOpLambda)   (None, 128, 32, 256  0           ['batch_normalization_12[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 128, 32, 128  32896       ['tf.math.tanh_12[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 128, 32, 128  0          ['conv2d_13[0][0]']              \n",
            " ing2D)                         )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 128, 32, 128  512        ['average_pooling2d[0][0]']      \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_13 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_13[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 128, 32, 128  16512       ['tf.math.tanh_13[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 128, 32, 128  512        ['conv2d_14[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_14 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_14[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_14[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 128, 32, 160  0           ['average_pooling2d[0][0]',      \n",
            "                                )                                 'conv2d_15[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 128, 32, 160  640        ['concatenate_6[0][0]']          \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_15 (TFOpLambda)   (None, 128, 32, 160  0           ['batch_normalization_15[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 128, 32, 128  20608       ['tf.math.tanh_15[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 128, 32, 128  512        ['conv2d_16[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_16 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_16[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_16[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 128, 32, 192  0           ['concatenate_6[0][0]',          \n",
            "                                )                                 'conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 128, 32, 192  768        ['concatenate_7[0][0]']          \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_17 (TFOpLambda)   (None, 128, 32, 192  0           ['batch_normalization_17[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 128, 32, 128  24704       ['tf.math.tanh_17[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 128, 32, 128  512        ['conv2d_18[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_18 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_18[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_18[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 128, 32, 224  0           ['concatenate_7[0][0]',          \n",
            "                                )                                 'conv2d_19[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 128, 32, 224  896        ['concatenate_8[0][0]']          \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_19 (TFOpLambda)   (None, 128, 32, 224  0           ['batch_normalization_19[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 128, 32, 128  28800       ['tf.math.tanh_19[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 128, 32, 128  512        ['conv2d_20[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_20 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_20[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_20[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 128, 32, 256  0           ['concatenate_8[0][0]',          \n",
            "                                )                                 'conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 128, 32, 256  1024       ['concatenate_9[0][0]']          \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_21 (TFOpLambda)   (None, 128, 32, 256  0           ['batch_normalization_21[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 128, 32, 128  32896       ['tf.math.tanh_21[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 128, 32, 128  512        ['conv2d_22[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_22 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_22[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_22[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 128, 32, 288  0           ['concatenate_9[0][0]',          \n",
            "                                )                                 'conv2d_23[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 128, 32, 288  1152       ['concatenate_10[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_23 (TFOpLambda)   (None, 128, 32, 288  0           ['batch_normalization_23[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 128, 32, 128  36992       ['tf.math.tanh_23[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 128, 32, 128  512        ['conv2d_24[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_24 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_24[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_24[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenate)   (None, 128, 32, 320  0           ['concatenate_10[0][0]',         \n",
            "                                )                                 'conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 128, 32, 320  1280       ['concatenate_11[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_25 (TFOpLambda)   (None, 128, 32, 320  0           ['batch_normalization_25[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 128, 32, 128  41088       ['tf.math.tanh_25[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 128, 32, 128  512        ['conv2d_26[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_26 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_26[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_26[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenate)   (None, 128, 32, 352  0           ['concatenate_11[0][0]',         \n",
            "                                )                                 'conv2d_27[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 128, 32, 352  1408       ['concatenate_12[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_27 (TFOpLambda)   (None, 128, 32, 352  0           ['batch_normalization_27[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 128, 32, 128  45184       ['tf.math.tanh_27[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 128, 32, 128  512        ['conv2d_28[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_28 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_28[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_28[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenate)   (None, 128, 32, 384  0           ['concatenate_12[0][0]',         \n",
            "                                )                                 'conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 128, 32, 384  1536       ['concatenate_13[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_29 (TFOpLambda)   (None, 128, 32, 384  0           ['batch_normalization_29[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 128, 32, 128  49280       ['tf.math.tanh_29[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 128, 32, 128  512        ['conv2d_30[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_30 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_30[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_30[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenate)   (None, 128, 32, 416  0           ['concatenate_13[0][0]',         \n",
            "                                )                                 'conv2d_31[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 128, 32, 416  1664       ['concatenate_14[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_31 (TFOpLambda)   (None, 128, 32, 416  0           ['batch_normalization_31[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 128, 32, 128  53376       ['tf.math.tanh_31[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 128, 32, 128  512        ['conv2d_32[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_32 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_32[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_32[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenate)   (None, 128, 32, 448  0           ['concatenate_14[0][0]',         \n",
            "                                )                                 'conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 128, 32, 448  1792       ['concatenate_15[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_33 (TFOpLambda)   (None, 128, 32, 448  0           ['batch_normalization_33[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 128, 32, 128  57472       ['tf.math.tanh_33[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 128, 32, 128  512        ['conv2d_34[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_34 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_34[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_34[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_16 (Concatenate)   (None, 128, 32, 480  0           ['concatenate_15[0][0]',         \n",
            "                                )                                 'conv2d_35[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 128, 32, 480  1920       ['concatenate_16[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_35 (TFOpLambda)   (None, 128, 32, 480  0           ['batch_normalization_35[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 128, 32, 128  61568       ['tf.math.tanh_35[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 128, 32, 128  512        ['conv2d_36[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_36 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_36[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_36[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_17 (Concatenate)   (None, 128, 32, 512  0           ['concatenate_16[0][0]',         \n",
            "                                )                                 'conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 128, 32, 512  2048       ['concatenate_17[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_37 (TFOpLambda)   (None, 128, 32, 512  0           ['batch_normalization_37[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 128, 32, 256  131328      ['tf.math.tanh_37[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 128, 32, 256  0          ['conv2d_38[0][0]']              \n",
            " oling2D)                       )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 128, 32, 256  1024       ['average_pooling2d_1[0][0]']    \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_38 (TFOpLambda)   (None, 128, 32, 256  0           ['batch_normalization_38[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 128, 32, 128  32896       ['tf.math.tanh_38[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 128, 32, 128  512        ['conv2d_39[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_39 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_39[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_39[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_18 (Concatenate)   (None, 128, 32, 288  0           ['average_pooling2d_1[0][0]',    \n",
            "                                )                                 'conv2d_40[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 128, 32, 288  1152       ['concatenate_18[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_40 (TFOpLambda)   (None, 128, 32, 288  0           ['batch_normalization_40[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 128, 32, 128  36992       ['tf.math.tanh_40[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 128, 32, 128  512        ['conv2d_41[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_41 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_41[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_41[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_19 (Concatenate)   (None, 128, 32, 320  0           ['concatenate_18[0][0]',         \n",
            "                                )                                 'conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 128, 32, 320  1280       ['concatenate_19[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_42 (TFOpLambda)   (None, 128, 32, 320  0           ['batch_normalization_42[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 128, 32, 128  41088       ['tf.math.tanh_42[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 128, 32, 128  512        ['conv2d_43[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_43 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_43[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_43[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_20 (Concatenate)   (None, 128, 32, 352  0           ['concatenate_19[0][0]',         \n",
            "                                )                                 'conv2d_44[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 128, 32, 352  1408       ['concatenate_20[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_44 (TFOpLambda)   (None, 128, 32, 352  0           ['batch_normalization_44[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 128, 32, 128  45184       ['tf.math.tanh_44[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 128, 32, 128  512        ['conv2d_45[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_45 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_45[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_45[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_21 (Concatenate)   (None, 128, 32, 384  0           ['concatenate_20[0][0]',         \n",
            "                                )                                 'conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 128, 32, 384  1536       ['concatenate_21[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_46 (TFOpLambda)   (None, 128, 32, 384  0           ['batch_normalization_46[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 128, 32, 128  49280       ['tf.math.tanh_46[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 128, 32, 128  512        ['conv2d_47[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_47 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_47[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_47[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_22 (Concatenate)   (None, 128, 32, 416  0           ['concatenate_21[0][0]',         \n",
            "                                )                                 'conv2d_48[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 128, 32, 416  1664       ['concatenate_22[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_48 (TFOpLambda)   (None, 128, 32, 416  0           ['batch_normalization_48[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 128, 32, 128  53376       ['tf.math.tanh_48[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 128, 32, 128  512        ['conv2d_49[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_49 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_49[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_49[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_23 (Concatenate)   (None, 128, 32, 448  0           ['concatenate_22[0][0]',         \n",
            "                                )                                 'conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 128, 32, 448  1792       ['concatenate_23[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_50 (TFOpLambda)   (None, 128, 32, 448  0           ['batch_normalization_50[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 128, 32, 128  57472       ['tf.math.tanh_50[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 128, 32, 128  512        ['conv2d_51[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_51 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_51[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_51[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_24 (Concatenate)   (None, 128, 32, 480  0           ['concatenate_23[0][0]',         \n",
            "                                )                                 'conv2d_52[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 128, 32, 480  1920       ['concatenate_24[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_52 (TFOpLambda)   (None, 128, 32, 480  0           ['batch_normalization_52[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 128, 32, 128  61568       ['tf.math.tanh_52[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 128, 32, 128  512        ['conv2d_53[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_53 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_53[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_53[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_25 (Concatenate)   (None, 128, 32, 512  0           ['concatenate_24[0][0]',         \n",
            "                                )                                 'conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 128, 32, 512  2048       ['concatenate_25[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_54 (TFOpLambda)   (None, 128, 32, 512  0           ['batch_normalization_54[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 128, 32, 128  65664       ['tf.math.tanh_54[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 128, 32, 128  512        ['conv2d_55[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_55 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_55[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_55[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_26 (Concatenate)   (None, 128, 32, 544  0           ['concatenate_25[0][0]',         \n",
            "                                )                                 'conv2d_56[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 128, 32, 544  2176       ['concatenate_26[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_56 (TFOpLambda)   (None, 128, 32, 544  0           ['batch_normalization_56[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 128, 32, 128  69760       ['tf.math.tanh_56[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 128, 32, 128  512        ['conv2d_57[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_57 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_57[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_57[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_27 (Concatenate)   (None, 128, 32, 576  0           ['concatenate_26[0][0]',         \n",
            "                                )                                 'conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 128, 32, 576  2304       ['concatenate_27[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_58 (TFOpLambda)   (None, 128, 32, 576  0           ['batch_normalization_58[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 128, 32, 128  73856       ['tf.math.tanh_58[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 128, 32, 128  512        ['conv2d_59[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_59 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_59[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_59[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_28 (Concatenate)   (None, 128, 32, 608  0           ['concatenate_27[0][0]',         \n",
            "                                )                                 'conv2d_60[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 128, 32, 608  2432       ['concatenate_28[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_60 (TFOpLambda)   (None, 128, 32, 608  0           ['batch_normalization_60[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 128, 32, 128  77952       ['tf.math.tanh_60[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 128, 32, 128  512        ['conv2d_61[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_61 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_61[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_61[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_29 (Concatenate)   (None, 128, 32, 640  0           ['concatenate_28[0][0]',         \n",
            "                                )                                 'conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 128, 32, 640  2560       ['concatenate_29[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_62 (TFOpLambda)   (None, 128, 32, 640  0           ['batch_normalization_62[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 128, 32, 128  82048       ['tf.math.tanh_62[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 128, 32, 128  512        ['conv2d_63[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_63 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_63[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_63[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_30 (Concatenate)   (None, 128, 32, 672  0           ['concatenate_29[0][0]',         \n",
            "                                )                                 'conv2d_64[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 128, 32, 672  2688       ['concatenate_30[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_64 (TFOpLambda)   (None, 128, 32, 672  0           ['batch_normalization_64[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 128, 32, 128  86144       ['tf.math.tanh_64[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 128, 32, 128  512        ['conv2d_65[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_65 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_65[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_65[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_31 (Concatenate)   (None, 128, 32, 704  0           ['concatenate_30[0][0]',         \n",
            "                                )                                 'conv2d_66[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 128, 32, 704  2816       ['concatenate_31[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_66 (TFOpLambda)   (None, 128, 32, 704  0           ['batch_normalization_66[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 128, 32, 128  90240       ['tf.math.tanh_66[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 128, 32, 128  512        ['conv2d_67[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_67 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_67[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_67[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_32 (Concatenate)   (None, 128, 32, 736  0           ['concatenate_31[0][0]',         \n",
            "                                )                                 'conv2d_68[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 128, 32, 736  2944       ['concatenate_32[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_68 (TFOpLambda)   (None, 128, 32, 736  0           ['batch_normalization_68[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 128, 32, 128  94336       ['tf.math.tanh_68[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 128, 32, 128  512        ['conv2d_69[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_69 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_69[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_69[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_33 (Concatenate)   (None, 128, 32, 768  0           ['concatenate_32[0][0]',         \n",
            "                                )                                 'conv2d_70[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 128, 32, 768  3072       ['concatenate_33[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_70 (TFOpLambda)   (None, 128, 32, 768  0           ['batch_normalization_70[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 128, 32, 128  98432       ['tf.math.tanh_70[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 128, 32, 128  512        ['conv2d_71[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_71 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_71[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_71[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_34 (Concatenate)   (None, 128, 32, 800  0           ['concatenate_33[0][0]',         \n",
            "                                )                                 'conv2d_72[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 128, 32, 800  3200       ['concatenate_34[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_72 (TFOpLambda)   (None, 128, 32, 800  0           ['batch_normalization_72[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 128, 32, 128  102528      ['tf.math.tanh_72[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 128, 32, 128  512        ['conv2d_73[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_73 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_73[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_73[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_35 (Concatenate)   (None, 128, 32, 832  0           ['concatenate_34[0][0]',         \n",
            "                                )                                 'conv2d_74[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 128, 32, 832  3328       ['concatenate_35[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_74 (TFOpLambda)   (None, 128, 32, 832  0           ['batch_normalization_74[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 128, 32, 128  106624      ['tf.math.tanh_74[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 128, 32, 128  512        ['conv2d_75[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_75 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_75[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_75[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_36 (Concatenate)   (None, 128, 32, 864  0           ['concatenate_35[0][0]',         \n",
            "                                )                                 'conv2d_76[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 128, 32, 864  3456       ['concatenate_36[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_76 (TFOpLambda)   (None, 128, 32, 864  0           ['batch_normalization_76[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 128, 32, 128  110720      ['tf.math.tanh_76[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 128, 32, 128  512        ['conv2d_77[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_77 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_77[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_77[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_37 (Concatenate)   (None, 128, 32, 896  0           ['concatenate_36[0][0]',         \n",
            "                                )                                 'conv2d_78[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 128, 32, 896  3584       ['concatenate_37[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_78 (TFOpLambda)   (None, 128, 32, 896  0           ['batch_normalization_78[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 128, 32, 128  114816      ['tf.math.tanh_78[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 128, 32, 128  512        ['conv2d_79[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_79 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_79[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_79[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_38 (Concatenate)   (None, 128, 32, 928  0           ['concatenate_37[0][0]',         \n",
            "                                )                                 'conv2d_80[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 128, 32, 928  3712       ['concatenate_38[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_80 (TFOpLambda)   (None, 128, 32, 928  0           ['batch_normalization_80[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 128, 32, 128  118912      ['tf.math.tanh_80[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 128, 32, 128  512        ['conv2d_81[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_81 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_81[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_81[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_39 (Concatenate)   (None, 128, 32, 960  0           ['concatenate_38[0][0]',         \n",
            "                                )                                 'conv2d_82[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 128, 32, 960  3840       ['concatenate_39[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_82 (TFOpLambda)   (None, 128, 32, 960  0           ['batch_normalization_82[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 128, 32, 128  123008      ['tf.math.tanh_82[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 128, 32, 128  512        ['conv2d_83[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_83 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_83[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_83[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_40 (Concatenate)   (None, 128, 32, 992  0           ['concatenate_39[0][0]',         \n",
            "                                )                                 'conv2d_84[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 128, 32, 992  3968       ['concatenate_40[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_84 (TFOpLambda)   (None, 128, 32, 992  0           ['batch_normalization_84[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 128, 32, 128  127104      ['tf.math.tanh_84[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 128, 32, 128  512        ['conv2d_85[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_85 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_85[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_85[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_41 (Concatenate)   (None, 128, 32, 102  0           ['concatenate_40[0][0]',         \n",
            "                                4)                                'conv2d_86[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 128, 32, 102  4096       ['concatenate_41[0][0]']         \n",
            " ormalization)                  4)                                                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_86 (TFOpLambda)   (None, 128, 32, 102  0           ['batch_normalization_86[0][0]'] \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 128, 32, 512  524800      ['tf.math.tanh_86[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 128, 32, 512  0          ['conv2d_87[0][0]']              \n",
            " oling2D)                       )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 128, 32, 512  2048       ['average_pooling2d_2[0][0]']    \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_87 (TFOpLambda)   (None, 128, 32, 512  0           ['batch_normalization_87[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 128, 32, 128  65664       ['tf.math.tanh_87[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 128, 32, 128  512        ['conv2d_88[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_88 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_88[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_88[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_42 (Concatenate)   (None, 128, 32, 544  0           ['average_pooling2d_2[0][0]',    \n",
            "                                )                                 'conv2d_89[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 128, 32, 544  2176       ['concatenate_42[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_89 (TFOpLambda)   (None, 128, 32, 544  0           ['batch_normalization_89[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 128, 32, 128  69760       ['tf.math.tanh_89[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 128, 32, 128  512        ['conv2d_90[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_90 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_90[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_90[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_43 (Concatenate)   (None, 128, 32, 576  0           ['concatenate_42[0][0]',         \n",
            "                                )                                 'conv2d_91[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 128, 32, 576  2304       ['concatenate_43[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_91 (TFOpLambda)   (None, 128, 32, 576  0           ['batch_normalization_91[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 128, 32, 128  73856       ['tf.math.tanh_91[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 128, 32, 128  512        ['conv2d_92[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_92 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_92[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_92[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_44 (Concatenate)   (None, 128, 32, 608  0           ['concatenate_43[0][0]',         \n",
            "                                )                                 'conv2d_93[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 128, 32, 608  2432       ['concatenate_44[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_93 (TFOpLambda)   (None, 128, 32, 608  0           ['batch_normalization_93[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 128, 32, 128  77952       ['tf.math.tanh_93[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_94 (BatchN  (None, 128, 32, 128  512        ['conv2d_94[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_94 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_94[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_94[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_45 (Concatenate)   (None, 128, 32, 640  0           ['concatenate_44[0][0]',         \n",
            "                                )                                 'conv2d_95[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_95 (BatchN  (None, 128, 32, 640  2560       ['concatenate_45[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_95 (TFOpLambda)   (None, 128, 32, 640  0           ['batch_normalization_95[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 128, 32, 128  82048       ['tf.math.tanh_95[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_96 (BatchN  (None, 128, 32, 128  512        ['conv2d_96[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_96 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_96[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_96[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_46 (Concatenate)   (None, 128, 32, 672  0           ['concatenate_45[0][0]',         \n",
            "                                )                                 'conv2d_97[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_97 (BatchN  (None, 128, 32, 672  2688       ['concatenate_46[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_97 (TFOpLambda)   (None, 128, 32, 672  0           ['batch_normalization_97[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 128, 32, 128  86144       ['tf.math.tanh_97[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_98 (BatchN  (None, 128, 32, 128  512        ['conv2d_98[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_98 (TFOpLambda)   (None, 128, 32, 128  0           ['batch_normalization_98[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, 128, 32, 32)  36896       ['tf.math.tanh_98[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_47 (Concatenate)   (None, 128, 32, 704  0           ['concatenate_46[0][0]',         \n",
            "                                )                                 'conv2d_99[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_99 (BatchN  (None, 128, 32, 704  2816       ['concatenate_47[0][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_99 (TFOpLambda)   (None, 128, 32, 704  0           ['batch_normalization_99[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, 128, 32, 128  90240       ['tf.math.tanh_99[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_100 (Batch  (None, 128, 32, 128  512        ['conv2d_100[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_100 (TFOpLambda)  (None, 128, 32, 128  0           ['batch_normalization_100[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, 128, 32, 32)  36896       ['tf.math.tanh_100[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_48 (Concatenate)   (None, 128, 32, 736  0           ['concatenate_47[0][0]',         \n",
            "                                )                                 'conv2d_101[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_101 (Batch  (None, 128, 32, 736  2944       ['concatenate_48[0][0]']         \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_101 (TFOpLambda)  (None, 128, 32, 736  0           ['batch_normalization_101[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 128, 32, 128  94336       ['tf.math.tanh_101[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_102 (Batch  (None, 128, 32, 128  512        ['conv2d_102[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_102 (TFOpLambda)  (None, 128, 32, 128  0           ['batch_normalization_102[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, 128, 32, 32)  36896       ['tf.math.tanh_102[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_49 (Concatenate)   (None, 128, 32, 768  0           ['concatenate_48[0][0]',         \n",
            "                                )                                 'conv2d_103[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_103 (Batch  (None, 128, 32, 768  3072       ['concatenate_49[0][0]']         \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_103 (TFOpLambda)  (None, 128, 32, 768  0           ['batch_normalization_103[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)            (None, 128, 32, 128  98432       ['tf.math.tanh_103[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_104 (Batch  (None, 128, 32, 128  512        ['conv2d_104[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_104 (TFOpLambda)  (None, 128, 32, 128  0           ['batch_normalization_104[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)            (None, 128, 32, 32)  36896       ['tf.math.tanh_104[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_50 (Concatenate)   (None, 128, 32, 800  0           ['concatenate_49[0][0]',         \n",
            "                                )                                 'conv2d_105[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_105 (Batch  (None, 128, 32, 800  3200       ['concatenate_50[0][0]']         \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_105 (TFOpLambda)  (None, 128, 32, 800  0           ['batch_normalization_105[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)            (None, 128, 32, 128  102528      ['tf.math.tanh_105[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_106 (Batch  (None, 128, 32, 128  512        ['conv2d_106[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_106 (TFOpLambda)  (None, 128, 32, 128  0           ['batch_normalization_106[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)            (None, 128, 32, 32)  36896       ['tf.math.tanh_106[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_51 (Concatenate)   (None, 128, 32, 832  0           ['concatenate_50[0][0]',         \n",
            "                                )                                 'conv2d_107[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_107 (Batch  (None, 128, 32, 832  3328       ['concatenate_51[0][0]']         \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_107 (TFOpLambda)  (None, 128, 32, 832  0           ['batch_normalization_107[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)            (None, 128, 32, 128  106624      ['tf.math.tanh_107[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_108 (Batch  (None, 128, 32, 128  512        ['conv2d_108[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_108 (TFOpLambda)  (None, 128, 32, 128  0           ['batch_normalization_108[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)            (None, 128, 32, 32)  36896       ['tf.math.tanh_108[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_52 (Concatenate)   (None, 128, 32, 864  0           ['concatenate_51[0][0]',         \n",
            "                                )                                 'conv2d_109[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_109 (Batch  (None, 128, 32, 864  3456       ['concatenate_52[0][0]']         \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_109 (TFOpLambda)  (None, 128, 32, 864  0           ['batch_normalization_109[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)            (None, 128, 32, 128  110720      ['tf.math.tanh_109[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_110 (Batch  (None, 128, 32, 128  512        ['conv2d_110[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_110 (TFOpLambda)  (None, 128, 32, 128  0           ['batch_normalization_110[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)            (None, 128, 32, 32)  36896       ['tf.math.tanh_110[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_53 (Concatenate)   (None, 128, 32, 896  0           ['concatenate_52[0][0]',         \n",
            "                                )                                 'conv2d_111[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_111 (Batch  (None, 128, 32, 896  3584       ['concatenate_53[0][0]']         \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_111 (TFOpLambda)  (None, 128, 32, 896  0           ['batch_normalization_111[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)            (None, 128, 32, 128  114816      ['tf.math.tanh_111[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_112 (Batch  (None, 128, 32, 128  512        ['conv2d_112[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_112 (TFOpLambda)  (None, 128, 32, 128  0           ['batch_normalization_112[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (None, 128, 32, 32)  36896       ['tf.math.tanh_112[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_54 (Concatenate)   (None, 128, 32, 928  0           ['concatenate_53[0][0]',         \n",
            "                                )                                 'conv2d_113[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_113 (Batch  (None, 128, 32, 928  3712       ['concatenate_54[0][0]']         \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_113 (TFOpLambda)  (None, 128, 32, 928  0           ['batch_normalization_113[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)            (None, 128, 32, 128  118912      ['tf.math.tanh_113[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_114 (Batch  (None, 128, 32, 128  512        ['conv2d_114[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_114 (TFOpLambda)  (None, 128, 32, 128  0           ['batch_normalization_114[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)            (None, 128, 32, 32)  36896       ['tf.math.tanh_114[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_55 (Concatenate)   (None, 128, 32, 960  0           ['concatenate_54[0][0]',         \n",
            "                                )                                 'conv2d_115[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_115 (Batch  (None, 128, 32, 960  3840       ['concatenate_55[0][0]']         \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_115 (TFOpLambda)  (None, 128, 32, 960  0           ['batch_normalization_115[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)            (None, 128, 32, 128  123008      ['tf.math.tanh_115[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_116 (Batch  (None, 128, 32, 128  512        ['conv2d_116[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_116 (TFOpLambda)  (None, 128, 32, 128  0           ['batch_normalization_116[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)            (None, 128, 32, 32)  36896       ['tf.math.tanh_116[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_56 (Concatenate)   (None, 128, 32, 992  0           ['concatenate_55[0][0]',         \n",
            "                                )                                 'conv2d_117[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_117 (Batch  (None, 128, 32, 992  3968       ['concatenate_56[0][0]']         \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_117 (TFOpLambda)  (None, 128, 32, 992  0           ['batch_normalization_117[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_118 (Conv2D)            (None, 128, 32, 128  127104      ['tf.math.tanh_117[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_118 (Batch  (None, 128, 32, 128  512        ['conv2d_118[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.tanh_118 (TFOpLambda)  (None, 128, 32, 128  0           ['batch_normalization_118[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_119 (Conv2D)            (None, 128, 32, 32)  36896       ['tf.math.tanh_118[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_57 (Concatenate)   (None, 128, 32, 102  0           ['concatenate_56[0][0]',         \n",
            "                                4)                                'conv2d_119[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_121 (Conv2D)            (None, 128, 32, 1)   1025        ['concatenate_57[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,036,609\n",
            "Trainable params: 6,955,137\n",
            "Non-trainable params: 81,472\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "new_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRbIiDcsBdXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7f55ef2-d8fe-4951-9915-5f42e1b715ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " main_input (InputLayer)        [(None, 120, 120, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " separable_conv2d_1 (SeparableC  (None, 120, 120, 48  105        ['main_input[0][0]']             \n",
            " onv2D)                         )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 120, 120, 48  192        ['separable_conv2d_1[0][0]']     \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 120, 120, 48  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " BN_1_1_1 (BatchNormalization)  (None, 120, 120, 48  192         ['leaky_re_lu_1[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Conv_1_1_1 (SeparableConv2D)   (None, 118, 118, 48  2784        ['BN_1_1_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " lrelu_1_1_1 (LeakyReLU)        (None, 118, 118, 48  0           ['Conv_1_1_1[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " BN_1_1_2 (BatchNormalization)  (None, 118, 118, 48  192         ['lrelu_1_1_1[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Deconv_res1_1 (Conv2DTranspose  (None, 120, 120, 48  20784      ['BN_1_1_2[0][0]']               \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " lrelu_1_1_2 (LeakyReLU)        (None, 120, 120, 48  0           ['Deconv_res1_1[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 120, 120, 96  0           ['leaky_re_lu_1[0][0]',          \n",
            "                                )                                 'lrelu_1_1_2[0][0]']            \n",
            "                                                                                                  \n",
            " BN_1_1_3 (BatchNormalization)  (None, 120, 120, 96  384         ['concatenate_1[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Conv_1_1_2 (SeparableConv2D)   (None, 120, 120, 48  4752        ['BN_1_1_3[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " lrelu_1_1_3 (LeakyReLU)        (None, 120, 120, 48  0           ['Conv_1_1_2[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 120, 120, 48  192        ['lrelu_1_1_3[0][0]']            \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " Conv2_temp1 (Conv2D)           (None, 59, 59, 96)   41568       ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 59, 59, 96)   0           ['Conv2_temp1[0][0]']            \n",
            "                                                                                                  \n",
            " BN_2_1_1 (BatchNormalization)  (None, 59, 59, 96)   384         ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " Conv_2_1_1 (SeparableConv2D)   (None, 57, 57, 96)   10176       ['BN_2_1_1[0][0]']               \n",
            "                                                                                                  \n",
            " lrelu_2_1_1 (LeakyReLU)        (None, 57, 57, 96)   0           ['Conv_2_1_1[0][0]']             \n",
            "                                                                                                  \n",
            " BN_1_2_1 (BatchNormalization)  (None, 120, 120, 48  192         ['lrelu_1_1_3[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " BN_2_1_2 (BatchNormalization)  (None, 57, 57, 96)   384         ['lrelu_2_1_1[0][0]']            \n",
            "                                                                                                  \n",
            " Conv_1_2_1 (SeparableConv2D)   (None, 118, 118, 48  2784        ['BN_1_2_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Deconv_res2_1 (Conv2DTranspose  (None, 59, 59, 96)  83040       ['BN_2_1_2[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " lrelu_1_2_1 (LeakyReLU)        (None, 118, 118, 48  0           ['Conv_1_2_1[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " lrelu_2_1_2 (LeakyReLU)        (None, 59, 59, 96)   0           ['Deconv_res2_1[0][0]']          \n",
            "                                                                                                  \n",
            " BN_1_2_2 (BatchNormalization)  (None, 118, 118, 48  192         ['lrelu_1_2_1[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 59, 59, 192)  0           ['leaky_re_lu_2[0][0]',          \n",
            "                                                                  'lrelu_2_1_2[0][0]']            \n",
            "                                                                                                  \n",
            " Deconv_res1_2 (Conv2DTranspose  (None, 120, 120, 48  20784      ['BN_1_2_2[0][0]']               \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " BN_2_1_3 (BatchNormalization)  (None, 59, 59, 192)  768         ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " lrelu_1_2_2 (LeakyReLU)        (None, 120, 120, 48  0           ['Deconv_res1_2[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Conv_2_1_2 (SeparableConv2D)   (None, 59, 59, 96)   18720       ['BN_2_1_3[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 120, 120, 96  0           ['lrelu_1_1_3[0][0]',            \n",
            "                                )                                 'lrelu_1_2_2[0][0]']            \n",
            "                                                                                                  \n",
            " lrelu_2_1_3 (LeakyReLU)        (None, 59, 59, 96)   0           ['Conv_2_1_2[0][0]']             \n",
            "                                                                                                  \n",
            " BN_1_2_3 (BatchNormalization)  (None, 120, 120, 96  384         ['concatenate_2[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " BN_2_2_1 (BatchNormalization)  (None, 59, 59, 96)   384         ['lrelu_2_1_3[0][0]']            \n",
            "                                                                                                  \n",
            " Conv_1_2_2 (SeparableConv2D)   (None, 120, 120, 48  4752        ['BN_1_2_3[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Conv_2_2_1 (SeparableConv2D)   (None, 57, 57, 96)   10176       ['BN_2_2_1[0][0]']               \n",
            "                                                                                                  \n",
            " lrelu_1_2_3 (LeakyReLU)        (None, 120, 120, 48  0           ['Conv_1_2_2[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " lrelu_2_2_1 (LeakyReLU)        (None, 57, 57, 96)   0           ['Conv_2_2_1[0][0]']             \n",
            "                                                                                                  \n",
            " BN_1_3_1 (BatchNormalization)  (None, 120, 120, 48  192         ['lrelu_1_2_3[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " BN_2_2_2 (BatchNormalization)  (None, 57, 57, 96)   384         ['lrelu_2_2_1[0][0]']            \n",
            "                                                                                                  \n",
            " Conv_1_3_1 (SeparableConv2D)   (None, 118, 118, 48  2784        ['BN_1_3_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Deconv_res2_2 (Conv2DTranspose  (None, 59, 59, 96)  83040       ['BN_2_2_2[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " lrelu_1_3_1 (LeakyReLU)        (None, 118, 118, 48  0           ['Conv_1_3_1[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " lrelu_2_2_2 (LeakyReLU)        (None, 59, 59, 96)   0           ['Deconv_res2_2[0][0]']          \n",
            "                                                                                                  \n",
            " BN_1_3_2 (BatchNormalization)  (None, 118, 118, 48  192         ['lrelu_1_3_1[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 59, 59, 192)  0           ['lrelu_2_1_3[0][0]',            \n",
            "                                                                  'lrelu_2_2_2[0][0]']            \n",
            "                                                                                                  \n",
            " Deconv_res1_3 (Conv2DTranspose  (None, 120, 120, 48  20784      ['BN_1_3_2[0][0]']               \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " BN_2_2_3 (BatchNormalization)  (None, 59, 59, 192)  768         ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " lrelu_1_3_2 (LeakyReLU)        (None, 120, 120, 48  0           ['Deconv_res1_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Conv_2_2_2 (SeparableConv2D)   (None, 59, 59, 96)   18720       ['BN_2_2_3[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 120, 120, 96  0           ['lrelu_1_2_3[0][0]',            \n",
            "                                )                                 'lrelu_1_3_2[0][0]']            \n",
            "                                                                                                  \n",
            " lrelu_2_2_3 (LeakyReLU)        (None, 59, 59, 96)   0           ['Conv_2_2_2[0][0]']             \n",
            "                                                                                                  \n",
            " BN_1_3_3 (BatchNormalization)  (None, 120, 120, 96  384         ['concatenate_4[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " BN_up1 (BatchNormalization)    (None, 59, 59, 96)   384         ['lrelu_2_2_3[0][0]']            \n",
            "                                                                                                  \n",
            " Conv_1_3_2 (SeparableConv2D)   (None, 120, 120, 48  4752        ['BN_1_3_3[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Deconv_2_1_1 (Conv2DTranspose)  (None, 120, 120, 48  73776      ['BN_up1[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " lrelu_1_3_3 (LeakyReLU)        (None, 120, 120, 48  0           ['Conv_1_3_2[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 120, 120, 48  0           ['Deconv_2_1_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 120, 120, 48  0           ['lrelu_1_3_3[0][0]',            \n",
            "                                )                                 'leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 120, 120, 48  192        ['lrelu_1_3_3[0][0]']            \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " BN_1_4_1 (BatchNormalization)  (None, 120, 120, 48  192         ['add_1[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Conv2_temp2 (Conv2D)           (None, 59, 59, 96)   41568       ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " Conv_1_4_1 (SeparableConv2D)   (None, 118, 118, 48  2784        ['BN_1_4_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 59, 59, 96)   0           ['Conv2_temp2[0][0]']            \n",
            "                                                                                                  \n",
            " lrelu_1_4_1 (LeakyReLU)        (None, 118, 118, 48  0           ['Conv_1_4_1[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 59, 59, 96)   0           ['lrelu_2_2_3[0][0]',            \n",
            "                                                                  'leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " BN_1_4_2 (BatchNormalization)  (None, 118, 118, 48  192         ['lrelu_1_4_1[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " BN_2_3_1 (BatchNormalization)  (None, 59, 59, 96)   384         ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " Deconv_res1_4 (Conv2DTranspose  (None, 120, 120, 48  20784      ['BN_1_4_2[0][0]']               \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " Conv_2_3_1 (SeparableConv2D)   (None, 57, 57, 96)   10176       ['BN_2_3_1[0][0]']               \n",
            "                                                                                                  \n",
            " lrelu_1_4_2 (LeakyReLU)        (None, 120, 120, 48  0           ['Deconv_res1_4[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " lrelu_2_3_1 (LeakyReLU)        (None, 57, 57, 96)   0           ['Conv_2_3_1[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 120, 120, 96  0           ['add_1[0][0]',                  \n",
            "                                )                                 'lrelu_1_4_2[0][0]']            \n",
            "                                                                                                  \n",
            " BN_2_3_2 (BatchNormalization)  (None, 57, 57, 96)   384         ['lrelu_2_3_1[0][0]']            \n",
            "                                                                                                  \n",
            " BN_1_4_3 (BatchNormalization)  (None, 120, 120, 96  384         ['concatenate_6[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Deconv_res2_3 (Conv2DTranspose  (None, 59, 59, 96)  83040       ['BN_2_3_2[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " Conv_1_4_2 (SeparableConv2D)   (None, 120, 120, 48  4752        ['BN_1_4_3[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " lrelu_2_3_2 (LeakyReLU)        (None, 59, 59, 96)   0           ['Deconv_res2_3[0][0]']          \n",
            "                                                                                                  \n",
            " lrelu_1_4_3 (LeakyReLU)        (None, 120, 120, 48  0           ['Conv_1_4_2[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 59, 59, 192)  0           ['add_2[0][0]',                  \n",
            "                                                                  'lrelu_2_3_2[0][0]']            \n",
            "                                                                                                  \n",
            " BN_1_5_1 (BatchNormalization)  (None, 120, 120, 48  192         ['lrelu_1_4_3[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " BN_2_3_3 (BatchNormalization)  (None, 59, 59, 192)  768         ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " Conv_1_5_1 (SeparableConv2D)   (None, 118, 118, 48  2784        ['BN_1_5_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Conv_2_3_2 (SeparableConv2D)   (None, 59, 59, 96)   18720       ['BN_2_3_3[0][0]']               \n",
            "                                                                                                  \n",
            " lrelu_1_5_1 (LeakyReLU)        (None, 118, 118, 48  0           ['Conv_1_5_1[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " lrelu_2_3_3 (LeakyReLU)        (None, 59, 59, 96)   0           ['Conv_2_3_2[0][0]']             \n",
            "                                                                                                  \n",
            " BN_1_5_2 (BatchNormalization)  (None, 118, 118, 48  192         ['lrelu_1_5_1[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " BN_2_4_1 (BatchNormalization)  (None, 59, 59, 96)   384         ['lrelu_2_3_3[0][0]']            \n",
            "                                                                                                  \n",
            " Deconv_res1_5 (Conv2DTranspose  (None, 120, 120, 48  20784      ['BN_1_5_2[0][0]']               \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " Conv_2_4_1 (SeparableConv2D)   (None, 57, 57, 96)   10176       ['BN_2_4_1[0][0]']               \n",
            "                                                                                                  \n",
            " lrelu_1_5_2 (LeakyReLU)        (None, 120, 120, 48  0           ['Deconv_res1_5[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " lrelu_2_4_1 (LeakyReLU)        (None, 57, 57, 96)   0           ['Conv_2_4_1[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 120, 120, 96  0           ['lrelu_1_4_3[0][0]',            \n",
            "                                )                                 'lrelu_1_5_2[0][0]']            \n",
            "                                                                                                  \n",
            " BN_2_4_2 (BatchNormalization)  (None, 57, 57, 96)   384         ['lrelu_2_4_1[0][0]']            \n",
            "                                                                                                  \n",
            " BN_1_5_3 (BatchNormalization)  (None, 120, 120, 96  384         ['concatenate_8[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Deconv_res2_4 (Conv2DTranspose  (None, 59, 59, 96)  83040       ['BN_2_4_2[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " Conv_1_5_2 (SeparableConv2D)   (None, 120, 120, 48  4752        ['BN_1_5_3[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " lrelu_2_4_2 (LeakyReLU)        (None, 59, 59, 96)   0           ['Deconv_res2_4[0][0]']          \n",
            "                                                                                                  \n",
            " lrelu_1_5_3 (LeakyReLU)        (None, 120, 120, 48  0           ['Conv_1_5_2[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 59, 59, 192)  0           ['lrelu_2_3_3[0][0]',            \n",
            "                                                                  'lrelu_2_4_2[0][0]']            \n",
            "                                                                                                  \n",
            " BN_2_4_3 (BatchNormalization)  (None, 59, 59, 192)  768         ['concatenate_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 120, 120, 48  192        ['lrelu_1_5_3[0][0]']            \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " Conv_2_4_2 (SeparableConv2D)   (None, 59, 59, 96)   18720       ['BN_2_4_3[0][0]']               \n",
            "                                                                                                  \n",
            " Conv2_temp3 (Conv2D)           (None, 59, 59, 96)   41568       ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lrelu_2_4_3 (LeakyReLU)        (None, 59, 59, 96)   0           ['Conv_2_4_2[0][0]']             \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 59, 59, 96)   0           ['Conv2_temp3[0][0]']            \n",
            "                                                                                                  \n",
            " BN_up2 (BatchNormalization)    (None, 59, 59, 96)   384         ['lrelu_2_4_3[0][0]']            \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 59, 59, 96)   0           ['lrelu_2_4_3[0][0]',            \n",
            "                                                                  'leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            " Deconv_2_1_2 (Conv2DTranspose)  (None, 120, 120, 48  73776      ['BN_up2[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " BN_2_5_1 (BatchNormalization)  (None, 59, 59, 96)   384         ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 120, 120, 48  0           ['Deconv_2_1_2[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Conv_2_5_1 (SeparableConv2D)   (None, 57, 57, 96)   10176       ['BN_2_5_1[0][0]']               \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 120, 120, 48  0           ['lrelu_1_5_3[0][0]',            \n",
            "                                )                                 'leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " lrelu_2_5_1 (LeakyReLU)        (None, 57, 57, 96)   0           ['Conv_2_5_1[0][0]']             \n",
            "                                                                                                  \n",
            " BN_1_6_1 (BatchNormalization)  (None, 120, 120, 48  192         ['add_3[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " BN_2_5_2 (BatchNormalization)  (None, 57, 57, 96)   384         ['lrelu_2_5_1[0][0]']            \n",
            "                                                                                                  \n",
            " Conv_1_6_1 (SeparableConv2D)   (None, 118, 118, 48  2784        ['BN_1_6_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Deconv_res2_5 (Conv2DTranspose  (None, 59, 59, 96)  83040       ['BN_2_5_2[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " lrelu_1_6_1 (LeakyReLU)        (None, 118, 118, 48  0           ['Conv_1_6_1[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " lrelu_2_5_2 (LeakyReLU)        (None, 59, 59, 96)   0           ['Deconv_res2_5[0][0]']          \n",
            "                                                                                                  \n",
            " BN_1_6_2 (BatchNormalization)  (None, 118, 118, 48  192         ['lrelu_1_6_1[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenate)   (None, 59, 59, 192)  0           ['add_4[0][0]',                  \n",
            "                                                                  'lrelu_2_5_2[0][0]']            \n",
            "                                                                                                  \n",
            " Deconv_res1_6 (Conv2DTranspose  (None, 120, 120, 48  20784      ['BN_1_6_2[0][0]']               \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " BN_2_5_3 (BatchNormalization)  (None, 59, 59, 192)  768         ['concatenate_11[0][0]']         \n",
            "                                                                                                  \n",
            " lrelu_1_6_2 (LeakyReLU)        (None, 120, 120, 48  0           ['Deconv_res1_6[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Conv_2_5_2 (SeparableConv2D)   (None, 59, 59, 96)   18720       ['BN_2_5_3[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 120, 120, 96  0           ['add_3[0][0]',                  \n",
            "                                )                                 'lrelu_1_6_2[0][0]']            \n",
            "                                                                                                  \n",
            " lrelu_2_5_3 (LeakyReLU)        (None, 59, 59, 96)   0           ['Conv_2_5_2[0][0]']             \n",
            "                                                                                                  \n",
            " BN_1_6_3 (BatchNormalization)  (None, 120, 120, 96  384         ['concatenate_10[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " BN_2_6_1 (BatchNormalization)  (None, 59, 59, 96)   384         ['lrelu_2_5_3[0][0]']            \n",
            "                                                                                                  \n",
            " Conv_1_6_2 (SeparableConv2D)   (None, 120, 120, 48  4752        ['BN_1_6_3[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Conv_2_6_1 (SeparableConv2D)   (None, 57, 57, 96)   10176       ['BN_2_6_1[0][0]']               \n",
            "                                                                                                  \n",
            " lrelu_1_6_3 (LeakyReLU)        (None, 120, 120, 48  0           ['Conv_1_6_2[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " lrelu_2_6_1 (LeakyReLU)        (None, 57, 57, 96)   0           ['Conv_2_6_1[0][0]']             \n",
            "                                                                                                  \n",
            " BN_1_7_1 (BatchNormalization)  (None, 120, 120, 48  192         ['lrelu_1_6_3[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " BN_2_6_2 (BatchNormalization)  (None, 57, 57, 96)   384         ['lrelu_2_6_1[0][0]']            \n",
            "                                                                                                  \n",
            " Conv_1_7_1 (SeparableConv2D)   (None, 118, 118, 48  2784        ['BN_1_7_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Deconv_res2_6 (Conv2DTranspose  (None, 59, 59, 96)  83040       ['BN_2_6_2[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " lrelu_1_7_1 (LeakyReLU)        (None, 118, 118, 48  0           ['Conv_1_7_1[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " lrelu_2_6_2 (LeakyReLU)        (None, 59, 59, 96)   0           ['Deconv_res2_6[0][0]']          \n",
            "                                                                                                  \n",
            " BN_1_7_2 (BatchNormalization)  (None, 118, 118, 48  192         ['lrelu_1_7_1[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenate)   (None, 59, 59, 192)  0           ['lrelu_2_5_3[0][0]',            \n",
            "                                                                  'lrelu_2_6_2[0][0]']            \n",
            "                                                                                                  \n",
            " Deconv_res1_7 (Conv2DTranspose  (None, 120, 120, 48  20784      ['BN_1_7_2[0][0]']               \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " BN_2_6_3 (BatchNormalization)  (None, 59, 59, 192)  768         ['concatenate_13[0][0]']         \n",
            "                                                                                                  \n",
            " lrelu_1_7_2 (LeakyReLU)        (None, 120, 120, 48  0           ['Deconv_res1_7[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Conv_2_6_2 (SeparableConv2D)   (None, 59, 59, 96)   18720       ['BN_2_6_3[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenate)   (None, 120, 120, 96  0           ['lrelu_1_6_3[0][0]',            \n",
            "                                )                                 'lrelu_1_7_2[0][0]']            \n",
            "                                                                                                  \n",
            " lrelu_2_6_3 (LeakyReLU)        (None, 59, 59, 96)   0           ['Conv_2_6_2[0][0]']             \n",
            "                                                                                                  \n",
            " BN_1_7_3 (BatchNormalization)  (None, 120, 120, 96  384         ['concatenate_12[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " BN_up3 (BatchNormalization)    (None, 59, 59, 96)   384         ['lrelu_2_6_3[0][0]']            \n",
            "                                                                                                  \n",
            " Conv_1_7_2 (SeparableConv2D)   (None, 120, 120, 48  4752        ['BN_1_7_3[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Deconv_2_1_3 (Conv2DTranspose)  (None, 120, 120, 48  73776      ['BN_up3[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " lrelu_1_7_3 (LeakyReLU)        (None, 120, 120, 48  0           ['Conv_1_7_2[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 120, 120, 48  0           ['Deconv_2_1_3[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 120, 120, 48  0           ['lrelu_1_7_3[0][0]',            \n",
            "                                )                                 'leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " BN_1_8_1 (BatchNormalization)  (None, 120, 120, 48  192         ['add_5[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Conv_1_8_1 (SeparableConv2D)   (None, 118, 118, 48  2784        ['BN_1_8_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " lrelu_1_8_1 (LeakyReLU)        (None, 118, 118, 48  0           ['Conv_1_8_1[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " BN_1_8_2 (BatchNormalization)  (None, 118, 118, 48  192         ['lrelu_1_8_1[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Deconv_res1_8 (Conv2DTranspose  (None, 120, 120, 48  20784      ['BN_1_8_2[0][0]']               \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " lrelu_1_8_2 (LeakyReLU)        (None, 120, 120, 48  0           ['Deconv_res1_8[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenate)   (None, 120, 120, 96  0           ['add_5[0][0]',                  \n",
            "                                )                                 'lrelu_1_8_2[0][0]']            \n",
            "                                                                                                  \n",
            " BN_1_8_3 (BatchNormalization)  (None, 120, 120, 96  384         ['concatenate_14[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Conv_1_8_2 (SeparableConv2D)   (None, 120, 120, 48  4752        ['BN_1_8_3[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " lrelu_1_8_3 (LeakyReLU)        (None, 120, 120, 48  0           ['Conv_1_8_2[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " output (SeparableConv2D)       (None, 120, 120, 1)  481         ['lrelu_1_8_3[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,262,074\n",
            "Trainable params: 1,253,434\n",
            "Non-trainable params: 8,640\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yC2B-mgBTqv"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4ILjnmBnAYz"
      },
      "outputs": [],
      "source": [
        "def make_fid(freqs, freqs1, freqs2, r2s, ints, noise=False):\n",
        "    \n",
        "  retval=np.zeros( (NP, NP1, NP2) , dtype=np.complex)\n",
        "  \n",
        "  # Time samples\n",
        "  samp_time = np.linspace(0.,(NP-1.)/SW,NP)\n",
        "  samp_time1 = np.linspace(0.,(NP1-1.)/SW1,NP1)\n",
        "  samp_time2 = np.linspace(0.,(NP2-1.)/SW2,NP2)\n",
        "  \n",
        "  K = np.max([len(freqs), len(freqs2), len(freqs2), len(r2s), len(ints)])\n",
        "  for n in range(NP):\n",
        "    for n1 in range(NP1):\n",
        "      for n2 in range(NP2):\n",
        "        val = 0.\n",
        "        for s in range(K):\n",
        "          val+= (np.exp((1j*2*np.pi*freqs[s] - r2s[s])*samp_time[n])*\n",
        "                  np.exp((1j*2*np.pi*freqs1[s] - r2s[s])*samp_time1[n1])*\n",
        "                  np.exp((1j*2*np.pi*freqs2[s] - r2s[s])*samp_time2[n2])*\n",
        "                  ints[s])\n",
        "        retval[n,n1,n2]=val\n",
        "\n",
        "  return retval\n",
        "\n",
        "\n",
        "def make_sine_combinations():\n",
        "\n",
        "  # Number of Signals\n",
        "  nSignals = 80 #random.randint(200,NSignals+1)  \n",
        "  # print(nSignals)\n",
        "\n",
        "  # Frequencies\n",
        "  freqs = np.random.random(nSignals)*SW\n",
        "  freqs1 = np.random.random(nSignals)*SW1\n",
        "  freqs2 = np.random.random(nSignals)*SW2\n",
        "\n",
        "  # Transverse relaxation rate\n",
        "  r2s = np.random.random(nSignals)*(5) + (1/100)\n",
        "\n",
        "  #Intensity = amplitude\n",
        "  ints = np.random.random(nSignals)*600000 + 100000\n",
        "\n",
        "  # FID creation\n",
        "  ff = make_fid(freqs,freqs1,freqs2,r2s,ints,NoiseLevel)\n",
        "\n",
        "  temp_realPart = np.real(ff)\n",
        "  temp = np.abs(temp_realPart[0,0,0])\n",
        "  ff = ff/temp\n",
        "\n",
        "  return ff, nSignals\n",
        "\n",
        "\n",
        "def make_2d_mat(b_size):\n",
        "    \n",
        "  # Training matrix\n",
        "  target = np.zeros([b_size*NP, NP1*NP2], dtype=np.float)       # For Target\n",
        "  train = np.zeros([b_size*NP, NP1, NP2], dtype=np.float)      # For CNN\n",
        "  train1 = np.zeros([b_size*NP, NP1, NP2], dtype=np.float)     # For test_fft\n",
        "  train_1 = np.zeros([b_size*NP, NP1*NP2], dtype=np.float)      # For DNN\n",
        "\n",
        "  # Matix concatenation (training)\n",
        "  for i in range(b_size):\n",
        "    ff, nSignals = make_sine_combinations()\n",
        "    train_ff = ff\n",
        "\n",
        "    ff = np.fft.fft(ff,axis=0)\n",
        "    ff = np.fft.fft(ff,axis=1)\n",
        "    ff = np.fft.fft(ff,axis=2)\n",
        "\n",
        "    ff = ff/np.max(np.abs(ff))\n",
        "\n",
        "    train1[i*NP:(i+1)*NP,:,:] = np.real(ff)\n",
        "    # train1[i*NP:(i+1)*NP,1,:,:] = np.imag(ff)\n",
        "\n",
        "    for j in range(NP):\n",
        "      train_ff[j,:,:] = np.multiply(train_ff[j,:,:],mul_arr)\n",
        "      # index = (i*(j+1))+j\n",
        "      index = (i*NP)+j\n",
        "      # till_index = NP1*NP2\n",
        "      target[index,:] = np.real(ff[j]).reshape(NP1*NP2)\n",
        "      # target[index,till_index:2*till_index] = np.imag(ff[j]).reshape(NP1*NP2)\n",
        "    \n",
        "    train_ff = np.fft.fft(train_ff,axis=0)\n",
        "    train_ff = np.fft.fft(train_ff,axis=1)\n",
        "    train_ff = np.fft.fft(train_ff,axis=2)\n",
        "\n",
        "    train_ff = train_ff/np.max(np.abs(train_ff))\n",
        "\n",
        "    train[i*NP:(i+1)*NP,:,:] = np.real(train_ff)\n",
        "    # train[i*NP:(i+1)*NP,1,:,:] = np.imag(train_ff)\n",
        "    \n",
        "    for j in range(NP):\n",
        "      index = (i*NP)+j\n",
        "      # till_index = NP1*NP2\n",
        "      train_1[index,:] = np.real(train_ff[j]).reshape(NP1*NP2)\n",
        "      # train_1[index,till_index:2*till_index] = np.imag(train_ff[j]).reshape(NP1*NP2)\n",
        "\n",
        "  return train, train1, target, nSignals\n",
        "\n",
        "N = 5000\n",
        "NP = 2        # Direct dimension\n",
        "NP1 = 120     # Indirect Dimension 1\n",
        "NP2 = 32      # Indirect Dimension 1\n",
        "SW = 1000\n",
        "SW1 = 10000\n",
        "SW2 = 4000\n",
        "NoiseLevel = 0\n",
        "NSignals = 250\n",
        "dataIn = []\n",
        "dataOut = []\n",
        "epochs = 12\n",
        "batch_size = 32\n",
        "val_split = 0.05\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ph-qDh5LisMj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5encqgEcDfGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvvNwm3f8jbS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f62c72a0-4c30-4662-fa97-9f85d19e1a57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras = 2.8.0\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import keras\n",
        "from keras import backend as K\n",
        "print(\"Keras = {}\".format(keras.__version__))\n",
        "import tensorflow as tf\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
        "import numpy as np\n",
        "import pylab\n",
        "import sys\n",
        "import math\n",
        "from tensorflow.python.keras.backend import set_session \n",
        "# import keras.backend.tensorflow_backend as KTF\n",
        "from keras.models import load_model\n",
        "from sklearn import metrics\n",
        "#from model_logic2 import *\n",
        "#from generator2 import *\n",
        "import scipy.io as sio\n",
        "# from keras.utils import plot_model\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
        "\n",
        "# config = tf.ConfigProto(allow_soft_placement=True)\n",
        "# config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
        "#config.gpu_options.allow_growth = True\n",
        "# session = tf.Session(config = config)\n",
        "# KTF.set_session(session)\n",
        "\n",
        "# sys.setrecursionlimit(2000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B830iZxSuoFh"
      },
      "outputs": [],
      "source": [
        "train, target, target_1d, nSignals = make_2d_mat(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ip = np.zeros([80,128,120])\n",
        "target_2d = np.zeros([80,128,120])"
      ],
      "metadata": {
        "id": "IG593-KIP-sY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hSxf_Elg1aiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_ip[:,:120,:32] = train\n",
        "# target_2d[:,:120,:32] = target\n",
        "train_ip[:,:120,:32] = tar_2\n",
        "target_2d[:,:120,:32] = fid_2"
      ],
      "metadata": {
        "id": "2zrrV8sjQKDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(train_ip[:,:120,:], target_2d[:,:120,:])\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
        "\n",
        "\n",
        "output = model.predict(train_ip[:,:120,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyETZWuxQKGN",
        "outputId": "264f3f8e-6bd4-4576-e226-d8cab64084c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 132ms/step - loss: 0.8599 - NMSE: 0.9044\n",
            "Restored model, accuracy: 90.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkSWHfBBKYSI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk8gcyaCl2Bt",
        "outputId": "6e676081-cc61-4b73-ddf6-1cb57782947b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 3s 369ms/step - loss: 2.0562e-05 - accuracy: 0.0625\n",
            "Restored model, accuracy:  6.25%\n"
          ]
        }
      ],
      "source": [
        "loss, acc = new_model.evaluate(train_ip[:,:,:32], target_2d[:,:,:32])\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
        "\n",
        "\n",
        "output1 = new_model.predict(train_ip[:,:,:32])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuSCyYl4gRT2",
        "outputId": "3fc5a1cf-30eb-4e23-a5db-9e39fd9eee49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 128, 120)"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ],
      "source": [
        "train_ip.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVS-oVEygT0e",
        "outputId": "5c6ca713-30a7-4f83-c4e6-34e79f1b5072"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 120, 120, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWHdUUcYgYXQ",
        "outputId": "d5718b2c-f554-46c5-dd1a-1ed36a973ada"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 128, 120)"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ],
      "source": [
        "target_2d.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3eljk-GnKvi"
      },
      "outputs": [],
      "source": [
        "# z1 = azur[:,:,:,0]\n",
        "# z = luo[:,:,:,0]\n",
        "z = np.real(train_ip[:, :, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZxq6fFel2EK",
        "outputId": "f03192f3-1eeb-4522-a0cf-a66e0feaec56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   1   2 ... 117 118 119]\n",
            " [  0   1   2 ... 117 118 119]\n",
            " [  0   1   2 ... 117 118 119]\n",
            " ...\n",
            " [  0   1   2 ... 117 118 119]\n",
            " [  0   1   2 ... 117 118 119]\n",
            " [  0   1   2 ... 117 118 119]]\n",
            "[[  0   0   0 ...   0   0   0]\n",
            " [  1   1   1 ...   1   1   1]\n",
            " [  2   2   2 ...   2   2   2]\n",
            " ...\n",
            " [117 117 117 ... 117 117 117]\n",
            " [118 118 118 ... 118 118 118]\n",
            " [119 119 119 ... 119 119 119]]\n"
          ]
        }
      ],
      "source": [
        "# X = np.arange(128,dtype=int)\n",
        "# Y = np.arange(32,dtype=int)\n",
        "X = np.arange(120,dtype=int)\n",
        "Y = np.arange(120,dtype=int)\n",
        "X,Y = np.meshgrid(X,Y)\n",
        "print(X)\n",
        "print(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "_5pEmCv5nAXX",
        "outputId": "d6876d9d-9a29-4f86-e029-a69a62e11621"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"c29cda2c-48d7-49b4-8aca-34b8226d8865\" class=\"plotly-graph-div\" style=\"height:800px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c29cda2c-48d7-49b4-8aca-34b8226d8865\")) {                    Plotly.newPlot(                        \"c29cda2c-48d7-49b4-8aca-34b8226d8865\",                        [{\"z\":[[0.0016466143346638338,-0.02780997423347805,-0.039937097974854695,-0.00966846132673421,0.01657841571117765,0.020273790284613742,0.02420651700135758,0.016407593977111452,0.013676980641451678,0.027407706834358284,-0.0615519347283482,-0.012412110515525078,0.011627756575534744,-0.031381065099110844,-0.01741740084400804,0.013095849557149413,-0.004665674018895067,0.02410227562119939,0.025190686183907858,0.013003704850430564,0.010631807646970042,0.03189712418401059,0.020055667311869623,0.013577758969944736,0.006029473864055432,0.017108464407650688,0.010125910772339713,-0.01091743427154343,0.013997700335450843,-0.014001077983885321,0.016653962687930072,-0.01250756838138047,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0036266775999811863,-0.009489004790354756,-0.018146719046415637,-0.006220026751077947,0.01249799959391265,0.004659965332295231,0.007892718782210671,0.014194402257423015,0.02195404737096774,-0.0018442563801646928,-0.028396369424762587,-0.013929301790109906,0.0001209895213869288,-0.010361876324343912,-0.0032999235506120583,0.02181020945878628,0.01238976879076796,0.014973161740344576,0.016472219392664904,0.01453816073829886,0.0041240676774026725,0.016601198628520445,0.016573185616258347,-0.005657251492906931,-0.0012786951408449493,-0.003829056914788381,-0.0052019498499064265,-0.014559307238560727,0.0013173424926212168,-0.0048838010312161236,0.01035444612378757,-0.01882500881673546,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.000487437393180795,0.002693117844063027,-0.007963952460499035,-0.00727036267854593,0.006697026723668293,0.008819616718026717,0.0036586243564276553,0.014523987543462806,0.016966495794162966,-0.00536169759165283,-0.005646582551900641,-0.00465408202681616,0.0019372590394182794,-0.004265075566636547,-0.0015764336822786844,0.015534454174572129,0.01294454077443504,0.008543054849938708,0.011706974913315118,0.015714222514074932,-0.0007239446980521076,0.012293991636966076,0.0044267044302680626,-0.013380310090217345,-0.006938470894232949,-0.005792806728427777,0.003724527340690264,0.00236337244090359,0.008793225924927012,0.0031733226737677128,0.007994939961065843,-0.007497077192795686,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.000671803346529668,-0.007132225784485906,-0.002154595446239084,-0.0011876549067087985,0.003112709179400587,0.010009114174314597,0.002574931480844041,0.015559548683495196,0.011598494426310972,-0.004646615469438963,-0.007030629254630074,-0.0059493041370741115,0.004729910288769633,0.003783745784672913,-0.0007404852637642951,0.01753392642231415,0.010883909257954422,-0.0013584656042158732,0.008036005970751462,0.006886545125293751,-0.005341867868547054,0.02314782514043813,0.008666161602620525,-0.009042004722054192,0.0009716290124540354,0.0019781019535179845,-0.006320495191916143,-0.0009187971612856969,0.010420595229165119,0.005799402481917556,0.0019788590515950034,0.0015015906570359438,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.00028820227102349514,-0.00390141229455357,-0.005067089872544793,0.002319191919041225,0.01021461526413852,0.003143557167078331,0.005668571647251339,0.010343608439998275,0.007953996805916132,-0.011100602702418673,-0.0057886440855750565,-0.004338174925785067,0.0064432979221755015,0.008521616615086141,0.006293568108855031,0.015489361761398979,0.011468205022269118,0.003167922137748845,0.004495504781314143,0.0049667337790227405,-0.0016651207356126684,0.008059355242692964,0.005364204174759838,0.001414527549936181,-0.00028621636082187005,0.0071969169328893355,0.006121523394172786,-0.001792169147884515,0.004232711105920651,0.006833568174935605,-3.9275056351830434e-05,-0.00729336218440739,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0036649104449279547,-0.004477038103685083,0.0016633849558879337,-0.0004577682659635844,0.007458611807290821,-0.00308042648724728,0.0010159268672465427,0.00893807503224658,0.0038786336371545776,-0.0014230568083399805,0.005577771121749795,-0.002141021633563944,0.012354194299753495,-0.00071247207736656,-0.0017943471457068038,0.009857642976177026,0.0082069710334524,-0.0015280310228530253,-0.004205149403566377,0.0009951089996935894,0.0058429757316086905,0.012585997510141889,0.0013061837147163948,0.0006988553747913869,-0.00024065630959752539,-0.0031094481434898185,0.0029100848034377667,0.004799801775184604,0.007212271738207682,0.00648510102204956,0.0001602643675606886,-0.00739251818482052,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0013083958523268963,-0.004631905450967988,0.0008723492347728604,0.0016639012322813285,0.0025421861448755244,0.0012716947275736336,0.005405894521369201,0.0057408388176070635,0.005361187665024272,-0.0015370369694672615,-0.0016661639582911303,-0.007146926898158444,-6.775708751306327e-05,0.004092468345231249,-0.0005725902392869093,0.011421919863967041,0.010405516838434357,0.0006095884927163629,-0.0019424194716266122,0.0026838021536829786,-2.231036638427542e-05,0.0026199240071099056,0.008692774001461583,0.0007343125163386795,0.0065642935205917465,0.002547942711278758,-0.00035438558624019157,0.0013195551384594596,0.009135789455993469,-0.0016937172236163056,-3.954938312252907e-05,-0.002279844501990625,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0013868108421520714,-0.00354324691162126,-0.0006948330558710075,-0.0027660172560944707,0.0020737102662857615,0.003932485512505267,0.004281898500109603,0.0068589171128469375,0.006603143011185289,-0.002294137949939638,0.0013262593364757713,-0.003055348300074872,0.0014204257980956496,-0.0021080498723049434,0.003957774534832159,0.005058655120306171,0.007343298502626572,0.007467302017135092,-0.0021806192355500542,0.0004220699830796189,-0.0010601496665210498,0.006502309265592582,0.0078692347752525,0.007722820286413328,0.0040293475192589665,0.004778718805113382,0.0010867044061002745,-0.0025241115574127374,-0.0035191418419077665,0.0013650251256039398,-0.002111008264458218,-0.002519284529161042,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0045010015315085136,-0.006113902158151532,-0.00012219718726686005,0.0019831080688123576,0.008124262007874607,0.010002424664103733,0.01467189183874984,0.004628430915484878,0.002576613226872617,-0.004067978750314672,-0.008993013947683242,-0.0061095710637341675,0.00506423362985546,0.0028365363444348506,0.004292972551473582,0.007773599634758299,0.006480966646748882,0.005133833791474511,0.00040497165344318255,-0.0010933667173205917,-0.003006982964605156,0.004735225315753219,-0.005930262517008994,0.002908886663045182,0.006216985211943098,-0.0026293790289573155,-0.010035298281728939,0.006535717408979742,-0.006077395265318993,-0.005713265408127471,-0.0019018492488686331,-0.008293422924066486,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0028275353883707864,0.007113978506189014,-0.0051379842551820855,0.010464149977254792,0.009161643264348896,0.004373343318504654,0.006352168836521542,0.0010092890625680614,0.005402523349023853,0.003940347564962085,-0.0040837564340648344,-0.007915038176064152,0.00685921400483392,-0.0016432200691187668,-0.001109791079506987,0.0038412140058748717,0.013351133601064715,-0.0015029091766324489,0.005314589118887575,0.0037560497659827256,0.0026311009143443484,0.000431777812338616,0.003003176366912324,0.0035206918575833514,-0.0008003824957399271,-0.0064988943962231765,-0.008462099698019964,0.002927127917522339,-0.0021744964088365347,-0.0064266148592007554,-0.002300268857564631,-0.003760116415701719,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.005659710075679114,0.01037118758021556,-0.0037061604405548053,0.009526849315836004,0.0033955549494651075,0.00037565430356478453,0.003086407407240328,0.00960659331162712,0.0037084183056746737,-0.000545811853415794,-0.0019666948051395797,-0.00889947792003672,0.00510403791718406,-0.002985989619761803,-0.001724252779045632,0.008334928239477471,0.01648217977051623,0.0009807356354201225,0.004972287929037857,0.003946977317518428,0.004887080546696456,0.0031836848267228607,0.005087784002905391,0.006937520382905619,0.015116101719158526,-0.009089373828119118,0.003082575171904281,0.007907892462224756,-0.010066075549013112,-0.008210798854164874,0.008407994003563507,-0.005009864444097487,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.00571316749869678,0.002999263473460852,8.131015125053813e-05,9.88249241726125e-05,0.007365692192544709,-0.001575916201038956,-0.008488020094810686,0.002866248223611697,0.00514376575833375,0.0060067396487245295,-0.0018269730771523366,-0.0003746638994002952,0.005564956324349013,-0.0003504799327279374,-0.0037323728540499634,0.003505955651762527,0.0069876365248527274,0.0014455094008714137,0.012010334514476737,-0.002039196594207329,0.00431806228148636,0.0024074674246030467,0.00689581328599148,-0.0029867899171943826,0.0036357113263705844,-0.012487126737507188,-0.003563424355245808,0.006173395470712836,0.0007107148757877325,-0.0047906529049245705,0.004893520552212633,0.00027848401690965137,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.005608878965668624,-0.0028544662010327676,0.0006947640299517816,0.0071329510437807215,0.005149505740458817,0.011775520399866886,-0.0003719316444260541,0.0018104186064270907,0.0019477291971596346,0.0028020734032684013,-0.0007023629156187503,-0.005320465345149034,-0.003753858599591399,0.0009467184966893876,-0.0014023519945734668,0.0011787696738908022,0.007934696452732717,0.004335379669560305,0.009153777508977444,0.0010293129770290919,0.001144344244026958,-0.0026895393090564344,0.0038096818085983654,-0.004032356575122259,-0.0008793369759690638,-0.0045166141605694635,-0.0003038564176990767,0.001645667473010919,0.007477782780081545,-0.007797908273600007,0.005435285081596099,0.003288028124245533,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0010796451544370738,0.006285487013176002,-0.0042938107476110455,-0.0027641365832649406,0.004177930939346304,0.002503132176112952,-0.002290618212977427,0.01900549489339976,0.003943340577391731,-0.0007932880289633449,0.0030750393499859494,0.000334920673460908,0.0027288754266834025,0.00325876486428739,-0.002632020174821295,0.0027622698584332077,0.007907113025029772,0.006594882775681156,0.006005732764165558,0.004743095755241097,0.0007410791614585139,0.0012372098414294504,0.0050204314746403,-0.00020921711096345323,-0.0023940681949695545,-0.0008923043443987555,-0.0014588996251662506,-0.002370364912438387,-0.004718880833575977,-0.00023833700417731903,0.018286831348497904,0.009167892368294907,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.006658059029573464,0.00013462069015410803,-0.0003157513894826666,-0.0052910858729508965,-0.0008670409992836072,0.0024460989495674774,-0.003977369745256331,0.006200813424336646,0.0033707733599528944,0.001791396799176038,0.00020806389411350023,-0.00018140225382446434,0.0004013478387078977,-0.00031176777470047067,-0.00730225814071113,-0.003088929690194119,0.005910890464132387,0.0023551158652345074,-0.000597075216447335,0.0016588347469051654,0.0027265756331857054,0.0028279923272486944,0.002318489162364667,-0.0027208244489587553,0.009362978797841271,0.0022844996031057643,0.01052663293163382,0.0016481089277614672,-0.0006767310975788411,0.0033981766963970894,0.0073507314952432085,0.0018886200052166667,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.008362901652383672,-0.004301777602562779,-0.00629443334556227,-0.004066932374242573,-0.01114285228531137,0.0049872007555483745,0.0024972896915990603,0.005210046029212246,0.005928615622632221,-0.0020501755809341072,0.0012272925973043018,-0.007996080106200771,-0.000839246776348226,-0.007812792391907243,-0.004662085702850783,-0.0033810813526189572,0.005445845162454808,0.0035442736592043965,0.012003627016950484,0.0042931154088337595,-0.0024300818070558494,-0.00020275095047033739,-0.0036361646680443996,-0.008812968133061873,0.002251665424099374,0.003230630543196524,0.012791037009244312,0.003591712173360376,-0.003240800450233657,-0.0007127805453452941,0.0011630030614297366,-0.008036452026319831,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0024489835793375216,0.014334770251993867,0.0024832914196598224,0.0054186156838460986,0.0030696538838169826,-0.003275406980576388,0.0023314849303812434,0.007500219969144145,0.0031256175895520823,-0.0017332159547200343,0.00032905512173114835,-0.0013281112239808793,-0.003184846220528849,-0.0017419508875987548,-0.002759551232524065,-0.0002532304569142744,0.0060448718845304075,0.00222984081553475,0.00984566263754258,0.012554280250795219,-0.0004948163835672027,-0.0004129335573252601,0.006207769692434322,-0.0015346758429706832,-0.007810808782412841,0.009578448647356307,0.007605454784560434,-0.0023954127410976446,-0.013073670501686969,0.0002796451590419743,0.003846917024321269,-0.00519546873446598,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0028034596484935253,0.009292235408418647,-0.00971669989891401,0.003106369395565397,-0.003559614908002195,6.110091891176287e-05,-0.006031725605548671,0.001370749037513904,0.005488925208584898,-0.004235214740457362,-0.003091832606272956,0.0022443993961012315,-0.002794039432660939,-0.007737468736881449,0.000144355928824228,-0.007547026143517197,0.005849234063564848,0.0017490177383364567,-0.0007500223871828023,0.008402733315416671,-0.0024790199745618005,-0.0020141409050204832,0.008049656464472973,-0.003664957453954225,-0.006140943358425541,-0.00021901686370440535,0.00413756085898603,-0.0028558565731801283,-0.004781511391990617,0.008759011506543929,0.004036601193334189,0.004682739758875029,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0023951827796129892,0.00562438078819147,-0.0026612393401990587,0.00890540215370896,-0.000884549886894999,0.0003906171473194502,-0.005444163263143639,0.00257188178115276,0.0013508007095180583,-0.0071774028307654775,0.0026428153159559443,0.006787910928707094,-0.001429024653045486,0.0012757320051529869,0.006835711115655715,-0.003860845866559561,0.002149196925014763,0.004360925147296005,0.0015834932673322154,-0.006587425656593722,-0.0005490599094596175,-0.0007272153673847658,0.005784960088646104,0.0006117029642725124,0.007223846254067908,0.004963484962617347,0.0071797770351172095,-0.005533874261265167,-0.0013528924591870053,0.004441025059652787,-0.0006015032442727186,0.0014899528013577995,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.003118769073388217,-0.004078128890666692,0.0007643393073681499,0.006106038145880266,-0.0013599942477247366,0.0011007103105454916,0.0008306250631100951,0.0030826718022450355,0.0006895711255728403,-1.2029814057048287e-05,0.003962197682535459,0.0025448140611939347,-0.0031641969167991784,0.0009642074365589199,0.0018988325485037438,-0.004131184096177436,0.0024394982353885476,0.003905155470289841,-0.00039398202172427654,-0.00225442034648214,0.007157958255774184,0.004593548253073368,0.003985426448775856,0.005312598850164264,0.005351687618593894,0.0021119990770905555,0.010786137861674034,-0.00260760723966045,-0.009251334415457696,0.0020205657202838332,-0.009661289016483629,-0.005662999420746153,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0014484003339919561,0.0018076463863849156,-0.001596004503431785,0.005144746578785312,0.003202315238082584,0.003989468175440413,0.007899548363951516,0.00890069775167259,0.008777675629005315,-0.0035305695570069196,-0.0015853874939182582,-0.005986094542931841,-0.008552061652360752,0.0006146298016878618,0.0033062904637138676,0.008536905793310838,0.008134232570052217,0.009139013140858193,0.010023884263107569,-0.0007588222008777394,0.006796975037746849,0.013404636354911945,-0.004068958543775688,0.007006919853451457,0.005177052207884889,0.00045225022469185937,0.0024041574093513996,-0.002969917203148166,-0.01227761042430705,-0.0024045959533063868,-0.003087428896816832,-0.008675294571933103,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.01125651363395458,0.003895498164315501,0.0008354595141302271,0.0019055950050644304,0.008140992402843805,0.000530282952768755,0.006863523377257841,0.0080937728721037,0.0013850806562439276,-0.007737761522209441,0.006626598258358788,-0.009377387317420067,-0.003443591363030727,0.00135062091793139,-0.0005614109700447712,0.003792238125452171,0.012319569284028024,0.008379259858397489,0.007194734962042439,0.0043116405566133095,0.009405042513625055,0.003909694988006757,-0.0063496262943160625,-0.003340955813024398,-0.010206419452633706,-0.005149175160179524,-0.001252248983713542,0.0016653051137171188,-0.007196294200034198,-2.9532979247668144e-05,0.009951661047205781,-0.007053104680438939,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.003802453386745771,0.011958269951512076,0.0035778076698482525,0.006506813754268412,0.010353139560028663,0.0034316160273461073,-0.00025333313882406743,0.0031099473601421497,0.003763200624312875,-0.002502289273127899,0.0040612796430958805,0.0004612637858729153,0.0034515600223225806,-0.0009345890955378876,-0.0010515569376418768,-0.001108280541580091,0.0025566527766059423,0.008756895118009535,0.00039584293215044113,0.008233100312727785,0.014174597994504596,-0.000864694992099421,0.0006118230529905066,0.001723081505248618,-0.0055578982345717174,-0.003319548870948521,-0.0011139508672568738,-0.007797914803446767,-0.00479947565785541,-0.004514363749558102,0.003522419167689599,-0.0032079367092707096,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0033708347932370655,0.01982321645939405,0.008019205570053695,-0.005815363300164782,0.004750629043758858,0.002013835478964114,-0.005170895594606081,0.0004940582130024015,0.011128507722728574,0.00210963484719474,-0.0035082661990856133,-4.319913244207236e-05,-9.578613001628464e-05,-0.005976320080949206,0.0008600631358797654,0.0054943235698041585,0.005768949628600179,0.007332337847411047,0.005957358006204205,0.006028614946967485,0.009194652244141505,-0.0031081657592266637,0.0015359691256375495,0.0025853016740132453,-0.004174435017236232,-0.009359103545238273,0.0010852986564596375,-0.00896990826999393,-0.004534199540835231,-0.0010553995904221056,0.006439736844414394,0.005230386822542379,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0030616776040752816,0.006762492387432838,0.002301373893129337,-0.004107922396084708,-0.0023370684055382144,0.001015252736239929,-0.005182608554053628,0.0037966281360595744,0.005349103377370039,-0.0006669049003839137,-0.0005825196731926164,-0.0005024967118204264,0.0014006370986097037,0.005772402928054651,-0.006813025872193499,0.004543984154556864,0.001276152532316078,-0.001087627323936491,0.007690846754893909,-0.0026418385898453415,0.0034259217177604025,0.002670038290913932,0.0011893252203936196,-0.0007203968341254715,0.000742929056998995,-0.001752706686943279,0.0052009877498038655,0.0007134801709279521,0.001700781542301661,0.012425334158230923,0.014167005756087958,0.00393187805905578,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.002336692295663904,0.005354508446976,-0.006714122767673179,-0.002193553565102591,0.00031579467013921885,0.002971272488924368,0.0008180214131461475,-0.001709950218848498,-0.0015498954852600625,0.00045833654673475756,-0.004215546400128396,0.0036242320472244993,-0.001664939486381626,0.007174336649558371,-0.0008819497690858944,0.0024814827154908854,0.004125703311573604,0.0012378172826772306,0.0023346357900087414,0.0004797336736798567,0.013833759614984007,0.011679941898512358,0.007284148655369727,0.003724720893449849,0.0021731986867400523,-0.011227028096651336,0.003906255112226864,0.002993868814927444,0.0023791190882974564,0.012623170697876116,0.012620749910794784,-0.0068099178060878,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.006242000450940152,0.0023823171432865325,0.000289949059773018,-0.00947657355085557,-0.0003176239583342907,0.008257222382313635,0.0028420906376065186,0.004107716981415394,0.009727631170208159,-0.0028487474630849744,-0.002254047668451713,0.007436810876541742,-0.00026086683962547164,0.0034331268594070975,0.004510093613370292,0.0011330936223300863,0.00032724008346707794,0.0032464883773884075,0.0056793909694636754,0.01028059669410985,0.012709353303885873,0.013783061479376175,0.009388925902883568,0.0019756770430233743,0.00647681065418205,-0.012602251749264552,-0.0030020333737607523,-0.006281736168384762,-0.006500368916346239,0.009794770322448857,0.02234946448972548,0.0017746075493017225,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.005581213145161471,-0.006831534801309974,0.0010934504613921761,0.004649234271211439,-0.00211096932353133,0.009827953381030197,0.006560444531713577,-0.0002428869578730695,0.00888335200130107,-3.174987240579631e-06,0.0024018749369316404,0.009122226025340251,0.0008507127219438804,-0.0059664269798145155,0.005616551895898365,0.0052587195410381165,0.0013937202293923482,0.0029580183624325746,0.011340232601219054,0.0012139509339478614,0.0019886009354336863,0.0044201710417700575,-0.001767386536105805,0.0016107873365616395,0.0014933937535523641,0.0005641606792458547,0.002921961862532749,0.005483949681912433,0.0032552465198220815,0.00800504202944084,7.043029219263021e-05,0.0001917979183012929,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.005271522867433656,-0.005885592172269953,-0.00469171555457295,0.007513875062217863,0.009659716386892201,0.0022097442117545185,0.00883439347271949,0.0039024968867101923,-0.0009713937261763807,-0.0027640887959296937,-0.0014299353104706145,-0.0023567532436319515,0.0007178700329792524,0.0014999988415424494,0.0056365493716665615,-0.002281988522254749,0.0019035347490282439,0.0014012348993618533,0.007588346528662711,0.0015022232253500338,0.006906644771450063,0.007677799398844841,-0.007808117296464105,-0.0011701486448938332,-0.006125678198190385,-0.010640109571831402,0.002790707038785691,0.005168336271694668,-0.0005269322218761411,0.010201153540199522,6.289176327716247e-05,-0.003602561853815706,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.004147379318494578,0.0026512228232527433,-0.002682255577518711,0.005423189132855844,0.0008119879013010276,-0.0026702285027368692,0.0006801571615038205,0.005952432157999856,0.0014315900373828724,-0.001970818082719114,0.00794623663194615,-0.007011923753763468,-0.001263354039785515,0.0025609993066414657,0.00459286954487602,0.0009542253023188553,0.005579630611136948,0.0060030260904399045,0.007024307538612088,-0.0021582020306700673,0.004041215850231009,0.012610865723377083,-0.007531580233863731,-0.008415745909352488,0.0035039869028744616,-0.005115810422877019,0.00495411603359718,0.005153890343620934,0.005882824271393632,0.010969122971563312,0.0031785814083037833,-0.002742840514555315,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0028848782625507893,0.002459319399053812,-0.002604721726069739,0.010485628588030716,0.0006169154460962773,-0.002158682244117851,0.0009565708329078615,0.0016565986669979306,-0.003304273243102802,-0.003578474102489682,-0.000454611657297107,-0.0028299965141548302,0.007609458059084176,-0.004980138128265375,-0.0064765002802346545,0.0012852464302290823,-0.0005324624521719206,-0.002363814590056654,0.009581448960603657,0.004291891315368137,-0.007159283228417672,0.0024019530156803403,-0.0021331591612687387,-0.008189846834217264,0.0016343118316734001,-0.005575948364682375,0.004330243368728692,0.001455645366823094,0.006218084461045979,0.000475359422592198,0.0026340262434247836,-0.0022624493028383097,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.004256010041548734,-0.00477847539281435,-0.004967575219815567,0.0016146328543383227,0.0008989106650826625,-0.004350953724719586,0.001722513986695529,0.0030777337349236714,0.0017052883945450966,-0.000537070421280511,-0.005213996548675665,-0.001832744605270204,0.0014358811147224498,-0.0010612347490134566,-0.0028327101140479785,-0.0037534327617416833,0.003110104725478656,-0.006174978660876901,-0.0010080732989159599,0.0017784588746718075,0.0060536465237244295,-0.001042033796400881,0.006588570605129715,-0.00014647467586225443,0.005321233586501071,-0.01335369066832268,-0.002668096557779314,0.0021918256881425517,0.0008303781579013952,0.006400143746332229,0.007185644504609541,0.007215971810297237,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0008940182300141664,0.0026843272235067025,0.00425227139476455,-0.003772036021204567,-0.004762865410692257,-0.0031027167555505194,-0.005332433337511849,-0.003615689256231208,0.00836679114256901,0.0023585420388863776,-0.0060265193985705795,0.0013824138273819877,0.0007563552127896112,-0.00908731625221794,-0.006506334487416421,0.0015475112025311116,0.006327436383245984,0.004295465164419339,0.001285410913839091,0.004772664865495133,0.0063936516476815475,-0.006440497562302117,0.005774570210437913,-0.005159921097958486,-0.004641743211076099,-0.014219344130079317,0.0033624692056383135,0.00014546902192985115,-0.004953426844595681,-0.0003266249322785249,0.0103487983218985,0.0035253506332749472,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0008853758395448628,-0.0011038537190929008,-0.0012605846125787995,-0.0022019876868646575,-0.0068876317400283,-0.0055988231496883,-0.005027657565805246,-0.0034400933508535055,0.0003042063117156147,0.00046154476711563294,-0.005968418038648356,-0.0007644860988405348,0.0023686713669151082,-0.0064755543498437795,-0.0026227915858784727,0.0012322256545927823,0.0016259551761190405,-0.004638831181866058,-0.004513718949292244,0.00032703155651620175,-0.0014655043035156834,-0.0019002547372367938,0.003714184871312659,-0.003689801048950079,-0.0009544594356859728,-0.0038250221192014182,0.0011536295150199373,-0.0014815268787569185,-0.00043664431553354984,0.007137957483914127,0.006540974963091941,-0.0051397377545568,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00098183800356384,0.0024723365778123434,-0.0096822524677132,-0.013389777510845195,-0.0010694625174948807,0.0014544203690344756,-0.0036186668108949866,-0.002553258641088087,-0.004578237114832201,-0.002103767513549222,-0.004307112528935459,0.004189634515295487,0.002331531177286687,-0.005408230983621554,-0.002134922872670059,0.0036753711440027253,0.0012320015949441466,0.0025248035193552298,0.00266764820765352,0.0030963861715271545,0.002197760641343639,0.00018539093155011438,-0.0010105054140559795,-0.0029802821302949084,0.004963376301415103,0.0010839035018504455,0.001198319550612585,0.004704905164894165,-0.0007848154416164616,0.001530699974563273,0.00915439291666231,-0.004559919596758078,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.010960434965294872,-0.00031740188986574384,-0.008518170315398093,-0.004332344563549875,0.002464575016967998,-0.005917173681080669,0.0030010460263447817,-0.005292618089147391,-0.004082218759839604,0.009907712876852163,-0.006573846450752754,-0.000588064030703904,0.005400037013350577,-0.006640061129960923,-0.0009612390965045665,0.00656410045238158,0.003181599067405862,0.0033960548377156056,0.011873880017144095,0.000871995149818236,0.005803218540176117,-0.0006718461496965196,-0.002594293442738517,-0.0009610204063153286,0.008173325740154197,-0.009139578820506391,-0.0007939839957685482,0.0092726375914541,-0.002877577209723127,-0.008275716383059734,0.007979286008073547,-0.010243027355202087,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.004901829568844468,-0.0029665998226607,-0.006813353086699235,0.0002686726973379497,-0.00042822353671464623,-0.007578592953290979,0.011627603877549658,0.0033458935846529484,-0.002227011892201257,0.009176112225309204,-0.0024946731030536535,-0.008380975602800234,-0.002109603185909249,-0.005767992363890901,-0.007097810740671341,0.006003197821419878,0.008915921080793686,0.005200811458545791,0.00524704594997644,0.0021146735537277556,-0.005708049430231845,-0.007321796331960961,-0.004261161014286856,-0.003868812339521895,0.0033787456109938187,-0.0005978501632233229,0.0023507793779534943,0.0073510097757399605,-0.00409188774668963,-0.00411804583230338,0.002555063090094633,-0.011894645973176332,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0012558041863784926,0.0027058586190410777,-0.00572059207196128,-0.0025743181379536753,-0.0025768297727451874,0.0003295226283890953,-0.00551927069633383,0.0029466595781839867,-0.0012737586006157573,-0.00016094379433330533,0.0006110723088595861,0.002937644663645025,0.003797458816380625,-0.002430709487999489,-0.0015202353952173452,-0.004868377725530401,-0.001614426957442844,-0.0015039929678006977,-0.0021873733101630075,0.001944314310584068,0.00210793463400552,0.0055694537538941895,-0.00015647645097539162,-0.004590271769489114,-0.0010723651115751482,0.0015758857265635276,-0.0011248524530776023,0.007033530678539714,-0.0030892970645953516,-0.0021862699183015405,0.009071014256021893,-0.011395932882868474,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0009741583932546154,0.00038895675589728696,-0.005332025403506119,-0.005698462671801167,-0.0014274805869009572,0.003861414917291065,-0.0003788553227706886,-0.0015999355778306735,0.0010963730923557972,0.004663210285197053,-0.007707691901486883,0.004510473563795815,0.00550594277749989,0.006776983477570411,-0.0006358287116804201,0.003103791767661938,-0.0004077521376811653,-0.001834035570491183,-0.0018854450487347217,0.008546901702526812,-0.0009460297585465007,0.003353191159896907,0.004118888947932284,-0.0005703849557178835,0.003783947355030535,4.574812954540461e-05,-0.005536727489134391,0.003465456282737711,-0.0012187956026434336,-0.0025005045035963297,0.01193146643446893,-0.006000283278670338,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.001276545094995603,0.00031693716172030484,-0.0027329497625520113,-0.00256726100775423,0.0008998002663900576,-0.004331754435733962,0.00023986270639677685,-0.004327771384201401,0.0002794969302397253,0.0002351241127431565,-0.006694377118429444,0.004149074910165074,0.009941184779888168,-0.004073691645240216,-0.008968619592450412,0.008256958877889516,-0.0018047659484547393,-0.007518702181126352,-0.003927047417274949,0.013696789556372244,-0.006867267348447657,0.0007059938378411427,0.008038805061666418,-0.00283733567786129,-0.00038057752317199173,0.006965812043515298,0.004714513116723164,-0.0015926335658973136,0.005114370653550266,-0.004555356784789685,-0.002277797119010733,-0.009429267603850657,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0023846818876804864,4.809865432222417e-05,0.0043318671979254335,-0.0038274456548089857,0.006005076109106781,-0.005928746316214941,0.004537507720608529,0.002398298567584921,0.004774280405655728,-0.0010151391160637402,0.005206744105591249,-0.0025804908155846024,0.00045281686463782454,-0.007787767436987521,-0.004580677964029822,0.0039771190666507885,-0.005982152080469204,-0.0014973947391956626,0.0022552994433975133,0.006052781507971546,-0.0024180730393564653,0.0027019073060480956,0.001983604945454052,0.0023362065593347144,0.000783022977076122,0.004003704198532342,0.003158029349899373,0.005312556217933446,0.002277434463393504,-0.013112892616883726,-0.004587373921826217,-0.009473073189286125,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0009827753144291288,-0.0068653375289478525,-0.0018299839101260154,0.0016289554130790474,0.002173998186974704,-0.008593942113714476,0.002487685009606915,0.005193982731697633,0.0061803996406063965,0.005656346546883723,0.0016072174252924453,-0.006319559096757543,-0.0048451483714887465,-0.014056217491811065,-0.010593044919924044,-0.0004197819880344485,-0.0032704898851811394,0.0038093093051389452,0.01001537615227783,0.006418010103990093,-0.005006841068195991,0.004511954303907202,0.0031459437246384907,0.000450355521292394,-0.012980798447605543,0.00034820295951542375,-0.007192128737393328,0.004393222291198015,0.0034546602288000167,-0.006241873736968456,0.003136749048030842,0.002334008161473589,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.004934538080219107,-0.003845130880992672,0.00429684267001067,0.011403885672844165,-0.0034750540406404203,0.004324138273980115,0.0014393146730678579,-0.009049809975778474,-0.001706991098317312,-0.005888485695063362,-0.0030686265971376224,0.0015685945854691935,0.006133014876799756,-0.0033951114864663257,-0.005220625687953437,0.0019254404595215931,0.002944499973613073,0.004882712995195487,0.002316663831148083,0.009852519593609076,-0.0049099504694746065,0.0036237642163269856,-0.004085465479946283,-0.004955264752625136,-0.003894183545894539,-0.004912727930216562,-0.008443478064670648,-0.005038793718446255,0.003542039868692185,-0.005305299654967495,-0.005951914211702148,-0.0014272634171687798,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.009088886181137665,0.0009711224291505734,-0.004164512296203206,0.0018133085803583879,-0.003865756923481909,-0.004337507627820241,-0.002290845971686776,-0.009627798297687945,-0.001184380975582182,-0.0025026401129667666,0.002423135769898255,0.001401783244631113,-0.0017200172170548202,-0.0024482160737082878,0.0006352179153929809,0.0006588452142841458,-0.0027499743613329957,0.0015517481160890099,-0.0008325011259680738,0.00011285845331056786,-0.010041084494829024,0.00248374178803749,-0.002874311402141035,-0.00271565336162096,0.004223327292917634,-0.00668677436910765,-0.007657982369356291,-0.00752770826165182,-0.0007312437388824432,0.006476803621207892,0.0007166278139849042,0.0029401271388668246,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0066883313805694965,-0.004117996274499499,-0.008831201944613381,-0.0017815850730774436,-0.0029452038511042257,-0.009542372744479827,0.010120090491309257,0.00018391157660739828,-0.00659315644034773,-0.0009984987227049519,0.0001629441860969137,-0.007434605730607414,0.0015722650978808026,0.006332262107928844,0.00029356560978423474,-0.0010083929477961583,0.00015260254737230032,0.0002654250628672958,-0.0017396554792655314,0.004803850792307497,-0.0016704861873903382,0.002095973966986727,-0.0033367731744191453,-0.0024775290930917487,0.0027070145014683983,-0.001499110156369993,-0.005697487770682218,0.004128598933989667,0.0022969572048725834,-0.003742527331311807,0.0025943324889775537,0.006356834116871392,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0019109822751335575,-0.004032913642928676,-0.010027003912964698,0.000936952568854804,0.0010348186012433828,-0.004813561715536423,0.009489845865728402,0.009743764269507857,-0.0016551710281820199,-0.005857481793170968,0.00701804601591124,-0.0070016224881094226,0.004770646449613847,0.009611036588072224,-0.001082486488020631,0.0006893382615770257,0.00021516444132029598,0.0006840244372108446,0.0002962066578076597,0.0032767916873432004,0.0026105311428575727,0.009467538483748655,0.0056386962591394255,0.0020094530934513495,0.004727684163653325,-0.005761727700656452,-0.010097273122944464,-0.004464834972860234,0.00010504450159595923,-0.0035976855287667845,0.008316983855600075,0.0037614000082538362,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.007194255619317635,0.0029247281278155417,-0.0019428085383165457,-0.007695471835317293,-0.0005547326457383809,-0.003234354578163869,-0.0011199120114698058,0.0011690237749985876,-0.004624937624559543,-0.004179475425832335,0.0035031374848958487,-2.3894366814887105e-05,0.009278632665334815,0.013366210011485554,0.0022738017838738202,0.0050208761676583235,-0.007219428928441268,-0.002871941080183279,-0.005847247999843074,0.000969292517870136,-0.0020921126985729453,0.0036911157440671495,-0.0015285552530717075,-0.0035786387862320446,-0.0014541489328821393,0.002342397191800183,-0.0060888187237804385,-0.003703044261147185,-0.0005317602729329688,-0.008017342141853654,-0.0026701947999105205,-0.002098837789320999,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0017778397129946102,-0.0013994550242512546,0.0012412806933132245,0.0035834876195595428,-0.003977579407741302,0.008087259402794533,0.006157253587609669,0.0015648514077928326,0.007698479964549572,0.01008595561629469,0.00018434120968406382,0.001522713451506356,0.007693146876775948,0.013654675625263913,-0.002247439225301369,-0.002827995600386598,-0.005770231571899544,-0.004752087080289509,-0.008897464868507014,0.009745702666072038,0.008684140767717338,0.0035126899947006563,0.007898539034454739,0.003365217683013319,-0.004190438090444477,-0.0029193607169663884,0.0019377344634532773,0.003902791703922793,0.007501753719933132,-0.0013918797159549314,0.001707718833142772,0.0028301203286265884,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0003376520872607492,0.006364846665283666,0.0005465778674692047,0.007642344229336388,0.004388977817835638,0.002756274691463773,0.003572347583745914,0.006134570061984143,0.004970353684563769,0.0005004098374357999,-0.010457398614459663,-0.009803183808165505,0.0006822264063274961,0.009017451160553483,0.001737956622973939,7.19719485704704e-05,0.002041475988816774,0.0035443539631954397,-0.004400375976797892,0.004777721261212444,0.004159339731125648,-0.0017762331535645,0.013135725004505116,0.0038935204047380323,0.001586951303147761,-0.0015931331240894948,0.005095898366668674,0.004642809814921261,-0.004293438318678616,-0.005580189036356364,0.003241536887620997,0.003749485797285495,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0006329110859111908,0.0025227824836283556,-0.005631528791586623,0.004841236156612781,0.008532583424566966,0.0005401198470747128,-0.0032023002318923256,0.0037752500754941925,0.0015452401740909743,0.00046426106013917087,-0.007756846854824482,-0.008249758763321817,-0.002212124442287438,-0.01147295595346372,-0.0017464256118965456,0.005391464691980707,0.0035155506467211255,0.001732467144761628,0.005077862046190557,0.0029866281826809627,0.0010671600556413433,-0.006284920508090221,0.011222721672847276,-0.001459689730429256,-0.0015954845607124384,-0.0011521655827647997,0.004605257993277083,0.006739801541622179,0.0018357229416117358,-0.0011504112837347994,0.006926036543130306,-0.003472712331366804,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.003127868092417093,-0.005057757786952876,-0.003050982432034937,0.006046880305532535,-0.0007787976416380141,-0.003908848928361872,-0.006696411881992626,0.005623885099361217,-0.0013514692937020994,-0.003431849346676708,-0.00715498561961755,0.003314824358603801,-0.0022522842979134316,-0.006759646878944865,0.0008575989271105106,0.002621585884439879,-0.0012033332634591323,-0.0060050776398600705,0.0018667518171527938,0.002819025475599332,0.002283880607361936,0.0009440249670834682,0.012063590976178614,-0.0061257711900054865,-0.0071040918635798585,4.5514918749947524e-05,0.005022426774742222,-0.0017140779531828164,0.0063703855283941445,0.005229925071119116,0.007286281010905845,-0.0036127152649060956,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0013111791500823086,-0.002357930056537037,-0.004563857511570395,-0.002983300077110493,-0.0029398030928957796,0.0023042217481860426,0.0030206609401242602,0.003882969650855963,0.005351839612996608,0.0016854604735713943,-0.0015071493403160427,-0.005191455709907386,-0.004201604919055877,-0.004660349410201929,0.0019094358517743816,0.006797986400902373,0.010096672044819142,0.008302849679082394,-0.003537719803919121,-0.0025294725743498577,-0.0009656612103130907,-0.004531221505098189,0.012278291825188258,-0.002150510993502939,0.00014947301573405155,-0.0020401902325853844,0.0012277169488252152,-0.004215603072170071,0.003952592387982656,0.00876404424511388,0.011798477456011137,0.008562975376263512,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.006060813094971412,-0.004307731571719054,-0.008184608190181554,-0.0031918976207343922,-0.0047437074759405585,-0.008464501534282123,-0.005344285945745965,0.0010724964228290537,0.0024672211878524093,-0.003590911664547605,0.0076415340462992745,0.004815172799092402,-0.004430925435023813,-0.0027911729299788276,-0.00243290539151223,-0.0027241623241405846,-0.0018644329511664092,0.001698554314231505,-0.0019368774609629152,0.001131812749869152,-0.0038684514146571356,1.4236596907374528e-05,0.006997341432956473,-0.0018412947370829357,-0.00162645157039597,-0.003005400105624594,0.0034467435840241224,-0.009010002210630952,-0.0024361828560497106,0.002119523179467203,-0.001624432901236618,0.0036894351961525404,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.005428416097162636,-0.003521583489023676,-0.008672513218161565,-0.004944990604930053,-0.00530423154077007,-0.006383068090390352,0.0005240564959463688,0.0014414585050154366,0.001700548905419363,0.004727343482615234,-0.0035602575282855375,0.003467617506497471,-0.007305141733852088,-0.007878655457658491,-0.0065080924081140565,0.0014598141395211635,0.0049343071457637515,-0.0026530365577405847,0.0038885887642457736,0.0037322589642196755,-0.0015888030170357562,-0.006751390132929653,0.010083775411712547,0.005204778986927515,0.004259336331424859,0.0034417556135746784,-0.0002880963973657334,-0.002832516552650859,-0.0035264695782168455,0.0030794042573649796,0.0063311123307042555,0.0003344968041294411,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0034296951827118426,-0.0007600928606755333,0.0035732168552782815,-0.0033473442347555474,-0.006181492323004804,-0.004348425441228935,-0.0014452510503895337,-0.010817834579997878,0.0029340961924385757,0.0034839042606741115,-0.002892120473554464,0.005710793988088999,0.004791281474567381,9.725925435529041e-07,0.0011856372527702297,0.00772781008270963,0.0029576456294530505,-0.005181736843170522,-0.0024565909073348993,-0.00018274901822512267,-0.007046661422384408,0.0014969983134918066,0.009037435851499083,0.006977538374106874,0.0089774483049621,-0.0002814700337725616,0.003202991526146465,-0.008986539048698183,-0.005192397206667721,-0.008367066544784555,0.0024018952772743795,-0.001870655698747172,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.007015599145342848,-0.0008487939673360632,-0.0036748587569735134,0.001827672598323916,0.0009362218514752937,-0.0016970208053004143,0.003477258226256504,-0.0004264707164228206,0.006089932413014754,0.006832542039787001,-0.002107231108717274,0.009384289917067896,7.479183867058197e-05,0.001533442734199991,-0.0038548031831068543,0.001218434305234576,-0.0013056652907976554,-0.008349651246950196,-0.010591872596512895,0.0006875583829641185,-0.009132695914745899,-0.004124758758808739,0.0046629771426552275,0.004947027725691828,0.005693778839671051,-3.793787088677165e-05,0.010654662838764074,-0.004092392624452466,-0.005098434748419316,0.0008255257705135794,-0.0005576586851609749,-0.011038006666539894,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.004692130129152627,0.003005489581251797,-0.011348550887097518,0.006561147081356706,0.006359084434665079,0.0038295070203654136,0.0011672393406364993,-0.0033159789376323977,0.0020030050433882613,0.0011913697831252698,-0.0010638779780141967,-0.0005889982965360227,-0.0021581148249073525,-0.0025279959977510627,-0.007727044389981658,-0.0012391583161756878,-0.00040282612715201473,-0.004509402598210936,-0.001699328028136935,-0.002623252774875464,-0.001501251031810074,0.0009180204628652229,0.005034200353548825,0.00811744543646443,0.002950140588934009,0.004058593134546533,0.0068688172983749915,-0.007684645053957357,-0.004687084901722502,-0.00021194605311074567,-0.001694650186994836,-0.00856217311818624,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.004043894096223107,0.005487297994654147,-0.011407232439004402,-0.0009310802949374582,0.0011374621972046997,0.002064567583222993,0.006852170009912371,0.0024409532085413943,-0.0037056871310571383,0.00531393133070097,-0.0019117730433565767,-0.0015142804035094585,-5.677572516754371e-07,-0.004538309256168238,0.0010789949459901,-0.002159944989995033,0.0006159297334490973,0.009512075591455813,0.0017534111802683847,-0.001825672298169175,-0.0033857238568936986,-0.0006262422219443524,0.004743145651015606,0.004176867091595913,0.010076592395935127,-0.001586530392536239,-0.002125149835216787,-0.009009370289576928,-0.008949762684003057,-0.010371833362578927,-0.0006033246821156378,0.0005584621891157781,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.01236434946775889,0.007000546704963878,0.0002488145092644028,-0.0007950636779969262,0.00012893321258990723,-0.007489713491914131,-0.0018318568407525132,0.0020896046199980053,-0.006579934120690412,0.00287351526628548,0.0011527146448348426,0.00557207318316465,-0.0028267514109258235,0.0030555810781774597,-0.0008742716143363232,-0.003048254425279206,-0.008581040489711898,0.007991692454880859,-0.0017392812168027822,0.003913161707685027,0.00028303008625094647,-0.007804226586462243,0.012801606408313624,0.004112445962975663,0.0015321883791407896,0.0016236786127875997,0.004025536177074094,-0.007796283138147372,-0.01100063746225321,-0.013186289220084954,0.0008559598604401616,0.004211239834333888,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0006885298247691413,-0.0018672047673467008,-0.010406786366754562,0.00193452456732404,0.0027951743573961215,-0.003953700452638225,-0.005513192857799121,0.0018429068663077355,0.002974177906758037,-0.008914114997563555,0.00016256766323773016,-0.005468870676228378,-0.008681629748511624,0.0030117968889313536,0.0007038118287788974,-0.007401465951569687,-0.006173456599998705,0.003550581563358755,-0.0004377219668199482,-0.0010917528686548788,-0.008805073741044295,-0.0009789759890087319,0.009034354133747598,0.002664819931294038,0.002166107908258881,0.0011774482594588951,0.014436245235313025,0.0034140180263916263,-0.0005917875880694637,-0.011282193712216107,-0.009151501597532507,0.0015326243549510362,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.003873863964190141,0.002805599991707201,-0.00590364975107539,-0.0016726791978355806,0.000847440202213976,-0.009612521764678732,-0.00767726944371391,0.003527832785947298,0.004066152017068492,-7.53670689245028e-05,-0.002181909387791726,-0.002298879903340117,-0.00322285945092832,-0.004506319677641736,-0.0021101254026230495,-0.005582266659719189,-0.0001449228991891536,0.009570785977889773,0.002273921463113759,0.000573149609189553,0.006985450584606392,-0.002995438366987762,0.006737488168022723,0.0060516002254802255,0.0034517888485811757,0.0012338181764933102,0.007719108008642822,-0.002478795520462922,-0.00432276219546945,-0.0018736991993513353,-0.004764206688464589,0.002121888562516909,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0015751884289743627,0.0004148651391910498,0.0012854095845922936,0.0016865097800346054,-0.002023663433247483,-0.002965512419728534,-0.004424908103351828,0.010277720178959799,0.0032604073960819527,0.0005033576513283819,0.0004865616946571743,0.0053153235691235255,-0.008947754878588036,-0.00019366632949780044,0.0013134021099355966,-0.0013277864603234869,0.009657804015154736,0.011705155535247666,0.00741955212487022,-0.004441801085245632,0.00864855240892973,-0.0029079026514516122,0.005550216939006787,-0.00020425949822335958,0.0003429169128903138,0.002206443983464571,0.0035244292627483317,-0.009105416307439919,-0.01015422066327159,-0.006798316468435743,-0.005932915784974573,0.008212001877129248,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.011449682124883844,-0.004016868689583601,-7.725990383663756e-05,-0.00527506223769289,0.000558086644692103,-0.00482801391109894,-0.008114157162100497,0.007452314398269934,0.004313898230524414,0.0009639977326724895,-0.0026030723495736145,0.0012331049514701883,0.0035580688544726985,-0.004532008475071217,0.0015185866112537086,-0.002357162767041023,-0.008630472681214873,0.0052084362989392625,-0.002309632185767974,-0.004558528304970511,0.0034616041632244536,-0.0011517990521978856,0.010555775819154425,-0.001147224179778736,-0.009825037390476712,-0.002041830684449386,0.0070625682094032916,-0.00600922077831058,-0.006158311213806771,-0.00027497940796576074,0.0015102735383643153,0.007273833765682589,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0069194022402536085,-0.004143276433450476,0.010206754831756102,0.004635953292643069,-0.0009204076264298394,0.000872114138187076,-0.0012964155043990947,0.0022301132915208766,-0.002156479553966394,0.001006158241421273,-0.0011863925433125118,-0.002055796100956018,0.0004424531611221545,-9.04828531895404e-05,-0.004211051216256789,-0.005539011316550786,-0.0026172179237367054,-0.0025211462247936764,-0.0050401402359435184,-0.0018575184393539706,0.008573996531856802,0.002135893656160877,0.005869886341073713,0.004729670047000523,-7.839197299340758e-05,0.00408955599894168,0.01367892105849766,0.0004930515697542914,-0.008065034712964717,-0.0024026867052798625,-0.007218701171665699,-0.0019861002693774875,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0032028110427943027,0.0027924870373875975,0.0018859436158466679,0.0018454723140748945,-0.0054504561325163185,0.0009510743351888079,-0.004226953453009751,0.0012518591206377484,0.0031285744189527612,0.0007761969191430562,-0.0024497093151949613,0.004702302345817641,0.0027498878031244757,0.0010344180156451595,-0.006631024659723436,-0.0006560709763571732,0.005113739000082547,-0.005681786988728501,0.0012153875749860072,0.0004689120038847273,0.011262592494153335,0.009549576210758696,0.006024691078049038,0.010585385849741724,0.0034012304141824087,-0.009841925354618619,0.0024720542951541208,-0.003780431249747819,-0.011297460904543593,-0.0016374417884159327,-0.0033648327866425804,0.002874331246126019,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0017847723348543047,0.005894549220126122,0.011586966084356706,-0.002195218376292334,-0.00036206176948235116,0.004164455646280452,-0.009275863565345207,0.006015088477123291,0.005741837257523157,0.0007225870576093088,0.000518917320159519,0.0015983319501341722,-0.0013396330269773641,-0.005995742130343403,-0.012257729359976141,0.0041301527400043675,0.0049164450671389665,-0.002729504883805421,0.010735686732248836,0.0013307711440126919,0.0018053240082993025,0.0038630947493551626,-0.0038331334637712756,-0.0025097523558605932,0.0013471324515422231,-0.005531457378328935,-0.003067690096066201,-0.002714970677994659,-0.009247055064956957,0.0012495859580627716,0.0033155364317488155,0.0025925238492425485,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.007621769058956897,0.008707935600648755,0.00587355379088266,-0.0017001218455158175,-0.004773014657744801,-0.004443175095495544,-0.007827989847726284,-0.0034375713979219085,0.0005896364971847201,0.0006306433190409013,-0.0009858758278850305,0.00434309933977463,0.0016408733364005916,-2.81513238518991e-05,-0.006276860197186545,0.0022782520409305334,-0.006840394094535845,-0.00787447893857589,-0.0038835463720554033,0.003176516050753828,-0.001151391860034955,0.002700722533638298,0.002312602647575502,-0.00299038232309986,-0.000817520266949414,0.003946570776399223,-0.010284259256142445,0.0016673996018547036,-0.0013074658122111927,-0.0026580442250362236,0.003916212006732139,0.00845821952835089,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0007000852170804547,0.013709958002430725,0.0031669658266047155,0.004187441795157541,-0.0022796147855593005,-0.0037651017713959045,-0.010095892959403467,0.0017955295130298663,0.0004527177385990045,-0.0008572128842968569,0.007568462337377726,0.005093487254206401,0.005211959033307303,0.00017087929553851462,0.0013426851848169956,-0.00046587961111756236,-0.007999392570282326,0.0021020680843275063,-0.003102663435979621,0.00020903920686768761,0.0012909455238076261,0.009934319205012048,0.003963060670001446,0.0024167131110855336,0.0036328737521973456,0.006261684673606366,-0.004209238848725378,-0.0017934130050431781,-0.0038410809914429266,-0.0069389131854053045,9.571474987745e-05,0.003628489435541835,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0036021221879798124,0.0004893675275437975,-0.00031874884535634823,-0.0023120050920273252,-9.169953787955206e-06,-0.004750409743932683,-0.007419893469760658,-0.004558758740971832,-0.0022179387222582433,-0.0031719110176268123,-0.0001902865155146833,0.0012048438398374105,-0.0028338771951800616,0.00362376990732523,0.004392538100797219,0.003974123665526859,-0.0017463204778653482,-0.0009051453957797405,-0.0026513289991095933,-0.0014077199052292416,0.003764822764405853,0.008849421179295219,0.0015902180255622338,-0.003962260844414248,-0.003097785264300398,-0.003446279847295287,-0.0066614696536417654,0.0010462924331581043,-0.0063264007541996466,-0.0003621224527971184,0.0023735373508760333,-0.0036103685436165837,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0051335075822681086,-0.004627423326376061,0.0011021945148978341,-0.0016195631815784446,0.005693360684933841,-0.005392017999785702,-0.0002469380834911395,-0.003189442130076229,0.0048049894383840365,-0.0038239462861280383,-0.000818448413817464,0.007293741434806015,0.0042164623919144495,0.0036829094111192353,0.00352535397164026,0.01269587868836415,0.0034598626023068873,0.0032683689671289644,-0.008075559719138639,-0.001668465169700042,-0.0056707705901529615,-0.0032889465589498275,0.00957924457570217,0.003282873504814517,-0.0026391932497613784,-0.0009250580087654326,0.0014203479269898327,0.003649447865646226,-0.0012627497533271251,0.006760954641535499,0.0025116303525817845,0.002419102960282465,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.003945254991684655,-0.009373696657085338,-0.0010646113785702,-0.006440924713231144,0.00015020908983446823,0.0037736819849904808,0.0019173496423570797,-0.0040192387301841125,-0.0024452640334743795,-0.0052868046579140245,-0.0022572673025309103,-0.004321066775589781,-0.0016850378766284989,0.003303347399809097,0.005665313990278644,0.0009838009205609735,-0.002011145399995053,-0.0012085660208183537,-0.0064540691213243835,0.005776290236717578,-0.00641046477676977,-0.0009026386605148351,0.004393034733381195,0.0028102415409920465,-0.010328570171686376,-0.003999080106999071,-0.005536265091891765,0.005589415457252249,-0.0005345201687067957,0.0012437446787721225,0.006461362479906849,-0.0006905935807138079,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.004589063737428455,-0.0012617736010884625,-0.006349378757714236,-0.006923969443194471,0.004533494874951848,0.0021684322171439236,-0.0034585708457233414,0.000825356383742522,0.002560948987801959,0.0022007455483026004,-0.003938330129434849,0.0038899339572828896,0.0014587389224100394,-0.0016379473422802283,0.004640458394771696,0.0058520730336190626,-0.0010206599741485571,0.004585233351505846,0.0004864645513383557,0.005125782958796707,-0.005785852875609734,-0.003370911674581714,0.011236173023353821,0.002129894141448983,-0.011284259635039076,0.0045060493037540755,0.0028144408967373507,-0.005170393431471974,-0.005870518887902672,0.003270274157922851,-0.0038809177278208077,-0.009314192693366754,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.012098338834141307,-0.002922443059499294,-0.008073568210831293,0.000569385311866839,0.009081944768516747,0.0056798325055105086,-0.0047611525947290475,0.0025659449319717876,0.0065174368611824116,0.0007342154299100885,-0.002939274432767243,0.006619328347138081,0.0017051862267338513,-0.002435770230394013,-0.008819672546517877,-0.006224998219121945,-0.0063912706347006125,-0.001305183049498747,0.006568541449890809,0.0023055177790435896,-0.0003710980774214928,-0.0024546729806587202,0.010343397519637539,-0.006164007796654876,-0.011242007451962738,-0.0044488984160524474,0.007535744864831696,-0.0005946097551708567,-0.0041828315913793905,0.007895241873133419,0.004288090583313607,-0.0048742008394489665,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0021226966749625644,0.001185995516161249,0.004096446790480837,0.004081951287985932,0.007189960354203539,0.0028248635216962573,-0.008115015439850442,0.004577862714742597,0.0053450687635772,-0.0020299036314009367,-0.010200348398607006,0.004496771692442261,0.003392849046738897,-0.005286837295066879,-0.0055294571215032005,-0.004526875636690289,-0.0013232190731272693,-0.004414186016509945,0.009292130566046794,-0.0026118299520875954,0.0015404254852895009,0.011234063498164444,0.010836166615609885,-0.009017030509772546,-0.0037081508804028985,-0.0037934131628135346,-0.0014631664597719504,-0.0034025087266175156,0.0007986259568105251,-0.0003157875128372206,0.006696787282951064,0.006924654861429269,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.008640753832880366,0.006570685345111517,0.005238175549461177,-0.001698860374127726,-0.008297339430650374,-0.0023697320371346055,-0.0067293246590093645,0.00021624913653960965,0.002971663569358475,-0.0030464556506061115,-0.003795845314712103,0.010113213628535825,0.0007872280527105269,-0.007271178006921264,0.004302848194431803,0.0005109521882927939,0.001713005094792305,0.0013005258166421982,-0.00013171287636827553,-0.00678074601688706,0.003269385385755367,0.00015234960418088214,0.0017670908290374513,-0.004310382144115285,0.006884160778501821,0.0031221079885785053,0.001723921359808338,-0.005523020331908623,-0.002867077298421056,0.0034326209069522125,-0.00017552083186313442,0.009467892839374657,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0005562267023960337,0.0009795221022220332,-0.0035545266524867705,0.005420764451565176,0.006007361971163286,0.011073658498843267,-0.003750408345731102,-0.001557621382415419,-0.0006303386659951604,-0.00668907774770032,-0.007538774596194904,0.011506236174595208,0.0009580993782221036,0.0007994386428535111,0.007080060624607315,-0.00642409186661484,-0.0072019202651450115,-0.00482079480483157,0.005575043321448823,-0.00018928201168879743,0.004326798122171098,0.002605804703234833,0.004256291692719225,0.004675313529960572,0.0017229140856773193,0.0010985972861966167,0.00548737334529602,-0.0003390777641952449,-0.0021696100439598832,0.007451366546230804,-0.0036789140172185076,0.0005924323400718162,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0044080104876784085,0.0025393652589952545,-0.006107737376072916,-0.0027772839334188073,-0.008192030613898536,0.004225027536618715,-0.00039522289876956445,0.004763197937582118,0.0009498859970979312,-0.0017871585586536017,-0.012566048083539302,0.005285986317697671,0.00811488160572357,0.00016218966337828346,0.0034668127602122873,0.0023385293709207375,-0.0020280510414965465,-4.8711288123486964e-05,0.004852545688933925,-0.008668104391206402,0.0013697907853963526,0.007746531223801195,0.00697123200055603,0.0012005274046509623,0.004245378275115578,0.0007862412788302748,0.00037317394971800766,-0.00433951306383232,-0.005486969146636504,0.0015317118695986624,0.009760460565111024,0.010909614547314438,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.001429053654979703,0.000533316883170842,1.0701514272719775e-05,0.0012519480268249042,-0.008323292388434255,-0.0011303149177813805,-0.002443899804946916,0.004677880557927092,-0.0011132097026923058,0.0008094907702064771,-0.007373033733097086,0.004415888891108789,0.006532553862853798,0.005308933428237859,-0.0004784774292497164,0.006278115544016167,0.0016132567907805931,-0.007632768885852492,-0.001480297639183886,-0.006432322642966194,0.005103529626918972,-0.00031285630204023145,-0.0032896303680420057,-0.0033245513557869895,0.009979363245082416,-0.0008668026578576426,0.0007567937477328454,0.004026421581102461,-0.0026787880061107353,0.003837753364872514,0.008275687452316539,0.006234572728323294,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0008140503908013876,-0.006973330150408957,-0.003486996475964498,-0.008097648509960802,-0.006196094910624419,0.003252792411099263,-0.001412861516724219,0.00574592645792671,0.0010562895710673266,0.000626267534730672,-0.00985840960989221,0.0007792802331566485,0.0057422099094491235,0.003374502009933128,0.0012047618456327487,0.0023688948255807534,-0.0033898723891313434,-0.012371092799983914,-0.009037087047744854,-0.007698845058338891,-0.0011337449074036387,0.006055628520203461,0.006149783827250793,0.0032295608567251095,0.010923560328674175,0.010035018418854241,-0.002645515588264791,0.0007471912537081874,0.003223501436406783,0.0008706595151465749,0.009374895015987924,0.003837913141878569,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.007838937372354315,-0.0022774268549604973,-0.0001754110732939801,-0.00028676372854933733,-0.0026494182056101593,0.006474572618018688,0.00443555289296916,-0.003806386338191011,0.0007818254680820103,0.006120920534082891,-0.011325892655305947,-0.001916649862427246,0.005008560718834832,-0.000892336383029584,0.004871118199866809,-0.002402656927207591,-0.0006770366003119029,-0.0032493886037119756,-0.005745582441088101,-0.002668128292897966,0.002325331117764247,0.0030834826558951644,0.011324727637342134,0.0028972068214188898,0.003164405292946554,0.001181526066610515,0.0012357315153087836,-0.004407549202849002,0.0012311445439946267,-0.009093842530164091,0.008448706136830755,-0.0025911512627149963,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.009332278744615886,-0.0011731532926646496,0.0019866923861913033,0.008376815628083832,0.002531509427842024,0.012564982091404981,0.0035324403926342654,0.00012316241536355408,-0.006026968657961676,0.0019402918498886586,-0.012499881105578226,-0.002916850508395358,0.0015691355576229159,0.001747864264155632,-0.005754449300606697,-0.003919589880473846,0.0002579005804866497,0.002699417159247765,-0.0014165401508546558,0.0002904173277212614,0.000867541683877401,0.0025382685175508127,0.007398399237074006,-0.0034639671249594365,-0.0023672700230220082,-0.0027068065917564893,0.003302031543506069,-0.004936664075912023,-0.005378591735883192,-0.0027493852070493963,0.009498270349297526,-0.0036857976701117705,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.008428959979131023,0.001861508186600462,0.01021921689055423,-0.010546723534193366,-0.00491652186666969,0.009914052843674958,-0.0028871332366148528,-0.011523040485866266,-0.0036049955071335606,0.0009877326051698436,-0.011616353142057216,0.000983082805900237,0.004772409425429527,0.004260684535860225,-0.01102114512916006,0.006588405274784598,-0.0001685623036812288,-0.003004694921591626,0.0016913101066386208,0.0051849606903734335,0.005523579369338329,0.005325318804251322,0.005618338361093155,-0.0015672523317956906,-0.005900862989226898,-0.002709531720068024,-0.0044124914769457756,-0.003993383771045692,-0.0018063531808862729,-0.0029591330876906977,0.007807104268353884,-0.00020377273987713296,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0073381034387972974,-0.0001518265527337787,0.0006971027188726547,-0.006938640690272642,-0.001992029370135117,0.0009438610443731455,0.002993181689445082,0.0011025694616234678,0.0023025363443275482,-0.00067934994305018,-0.004514894489684297,0.0015164937487191848,0.008220512557989215,0.004543760153780876,0.0016903428939210507,0.005618686693656384,-0.0010736214736648516,-0.0035067136187442874,-0.0012739183851204951,0.004913885882909696,0.004833658703101109,0.004780769594928829,0.0074278687722914806,0.0058334109968108,-0.0022342006486181093,0.0016080250351826126,-0.0005410091738034465,-0.012750700414725655,0.0032710536481310917,0.004724000267455392,0.004444606961005203,0.003594143043560097,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.007657914395458814,0.0005465122832964834,0.002577165896473463,0.0037775437608730464,0.0038075352787469556,-0.0018805296935662452,-0.002188840383003929,0.0015085377691317293,-0.004731523990078275,-0.002663135577767488,-0.004965259211020546,-0.0014416517539401197,0.0047803683145136435,4.004190820550855e-06,0.0057706277104525305,0.002072042342940356,0.007864166591400172,0.00017768392164682923,-0.0079891174504383,0.006685413157795046,0.004108180083431006,0.0013726179196280298,0.005107782794628831,0.00971413562691957,-0.007002663487138081,0.0032913090606592897,0.004272088636784468,-0.010612331513233032,-7.278577061969554e-05,0.000577512622905471,0.0011659636048486322,-0.001189305405745639,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0029123201898348656,0.003583026109892355,0.0001727782578692558,0.002425045741919105,-0.0024120588832846086,-0.001402079766596684,0.0020453960402266433,-0.006131397065493597,-0.0010997091742741744,0.0042480804088769605,-0.006880706037134521,-0.0030366267105196333,-8.42600573637539e-05,-0.00690071958917532,-0.003718997288843439,0.007933557117776173,-0.005051587599115231,-0.00021773295288261133,0.0004670560840674737,0.002963970177997622,0.0029061955650090837,0.0003934508600874906,-0.005017002717761315,0.001851382519134783,0.0012988516570849444,-0.0014999378653967387,0.0021549830057105194,-0.0011685784255085,-0.004671336689135713,-0.00040170102141115813,0.002177410600051045,-0.001793857464508208,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0016122526226022627,0.0018840238920301952,-0.010371919048377058,0.009093318316946434,-0.0034933368917071314,-0.0007391259948175066,0.01103956785086978,-0.004401735116784554,-0.0006484079396493223,0.009039740674526682,-0.004872572078641036,-0.00797638766774077,0.0026134730708207024,0.0031341844885518885,-0.006577444086291462,0.004336507785364772,-0.0005581069875581761,0.003527951851406098,0.006744737871710049,0.0052094083438404114,0.008457078118002156,0.010096035562717582,0.0020126048010871405,0.0045607404192862236,-0.0021614403489894534,-0.0004096946094249868,0.006846195846924274,0.002138575490512305,-0.001730761668208826,0.007195989730169414,0.008418750148275235,-0.0013816783316368088,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0019375693786252413,-0.0007511168846107304,-0.0065316910523226576,0.00012003672419189149,-0.010604075335091745,-0.01040165418752657,-0.0016293342092919263,0.0013631863187664784,8.74735534341342e-05,0.00408588063680932,0.006214751702503554,-0.0021513796885112026,-0.0030351054496102346,-0.0014679928464358645,-0.0056679520865678375,0.005176152779247013,0.014066545387002848,0.0022217300314841815,-0.0003587969015083257,0.005806923106514039,0.0043010884325882445,0.007284195254280435,-0.003395951508957754,-0.0013408338764394087,0.0009799902914177018,-0.00623719950697022,0.003880329288714553,0.003407330974177103,-0.005227437415159641,0.008577215745855536,0.005072259594925329,-0.0007942165386789754,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.003102493295711253,-0.0020496745216334704,-0.0015653922882440288,0.0008100061547921374,-0.0007604233273210451,-0.00020548990290415102,-0.003537959693461352,-0.004177174336479927,-0.007821737389745582,-0.0005178970943672763,-0.001805927901128355,0.002613338652581257,0.0006048146718507576,0.0010598935101668744,-0.0017502076065227857,0.010301227927768355,0.004098094667405306,-0.0030035971937566516,0.0015400970168067598,0.0024790770288546727,-0.00482366800192135,0.006347025601056833,-0.0020573373010323837,0.0050810523252698536,0.008725423346565465,-0.007084182910990268,-0.0010454304588248815,0.003544208333590082,-0.002643928858851679,0.006834186545130903,0.0039058713220956128,-0.008692383236929708,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.00024966987727383013,-0.00024254634152813415,-0.00927131793064164,-0.002981903132958401,0.0026122672634689738,-0.0035863880939772225,-0.004755009384111806,-0.006433932218882163,-0.002698082316989202,0.001848526318529008,-0.00029996998920197806,0.007479192571022439,0.0034855151089240527,0.004687729845692687,-0.005966003772798069,0.003566274730142788,-0.0010676602102358346,-0.0012205919522126608,-0.00020832929753747685,0.005452874800602174,-0.010475414952086537,0.000997651171852784,0.0034377418620251364,0.002145621587823241,0.0028393843511882676,-0.0022885315010475952,0.004785350752657796,0.002677506300310536,-0.0034623747852595395,0.003960487831346545,0.0021827600489215705,-0.006166510448760817,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00013887150654389108,-0.0012473769244833524,-0.005245139895205963,0.004119753004450448,0.002385481626283183,0.0028726528413981103,0.0011896315455742633,-0.0022114965242065565,0.0036286293892280486,-0.0010812415583954843,0.005263328557628633,0.005841039085386801,0.0024688604835185345,0.007255906821565468,0.0026934686810986134,-0.006949386541041776,-0.008365384638766736,0.012002361941130761,-0.0008304975392589726,-0.0021209922270793652,-0.006402134824652087,0.005169671855901098,-0.0001782943791178091,-0.0023635581648869023,0.002911280222809691,0.003159242845378565,0.00023114602973613163,-0.002856224549422624,-0.005538976168324983,0.00689216210304166,-0.0026302869696310685,0.001202299671368,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-7.606022642413926e-05,-0.0017339912107174245,0.0011453124051719933,-8.4913816053325e-05,0.0005677249921728911,0.0013566472100605465,0.0033310701810915673,-0.003115335434897048,0.0007339687265204378,0.002747743055445495,-0.004616781981546703,0.0009270875684990902,0.0005170413777817668,0.003727138641797816,0.0034594217800537363,-0.0018529426135359295,-0.0018132619907547491,-0.0015634785761657497,-0.001327462177857247,-0.009891253452838528,-0.007059288047308257,0.001667623774934167,-0.004665555218479494,-0.006451421132192682,-0.0017580585556755512,0.004888240585065946,0.0012846125556875568,-0.001726017880177575,-0.007142612833922417,0.003416178192498689,-0.002559830697539599,-7.009114270635424e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.005313585780170938,-0.0048987127595996926,-0.005656877992172456,1.615865548985749e-05,-0.000343823209260088,-0.0038741778930278586,0.0015938070040202573,-0.00023378474902978607,2.9000129856315683e-05,0.0008741938538482631,0.0017943379012175728,0.007386814080596277,-0.0028953144488290815,0.0013964434674991122,0.0034450018185117923,-0.003927927130377046,0.003969841779241841,-0.0011998191272725252,-0.0025472480902156923,-0.0008447531659858395,-0.0019123353292641837,-0.0014454402699195503,-0.007408819356952012,-0.0021119212827340173,-0.0010328761254984704,0.0004373667562795323,0.005638336308724468,0.0063370778831378285,-0.006877689320248985,0.008291900884499225,-0.001910615961879793,-0.0037308703282755784,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0008144379084242391,0.0036174000331418966,-0.003790237830482915,0.001940722929467252,-0.001650650721542558,-0.0017746156682834245,-0.0014370687655484672,0.0048405540492774055,0.0029627486836106397,0.007054206025453402,0.0005794606904517931,-0.0006309847779822635,0.001347259215743999,-0.004112858672141878,-0.003155296897749568,-0.0056377587555598106,-0.00608765055804375,-0.0022414158187343877,-0.0028323496986132424,0.003768489683169754,-0.0008982242329488196,0.0016287721554426391,-0.004378614618223418,-0.00607357210899078,-0.007113062203527196,-0.0018625645912121627,0.005437836941863846,0.011686964786846967,-0.005550713478098323,0.005392799168026831,0.0031368709049916254,-0.010292134470895754,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.000672259958689026,-1.860240566387724e-05,0.0035167104449980633,-0.0015852025022857123,-0.006704682380901108,-0.0011273488177559782,0.00490523121256458,-0.00658685047146776,-0.005162337776810331,0.0045894558154972705,-0.0009856961761260578,-0.004221468490834443,-0.0003465356887141524,-0.0032975486672053743,-0.007678600823992331,-0.004255317950264318,0.0056354897482048345,-0.0011856907935727814,-0.0003488155252043019,0.0059784335608519005,-0.00439407162642186,0.005640348980344713,-0.0036197833940562114,-0.009100352576690297,-0.0030817107730970635,0.0005676030563403204,0.0033157773735601657,0.003753852271322758,0.001199669003137025,-0.0008782607079338616,0.006019963865441274,-0.0008690360462369913,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0049732608998342125,-0.003240198206367174,0.0010335594279902586,-0.0013355251959294885,-0.0041330449454979375,-0.004065861865729238,0.0005190350766611822,0.0022710485935226485,-0.0020878626851231117,0.0038288303655247334,0.0013147064351231909,-0.004187104019236832,-0.00305118676792064,-0.00030722079630300105,-0.007856288619117874,-0.008025029898814784,0.00012703961053318525,0.0021826014916881604,-0.006117404046433657,0.011568043194368632,-0.004846643708456853,-0.003994574925353208,0.000467444568141597,0.0026397451659814783,-0.005881460941120671,0.0029596543708904433,0.007658663283259934,0.002394834270331507,-0.001745873632180678,0.005509245371086767,-0.003098127024916422,-0.012683272182378648,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-2.066796541910112e-05,-0.002382662108738498,-0.007705810450295549,0.0018681806890183223,0.0011377908723719846,-0.003848949935140561,0.007473340087985218,0.0005438851497898636,-0.008299427327373396,-0.0027672797371103485,-0.00301293313478786,-0.0051282105075697625,0.0024958663624690828,0.0005803689931793789,0.0009644863986758744,0.00836259975786297,0.006614926240434893,0.0002837835770733516,-0.008627547761405738,0.002616523726783984,-0.004493590581982926,0.006295211401536941,0.005165085794182179,0.011551770932952465,0.003012869087152139,0.0018453420559451726,0.0007391582555293543,-0.0017147356506522892,-0.00430177770420534,0.007860689130102782,0.0015951094896992462,-0.009264439113853573,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00017953975793533268,-0.002979954116340334,-0.0019436801775077677,0.0031953291832839017,-0.005173335184820972,-0.002408293126724094,0.00343797359743262,-0.006025347833796587,0.0002746807211097365,0.007157810402781218,0.00029045994968974424,-0.0007771607303477414,0.0015523536414880743,0.0035672585191236315,0.0010006938202128403,0.005519025458804312,0.01118296933445737,0.009281175004834916,0.002266552110779381,0.004991327241514746,-0.014186879923742726,-0.009291655574457743,0.0006777156029735286,-0.0005921105730630009,0.005066553449270236,-0.0015580129546196827,0.0028671382953354024,0.0027360235620199386,-0.0035688419189386627,-3.705719415630409e-05,-2.884248481784486e-05,0.0006189096770622614,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.004129178051771013,0.0003653514988513084,-0.009609826827881694,0.003115981844956775,-0.004267616077185785,-0.0022725540539186213,0.0011769750053643952,0.0011732716735565476,-0.0017759282941247649,-0.0021109577306871923,0.000620332815568695,-0.0008963974912829547,0.00021545632663525597,0.0046029914067435345,-0.005134414715963605,-0.0013751042099279132,0.000717096646486268,-0.00770112018231533,-0.011459686969516311,-0.002020691462696887,-0.004159849763777675,-0.012483195918952299,0.005690258782999001,-0.0008749983903739057,3.812278933352402e-05,0.009939096609711894,0.0058029552381944245,0.002530016566173555,-0.0026785868548742523,0.0002488741576787896,-0.0005836610317335896,-0.00564949288770373,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0013900165247382992,0.00151819620895393,-0.008938406965253174,-0.0013867031828891398,0.008866176172898449,0.0009855627637870039,0.0011484755697409468,0.009270497446298848,-0.0015416252552864175,0.0003560756046171635,0.004365002106046823,0.004078534882214371,-0.0019280730813162027,0.0002646060436207894,0.0020940867772454813,-0.008607748948357443,0.0027770360738410267,-0.004046598817358578,-0.007965188444858001,-0.0014536913232653325,-0.0009002350375038904,0.001585158993333639,0.00947823589836966,0.0061993091018799126,0.008848387113776394,0.014955285315378096,0.004127857654460537,0.0023965714617576613,0.0016443378432518673,0.006140347152772391,-0.0034827714895244084,-0.004979418783487511,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.001648366782436925,-0.0016531425447273553,-0.008659092733951473,0.0058633540355182414,0.0066907901263354285,0.0006694817152577622,0.006137758126671573,0.008447151160483413,0.005274278834229063,-0.00036183229092880777,0.00051434374989306,0.002969831957279195,-0.01006883259493159,-0.004328407765536177,0.003219257841966805,-0.0032079018486931787,0.0002415875671686663,0.002532118089942402,-0.002623546782066435,-0.013303743520702144,-0.007423806214139349,-0.00508178002403561,0.0025359251540856124,0.009907599748680175,0.006842521215463118,0.007279963863429926,0.010705427602183442,0.0014079933934111584,-0.0038291288977705955,0.007313151332926934,-0.005181194068147296,-0.0010695457549773307,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0006565711823278152,-0.009295675241658967,-0.006262138266230258,0.006313494133215877,-0.0011622867866832776,0.0050843372961335434,0.009821630254570122,0.005801034705754334,-0.00296142117564484,0.0015861317823247904,0.0032442603255527043,-0.005930007901475178,-0.010600869245036441,-2.7569523353161403e-05,-0.003941754525356,-0.005321957365746552,-0.002266646514612733,-0.001256204655805603,0.002470790086437829,-0.0070021050843312145,0.0019534574096454916,0.0030750876518961133,-0.0038171105426390113,0.00985196391073448,0.013491870215339883,-0.0007309826276175036,0.012489368158548493,0.00034867326173951193,0.00185188551205417,0.00430393586613044,-0.0013486216917574132,-0.006631923512374687,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0031848335089337625,-0.0022933031166309,-0.005444783505027239,-0.006434651787677697,0.0011292573193201127,-0.00040870726695875693,0.003685479351912007,0.008331101560989915,0.00012360450833581998,-0.00919595831040658,-0.0018642745329009336,-0.005519293205687352,-0.01051834069171861,0.0009660396318289739,-0.002090821629171246,-0.001784693243588472,-0.006402589619752262,0.008748863016623695,0.006800902457116598,0.007919590218972638,0.008402782336991954,0.00977555513953174,0.005654990541036775,0.008318428238119168,0.005205964600877866,0.000439780100095542,0.0010236728319920766,-0.0032436953553722394,-0.0009051632033727591,-0.0017210033199612097,0.0028973235635121894,-0.00031249793970141376,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.005651361239324985,0.003632647235333257,0.0015976305710592319,-0.008938120962380287,-0.0009196271029262603,-0.006199220707273393,0.0005156378558607282,0.0010209351222490327,-2.3137444503601365e-05,0.0021139803295423414,0.00786672047505485,0.001755779724886012,-0.0036899667454822326,0.009437147152286598,-0.0015344274941170855,-0.003056947549958483,0.0030690652049886738,0.0067271752021544826,-0.0029882682862801472,0.004197880069155473,0.007865677683034804,-0.0035791673553924623,0.0018393206175722197,0.00908861248358367,0.0037711322143307037,0.0027747497479457756,6.700967615047569e-05,-0.006399960617601646,-0.006149789175793629,-0.0027486062593797276,0.008877330458802141,0.011498127639582384,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0007299604074644445,0.0026643069621736307,0.004436596828425999,-0.006238572329670132,0.003411349788482704,0.0006202415346472996,-0.004169579615448648,0.0002628576226954552,0.0025534474255972605,0.001249922411593364,0.0020202103363934345,-0.0066724264599546885,0.003546139690600663,0.007650772491284607,0.0005518807346544481,-0.0012658105698736938,0.002959452351877383,-0.003088720592907092,-0.006138978331697802,-0.0035536537405606596,0.0024084838133527093,-0.0057403935458425395,0.006843679879369948,0.008655235952383857,-0.001542598611578381,0.004099888456448418,0.0010276663878194716,-0.0004647783451478305,-0.003775629899967736,-0.003461068509071873,0.0057401238236261705,0.0037373921230699383,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0047682626170151175,0.0010008287412913229,-0.0012942635713482096,-0.0015268270275077339,0.0002559897993260243,0.0022908468273503324,0.0051797988362018155,0.0029584240189067337,0.009548777531086381,0.001551149534376629,-0.005690792655172072,0.004539530593308727,2.868725505169155e-05,-0.006128964931384243,0.0046360477452999805,0.0006919438715475809,-0.004798005878384948,-0.0035506505623268056,-0.0038067670215283476,-0.0014846904471420988,0.00015040463062149958,-0.0007240907735870464,0.009331854919516634,0.006598580604836938,0.0015713727847940253,0.0015919170941392318,0.00983752591162236,-0.001136502708507655,-0.0033214833718054368,-0.0025824658094152427,0.005692172808952819,-0.004499840304483737,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.006549033163342571,0.006884241085397732,0.00038212989594186474,0.004574814431085232,-0.0057016042458195035,-0.0007753942622769959,-0.004504255591849055,-0.0027301549037805867,-0.0002226276399968192,0.005382752264736193,-0.007561052310304675,0.003952604134700184,-0.007426342991972148,-0.010278611236380903,9.830731828356947e-05,0.007051058405153459,-0.0036095686782790597,-0.007222038475292972,0.009400794707132792,0.009128867754027999,-0.0007435379174207062,0.0002993118265261839,0.002782012073924937,-0.0015165232041765304,-0.001449337599161519,-0.0007827472634053527,0.00617268074168161,0.003078755905301126,-0.007418326618706991,-0.0026370692856997964,-0.004383195837217628,-0.007284317760883823,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.002237930953042907,-0.0034151450728487705,-0.0036322605966668206,0.004726448172441269,-0.0023198971498823236,0.0035843241918521616,-0.005661286577789509,-0.003147832032459343,-0.0003002661852365265,0.001587653843794549,-0.00721546796946402,0.0010512341774405395,-0.0014757025108447055,-0.003270466921373269,-0.005115607856862553,0.0037560717277805786,0.00054290463893849,0.003727160182694898,0.006374788030427839,0.01117825459237178,-0.0003989652133790513,-0.006973621733007899,0.00016660495982184304,-0.005373647810009232,-0.0068041876765688345,-0.0030170946344744956,0.00022783673214391988,0.005137742123575795,-0.003793257172253852,-0.0013110022318105694,-0.004508916652422587,-0.004268248752982439,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0005672318091702025,-0.005729562035160557,2.8993642424858876e-06,-0.0018152555296537397,-0.0004970677099902844,6.967663554030528e-05,-0.0013473042208975946,-0.004005913188422989,0.0070683157049597385,0.003956039444108112,-0.008096727927254169,-0.0019088404220062847,-0.006704394064974208,-0.008060384212912884,0.008696970183112976,0.0012564544474048477,0.0013401008582244443,0.001838121534338243,0.0005521749793304043,-0.001602997131958891,-0.0061704902638521205,-0.006491932189827201,0.007062344362944491,0.0028633402921850893,-0.004087997479446407,-0.0012486391872651614,0.005351014115038023,0.0014923319205609497,-0.0008229880270799937,-0.004423867470355895,-0.00010641454266750287,-0.004269771543826093,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.00858914589535776,-0.009278192058396684,-0.0006887442352141454,0.0008959408358272174,0.0009072314634253846,0.0024419776074371888,-0.0010417750809896603,-0.0004094647836980316,0.002814829416531469,-0.0019271448681150965,-0.006625958295558926,0.007122136056179646,-0.0027398899064947054,-0.011613554444340318,0.0020263953335078215,0.0026636904887563043,-0.004544077024567597,-0.0069157799138893205,0.0028787475981677966,0.00012745343420760772,-0.010676665275847924,0.002300936785321341,0.007508974503636188,-0.001932547948014497,-0.00351555205044316,0.004675857191148428,0.004633194204907088,0.0026942141499327063,0.004180130256230598,-0.004163705099480744,-0.0037492814379173835,-0.002986646821933109,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.00010552240300622431,-0.0013039424960848167,0.0034080714828242822,0.012449704316222826,-0.0066534290696323205,-0.0014627822580776098,0.0003990123630436551,-0.004930317924513374,0.006999789721238562,0.005063195571450423,-0.005037761756361568,-0.0031100741604661282,0.005780368143813348,-0.00820140524277324,-0.005678563998330825,-0.0015828491118140347,-0.0013344284407252726,0.002007094459530278,-0.00041975146855930973,-0.002049738025463038,-0.007981893512771766,-0.007722034484085228,-0.001988303245045307,0.0017971605114133473,-0.0015518332910091728,0.014110028091114328,0.013884051470958406,0.002637101184141521,-0.009147181145618102,0.001962657163549625,-0.0048561750896994535,0.0009417965269510918,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0008346964711262603,-0.0034902993427618286,-0.008864998183364786,0.007859052430165558,-0.003662816130030843,-0.003458612778789325,-0.0008352704723001017,-0.0025296181164164693,0.0005475966123233,0.005199099505575362,-0.002125978025928102,0.0007901300013052229,-0.001009544990588109,-0.012077812932799326,-0.005314230410199729,-0.00942284513406642,-0.007783614585717314,0.0031086910310595983,0.010855623437541578,-0.0055087156005432965,0.0033418062146517535,0.002613821065934558,0.0037769073882805565,0.006758244141097883,-0.003279246909586678,0.0052609707665327455,0.010216376935145976,0.0023713386157272484,-0.006844863906338016,0.009436780642573642,-0.007136711201880812,-0.0073786061297666135,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.005403621533024335,0.000765241731806342,-0.0071935947233115255,0.006661973612818967,-0.0004574383247495407,0.00412097617440133,0.004746509035271079,-0.001508337794369006,0.003957541198249802,0.005963480274089034,-0.006142842904414085,-0.0005632811253425086,0.0006684271169258914,-0.010208550269280895,-0.0021906876235849174,-0.004967333548525835,-0.0064042210118154955,-0.0021940675316092693,0.009646506436518744,-0.010248800102334457,0.0036978672045414507,0.004905998407418984,0.002124749996962907,0.004732350695503916,0.0036545855497701163,0.014384900539393746,0.007247492736655055,0.003105446816805197,-0.0013261823515043358,0.004413930337322202,-0.0061365795285057345,-0.0040836957676064125,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0032387445904402397,-0.005885881421575251,-0.0012145433134017304,0.008328398419509506,-0.005931987600641021,-0.0014349678427781655,0.0020352221470490983,0.00030588871589723254,-0.000594806211573155,0.007437460290175284,-0.004006311241952063,-0.004097590178248579,-0.0010013075316150576,-0.00783571842290486,-0.00990980437212402,-0.009351078348929724,-0.005871304932072982,-0.0019083797777963002,0.009584217371800298,-0.001369337631899652,0.005956441584488097,0.007205809603515915,-6.79073516190694e-05,-0.0010532723856010663,0.010310354863372262,0.008740147457145837,0.009214243769558796,-0.002608960418258607,0.00437794227609135,0.0064278152433427365,-0.003977721216905603,-0.0032873671072392394,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0021383052654542992,-0.002313306652535293,-0.0031933319405049194,0.0007710455364348763,-0.006582215490726992,-0.003279915758032695,-0.003683198549949878,-0.0007781677516645494,-0.003882775729796365,0.0013234274577904107,-0.003192377813745332,-0.0037377500440246977,-0.006396568853887366,-0.00843118649990781,-0.008311300414727616,-0.0041444104135893445,-0.004960071845446568,-0.0017124547778117106,0.0034897043316192674,0.0004098842379383154,0.004817559621210496,0.00930916321623881,0.007056198880566755,0.002939050701015572,0.006304115445708715,-0.00573969923173153,0.00020847838550943184,0.003182408777762481,-0.0025232203079694556,-0.00033474801184535093,0.008318715032629317,-0.005896668269133294,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.005110096995993115,-0.006011132999113961,-0.002325813044582517,0.0011988237790593193,-0.0037480496402463024,-0.0005259565213603034,-2.396464493836369e-05,-0.004778898052457548,-0.001400647516728356,0.006489428112874856,-0.005669590614248276,0.0034934850279980424,-0.005636040055142223,-0.008376812634558856,-0.0025733321362602615,-0.00176034223983622,-0.005364618830205008,-0.0007813782660808697,0.00698876153697274,-0.0012085775041969504,0.0029282696081339376,0.009192526774814825,0.0023834315712549176,0.0012355250268556422,0.0027412506162427007,-0.0018918116838554798,-0.0037567954665468062,0.0006648747679003789,-0.001863619233118826,0.0035756187411710217,0.002616103637502048,-0.002172566645489222,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0006911258085262869,-0.0015399019912739566,-0.006183877166449596,0.0071218604035777205,-0.008438041642048994,-0.002740264401637069,-0.0007690280634069306,-0.01137384627812902,-0.012491629616114653,0.006635865163327648,-0.009524258524253086,-0.0016449757991680984,0.0016016513245762328,-0.001720677774849504,-0.0002328767340335033,-0.0053243117290599894,-0.01147248042519167,0.0001606603968995194,-0.0021433456350119593,-0.0036184274288979315,0.0055647765760149,0.005752066480405454,-0.0026193178639992297,0.0022220402553953657,0.004246603829991942,-0.0068602747985879505,-0.009754170610848437,0.0006749405871475258,-0.0037331376441152963,-0.001419969165106376,0.0006525280102859758,-0.0033604581891922883,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.002886496880842931,-0.00299895520828344,-0.0043973943771652,-0.004236359405333597,-0.007471166188776476,-0.001371409925881588,-0.00033359963677196357,-0.005012222344628048,-0.00252991368647181,0.00605833541918557,-0.0034521469799597203,0.002775734127212964,-0.006303638659404809,0.00018265078949869298,-0.0027287083467692316,-0.006843840402096626,-0.010198242470643794,0.00735396080814649,0.0027808819113132434,-0.0021097915383044125,0.006687117377146701,0.006865942458748979,-0.00513161783056384,0.0038447348866078863,0.00771763093015184,-0.00869971739091567,-0.0024164504444876837,-0.0021756935402357878,0.004289400658665721,-0.005347993691334711,0.0022855868668995014,0.003338514418189638,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00013189335418205636,-0.01359283341055014,0.002673818987706739,-0.0005051477937271774,-0.007874246142636869,-0.0050577045400335835,-0.006027338110549081,-0.011281430392167889,0.00019368379984999954,0.01618397640916459,-0.004147063750728501,0.0049030388529163705,0.0023472821347286514,-0.006540032843063193,-0.006506936462316041,-0.00814976368699401,-0.009904913470548437,0.0028742070809744304,0.0036381985262345868,0.0006766344278115391,0.002784160098111656,0.01023206069504502,0.0038249231403253456,0.0015404456082858814,0.0013965111862839724,-0.0013895463181706838,-0.003518903149548075,-0.007781343601807594,0.007851528280120163,-0.0010554484807224751,0.003061174025398502,0.0028052286928610714,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0063570543165248706,-0.009904105021816854,-0.004125186521784683,-0.010386586293872785,-0.0063221987963898605,0.0010081999411567085,0.0025288249381825545,-0.005259046218881541,-0.0013099150510385192,0.021244779024263884,-0.007400555203000411,0.004929580104792395,-0.0007437015531861663,-0.00325322488846435,-0.007917762223005251,-0.0012128030299127575,-0.009723310386267135,0.004320693254075894,0.00015125512793830108,-0.002556725686687471,0.007789683810673829,-0.005880258936319257,0.0062130202150152605,0.009622025040034034,0.003211134852202358,0.0002947265926683557,0.008511345886924622,-0.005090051597737655,0.004314869737862196,0.0004539971451634016,0.0064121592162057735,0.0007226717714953851,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.008078749887734011,-0.009913069810244273,-0.012821633729773685,-0.006749305271800893,-0.004153300817338814,0.0016911998939422295,0.006875929362813759,-0.0014534824571532919,0.0020363716283483655,0.02642808153725141,-0.02096877534726328,0.004579674719097308,-0.0038440098055406045,-0.01501764262716127,-0.011828993635519312,-0.0036372248504568387,-0.017421928686821294,0.011898703381252485,0.008806583925186717,-0.0001016546125123802,0.005740777183894739,-0.0023923220595720787,-0.0007172603761538589,0.01217324778057379,0.01443102324153803,0.006643028838385584,0.013821891861892704,0.0007772807488775932,0.0072394230906941,-0.0056622487476107744,0.0014755385629204012,-0.006171656000060197,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]],\"type\":\"surface\",\"contours\":{\"z\":{\"project\":{\"z\":true},\"highlightcolor\":\"lightyellow\",\"show\":true,\"usecolormap\":true}}}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"scene\":{\"camera\":{\"eye\":{\"x\":1.87,\"y\":0.88,\"z\":-0.64}}},\"margin\":{\"l\":65,\"r\":50,\"b\":65,\"t\":90},\"title\":{\"text\":\"Mt Bruno Elevation\"},\"autosize\":false,\"width\":800,\"height\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c29cda2c-48d7-49b4-8aca-34b8226d8865');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# fig = go.Figure(figsize=(24,12))\n",
        "\n",
        "fig = go.Figure(data=[go.Surface(z=z[38,:,:])])\n",
        "fig.update_traces(contours_z=dict(show=True, usecolormap=True,\n",
        "                                  highlightcolor=\"lightyellow\", project_z=True))\n",
        "fig.update_layout(title='Mt Bruno Elevation', autosize=False,\n",
        "                  scene_camera_eye=dict(x=1.87, y=0.88, z=-0.64),\n",
        "                  width=800, height=800,\n",
        "                  margin=dict(l=65, r=50, b=65, t=90)\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arXeGxqGl2Gs"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rddVS_MMn7kE"
      },
      "outputs": [],
      "source": [
        "z_op = np.real(output[:, :, :, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4CclFG6hNef3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GV6bG73oWmD"
      },
      "outputs": [],
      "source": [
        "z_op.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYtxET4csZHw"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsqUDwLPn7qk"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# fig = go.Figure(figsize=(24,12))\n",
        "\n",
        "fig = go.Figure(data=[go.Surface(z=z_op[20,:,:])])\n",
        "fig.update_traces(contours_z=dict(show=True, usecolormap=True,\n",
        "                                  highlightcolor=\"limegreen\", project_z=True))\n",
        "fig.update_layout(title='Mt Bruno Elevation', autosize=False,\n",
        "                  scene_camera_eye=dict(x=1.87, y=0.88, z=-0.64),\n",
        "                  width=800, height=800,\n",
        "                  margin=dict(l=65, r=50, b=65, t=90)\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z_op1 = np.real(output1[:, :, :, 0])"
      ],
      "metadata": {
        "id": "FeiNufBbXmdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z_op2 = np.zeros([80,128,120])\n",
        "z_op2[:,:,:32] = z_op1[:,:,:]\n",
        "z_op2.shape"
      ],
      "metadata": {
        "id": "r78QCBeFXmaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# fig = go.Figure(figsize=(24,12))\n",
        "\n",
        "fig = go.Figure(data=[go.Surface(z=z_op2[20,:,:])])\n",
        "fig.update_traces(contours_z=dict(show=True, usecolormap=True,\n",
        "                                  highlightcolor=\"limegreen\", project_z=True))\n",
        "fig.update_layout(title='Mt Bruno Elevation', autosize=False,\n",
        "                  scene_camera_eye=dict(x=1.87, y=0.88, z=-0.64),\n",
        "                  width=800, height=800,\n",
        "                  margin=dict(l=65, r=50, b=65, t=90)\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "VLfeMEKwXmXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AVXBGfK0XmRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRY-y9-7n7tS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jI2YW-gEhGGe"
      },
      "outputs": [],
      "source": [
        "z_act = np.real(target_2d[:, :, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW42rwfphGJt",
        "outputId": "64bc93e6-35ba-4574-ad79-75f0087a8e83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 128, 120)"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ],
      "source": [
        "z_act.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "JbUwsBD_hGL-",
        "outputId": "af618e80-ffc7-49b8-b752-67b0179180e4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"c44a9b8c-2bd2-4e1c-a86e-772256a1e093\" class=\"plotly-graph-div\" style=\"height:800px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c44a9b8c-2bd2-4e1c-a86e-772256a1e093\")) {                    Plotly.newPlot(                        \"c44a9b8c-2bd2-4e1c-a86e-772256a1e093\",                        [{\"z\":[[-0.02338981289701287,-0.013652511615249299,0.043319715122359395,0.011748795887232545,-0.017121741380442795,-0.014471836507457857,-0.06109599241277979,-0.008118471662142399,-0.11090765034348665,-0.0532279788401978,0.0022952670109573693,-0.009655326126117341,0.04913308538740478,0.0011619424686835468,-0.01400121648808755,0.00872140667775172,0.027511976464919086,0.04419605869358274,0.059308661170174984,0.007813499687501616,-0.010489260659782782,-0.043159610011025855,-0.014763629017965508,-0.0014555472091535928,-0.0589021272142206,-0.025074949305829587,-0.045610882108121434,-0.03025615710494523,-0.046590933708296985,-0.036085801636047014,0.005828768086176239,-0.033042602137880635,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.021429567976983584,-0.0036067819968719993,0.013054132724049154,0.004890154815821841,-0.01347919723618136,-0.007531963060406615,0.0008179531680312498,0.0012789584809183821,-0.002000369226972218,-0.00014322732089599603,0.0081306365353423,-0.0005355588629118031,-0.0032450746242241335,0.0026658729445578253,-0.0004048461373666961,0.013759860431367196,-0.0006881094201396006,-0.003709866369695738,-0.00022259163232939567,0.004425614737941523,-0.008081179450740621,-0.008795885567039023,-0.00447844257664916,0.0026254605970195775,0.013887653433209291,-0.003699524739323933,-0.0032553233132087724,0.00619321833039676,-0.0032024740917607226,-0.015058577561031334,-0.0037476211131990114,-0.0057364769976396045,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.01185923692542726,-0.000848261381310002,0.008292251047140674,0.00650505994502756,-0.003632796719486962,0.0036821099838572303,0.007891637948218594,0.0021036666223586686,-0.004503067059765202,-0.005900706279206124,0.0031382085734439746,0.004998921101664933,-0.001132021821317804,-0.0032862286861031625,-0.0029729519786507548,0.003406646878640767,-0.0008279359750508299,-0.0029749627830470146,-0.0020240426948175427,-0.0006619688695378794,-0.0016334264071302214,-0.0009080811207145687,-0.00434072757053866,0.003428747227902191,0.004207871732916309,-8.291063848072237e-05,0.008381077945499837,0.0021966372320543614,-0.001454321490433107,-0.008694055345733047,-0.0016785501485417713,-0.0010626934585170284,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.008713520222001156,-0.0006967829170513477,0.005449329971429798,-0.0007621562094373255,-0.0024711092773268533,0.003049113373442688,0.0015280627162314094,0.002355581716102491,-0.002318766521065752,-0.004517804908031915,0.0033980293092608477,0.0024043009880318133,-0.0005894674500332183,-0.0012611134675542285,-0.002635373635921099,0.0034817597706525553,-0.0009146467667923878,-0.001299825868736175,0.00015856591603832776,0.00014715381843205446,-0.002135753114716664,-0.001685815706940713,-0.004314540730189274,0.0018661570564310428,0.004138470382532329,0.0009955043988708703,0.004006588252345475,0.0007904688838521432,-0.0022017366637066636,-0.005186356091958552,-0.0022123618053296514,-0.0007446435405636432,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0056611350530576,-0.0007249524960905473,0.002776419085856435,0.0014803288086870639,-0.00048139281741561325,0.00020191086828808233,0.002160774361346087,-0.0007678338823866546,-0.0009405173053435107,-0.0037234588835887003,0.0031890048175487735,0.0023592594233138643,-0.0010270230832220815,-0.0009011741943563607,-0.001253335903371334,0.0021533118087686616,-5.507117326094578e-05,-0.0006754252199523705,0.0001369392874576747,-0.00054310746239239,-0.000981905858310759,-0.0017274762264945052,-0.0024233519060780427,0.0004057916806099089,0.0012925602119513958,0.0009081368521905534,0.004988126197195899,0.00304110375955489,-0.00013923173736689074,-0.004781122737714731,-0.0013761807765002472,-0.0008894336860455836,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.003924335560583969,0.0002496456725004517,0.00277117381858749,0.0010460304399118586,-0.0016087942643040409,0.0012294760854215166,0.0016474549657369982,0.0021268682375762795,-0.0004963980185330655,-0.0017189417279328816,0.0020239054905579713,0.0015630306250496813,0.00043939564425220966,-0.0015210560549402234,-0.001016286691301749,0.0011774515483095134,-0.0009382083191100633,-0.00032551409708867196,-0.0012321076789269696,-0.0007437757281712669,-0.0005081142659378007,-0.00015151089753295908,-0.0019578068634359368,0.00015898605487856817,0.0015449149582204846,8.51692638973433e-05,0.0037942033396486173,0.0015150984369888866,-0.00029302383196283044,-0.003080897449305281,-0.0005823984132439419,-0.0006673956879844537,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.004448870711173345,-0.0010581887110764157,0.0025352947157120656,0.0010424055824852351,0.0004784842198885076,0.0003060228175724988,0.0013991630342062582,-0.0008980866801307836,-0.0027075610999536498,-0.003812726557058898,0.000989006210126772,0.0013022548692975119,-0.0013466878879127156,-0.0003980776889550931,-0.001637480710198421,0.0028131977471565523,0.00012383384635579773,-0.0016496117582201941,0.0011629070983665507,0.0006172478296502577,-0.0010899700304074485,-0.0010611875938509963,-0.0003547180071775998,0.0008552205705105575,0.003357698932213407,0.0015140526049112538,0.0019541648969140664,0.0010482177770494852,-0.0015021569526234972,-0.003582387467968353,-0.0013701198015402152,0.00043716880171541366,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.004608475840454787,-0.0006603225456054924,0.0019433625976857678,0.0009617805138653049,-0.0012987963140691239,0.00021954515550441127,0.0008964733873681636,-0.00010313742824085303,-0.0010116151579293601,-0.00243120728174069,0.0011950440207070525,0.0006857319825472835,-0.0008933566675394916,-0.0009521860787125145,-0.0008089972233133444,0.001965423966126627,-0.0004436077280424451,-0.0005374352845234312,-1.2757575169618522e-05,-0.0002588752987326957,-0.0013263060756552466,-0.0006332223941006783,-0.0010571376920674416,0.0009252145555992267,0.002144606847384182,0.00022405153470352824,0.0014151396664687434,0.0005595982081228319,-0.0011812800821756058,-0.0028554166363789642,-0.00028308167222726346,-0.0003663803430065035,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0039199814082950596,-0.0002656365263538806,0.00200018773708684,0.0006625808262730271,-0.001002699146423121,6.036683009714412e-05,0.00048223366774390817,-0.0002329791503009111,-0.0010530744408923872,-0.0020168100456034875,0.001043055540966134,0.00048222714311135935,-0.0007413940781807433,-0.0005901153021822997,-0.0009546332313757237,0.001299886929443405,-0.0002291096608618862,-0.00032512456262244254,-1.3904146954216405e-05,-9.546643950426849e-05,-0.0011030413836217762,-0.0009344991733308562,-0.0011539904044829696,0.0008148285565252203,0.00124066445891943,0.00019921471787143265,0.0013684134115481887,0.0004612669734283828,-0.001344111005482101,-0.0025564346933637174,-0.00036648237166146403,-0.0003578956010907068,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0034394900735346856,-0.0005867158058744909,0.0016956621465894974,0.0004088973184791961,-0.000811352156394265,0.00022975449901973087,0.00048166020776553104,0.00034077167717877434,-0.0006186341754397805,-0.0019717650527048144,0.0008167210048937002,0.00046493712889569036,-0.0004079267510407458,-0.0006802226370898041,-0.0008989982081869908,0.001237025826039927,-0.00044813590193453894,-0.0003601918054238257,0.0001309160585322761,-0.0001793319764751926,-0.0009748973125815529,-0.0007599111077908385,-0.0010063980414742066,0.0006336888433889782,0.0013622358305368134,0.00021545523354932298,0.0012740014982956767,0.0004672825285009358,-0.0010853113615524016,-0.002262498047883897,-0.0005619013416959185,-0.0005724316981576839,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0033479549219123023,-0.00043477096470100616,0.0015770321667871294,9.559466273504311e-05,-0.000808519652421305,0.0001248489482369371,0.0002578082530823254,-9.76587569546994e-05,-0.0007357358033878481,-0.0017017440284949335,0.000857914627821224,0.00041176996160254513,-0.0007070102605651982,-0.0006575319718034047,-0.0009099391690647042,0.0010962366309742368,-0.0003389392651830734,-0.000256414223516358,-8.54127926177197e-05,-3.273923429750651e-05,-0.0008601886855698855,-0.0005655941859586926,-0.0009856192005503407,0.000724847752165112,0.0012332252046374549,1.5466315318733459e-06,0.0010696599022341688,0.0004464047838344083,-0.0009799807744964358,-0.0020360060876949498,-0.000401815948514969,-0.000457300474959894,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0028338196745217553,-9.774789827050623e-05,0.0014311368351857322,0.00012452946589923774,-0.0007011438224573123,0.0002794072193106396,0.00025902108642438096,-2.2413540561420604e-05,-0.000758394939679701,-0.0014368628553211226,0.0006586362203174405,0.00021221566949503523,-0.000302474159602703,-0.0006078341655149193,-0.0005670117601087663,0.0011711626518533674,-0.0004678433391784212,-3.277294293066284e-05,8.173160450571543e-05,-0.00018517402990473678,-0.0006993550650429998,-0.0007508164875449026,-0.0007494612050820258,0.0006774863822999173,0.001047205775577168,-5.79931689375854e-05,0.00100943536275943,0.0004134235585169259,-0.0010092346935191713,-0.00199596805300224,-0.00032856496886613456,-0.0005764851985408982,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.002590427412754793,-0.00040287073645302454,0.0014506715278567507,-2.355949473173535e-05,-0.0008417896394676702,-3.372941270388742e-05,0.0001704424116243094,-0.0001789194580429952,-0.0006396227603410682,-0.001391403422840995,0.0005522236178654952,0.0003344723933741352,-0.00040829107633485795,-0.0005649507428515482,-0.00047860651516612636,0.0008967840274683785,-0.00024749089509914184,-0.00016551378088187782,-0.00013241124816326427,-0.0001964014382269989,-0.0006385889503807054,-0.0008619113935922768,-0.0005863678371789558,0.0004948105365601547,0.0009463215161583396,-0.00011920750732516793,0.0008623833949997154,0.0003163082697859535,-0.0011037941525743832,-0.0019430103107705983,-0.0003257129130641071,-0.00027881098559860956,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0022938677716776252,-0.0002989183543502055,0.0013701762611994317,-9.742058368100867e-06,-0.0007548315398049598,0.00019126887672226222,8.465888987673758e-05,6.991300762099972e-05,-0.0004359580607778319,-0.0015237421186734019,0.0005459662978738172,7.691821114282184e-05,-0.00028568785641209246,-0.0006093686971796559,-0.0005061553367386168,0.0009155625111705961,-0.0004262756865600294,-0.00011567977835111982,3.839986942147028e-05,-0.0001576700850889441,-0.0006819590691829726,-0.0007026302348276806,-0.0007874248370856404,0.00026170949999510424,0.000908782413617688,-1.3750099381222948e-05,0.0008726673661437669,0.00020980502843563934,-0.0010052967990548988,-0.0018535524068389148,-0.0004893773439909161,-0.000406444187092145,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0022644747923549102,-0.00033076784328551036,0.0011834531111067702,-4.785420679764026e-05,-0.0007269365530215423,0.00011938088658146823,9.402248072571066e-05,3.4805463410780354e-05,-0.0005678484571935966,-0.0014197887716593143,0.00042914234477741216,9.82799373635583e-05,-0.0005726190269429496,-0.0006873262062364865,-0.00048358402649673873,0.0006974503849007809,-0.00025141554385192395,-6.218890950269295e-05,0.0001235106447150879,-0.00019025662166853322,-0.0003594359470204009,-0.0008158757253846835,-0.0005840711172467046,0.00035161669118247444,0.0005871337812094361,0.00013834064767462737,0.0007845524424414645,0.00010132873036750525,-0.0009538328922838671,-0.0016407294738717485,-0.0005160436604872162,-0.0004480018719301446,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.001975155219281228,-0.00015010732591374049,0.0011932254313574708,-0.00014561311604833465,-0.0004893802238114873,-0.00012972336314905395,3.809667719492241e-05,-5.6359401789076856e-05,-0.000627534880149747,-0.0013824827111559536,0.0004319707752076892,0.00021760591548923986,-0.0003708809281152772,-0.0004517255401980303,-0.00047850234857955466,0.0004965739453655837,-0.00034755457159224947,0.00013757907941325183,9.108669020367495e-05,-0.00016148482394845093,-0.0005215220804331777,-0.0005431168890156971,-0.0005620582536894075,0.0005524040349375483,0.0004234470810926332,0.00015806520011719315,0.0006901223196894698,9.834966319258389e-05,-0.0007657515015733463,-0.0014812390810572645,-0.00037264187132654786,-0.00039631818188033837,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0020597027266461795,-0.0002118862238336578,0.0010081804341461236,-9.522110222867723e-05,-0.0005320293022863266,-7.108997247772539e-05,6.743447848710674e-05,-0.00014921926559582772,-0.0006663283845689547,-0.0011744741425532541,0.0005383181254599012,0.00015626675434378707,-0.000474488902579519,-0.0005256320804265638,-0.00038678377023905887,0.0005000228436278523,-0.0003477708443677912,2.80581115174533e-05,7.991718323422138e-05,-0.00017923508243378736,-0.0006551026131951947,-0.0007852753077569154,-0.000775939602193709,0.00042474581611877437,0.000338472030403974,-0.00013273403520965875,0.0007580675850781803,3.34142176280209e-05,-0.0010037695094505896,-0.0017293366015641055,-0.00040564133362537097,-0.0002925945000700438,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.002003922732201224,-0.00018619122089381677,0.0010862656267406504,-0.000422286459550352,-0.0006895350420068429,-0.00010331075436780767,-4.379682842982917e-05,-8.793018900667356e-05,-0.0006024567692105187,-0.0012255074463552865,0.0004203249220323085,1.4630492037250457e-06,-0.00014485729070440342,-0.0005880220627291919,-0.0004343203840907237,0.00040286092259599033,-1.1014645633131178e-05,-4.01096231870684e-05,8.096249222171592e-05,-0.0001842448114083743,-0.0004131382660438984,-0.0006931499988126923,-0.0006593368617995578,0.0005772514031264385,0.0003875789360113177,-4.9032261542663036e-05,0.0005443912653701224,-0.00012708587704305876,-0.0008393734073786206,-0.0016356506847645612,-0.0004840899583247052,-0.0006985531602824747,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0018785461588933388,-0.0002968749648891281,0.0011509583653500717,-0.0003530101160010332,-0.0006960938861264404,-0.0002389062077689149,-0.00014303663088923276,-4.9664561961119075e-05,-0.0005434465832479523,-0.0012897829666876405,0.00033429280558311517,0.00014526628306319665,-0.0002649845028808494,-0.000599370037806188,-0.0004454075504548971,0.00027158464210332126,-0.00012760965208638954,5.713149835291986e-05,8.303080862604165e-05,-8.542674377580732e-05,-0.0003814174935034872,-0.0006869887343326567,-0.0005472693343600568,0.00025193010465200216,0.00021825114779083798,4.354274280638372e-05,0.000545510309002288,0.00015082714549236265,-0.0010260925036175428,-0.0017387519652173826,-0.000384181382221707,-0.0005241596776688911,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.001851395530543042,-0.000276445051942129,0.0010755899800997239,-0.0003968865800267335,-0.0005892755005996902,-0.0002359475339309492,-0.00012680642714701205,0.00012818206282296876,-0.0007353992720475063,-0.0010884634220533717,0.00014101213180570563,-7.106799403304142e-05,-0.0004082245852015583,-0.0005961606568216234,-0.00027316447393211074,0.00023312801212453223,-0.0002774566553479151,-1.6257804043867944e-05,-0.00011712221492352716,-0.00028738216417712766,-0.0004962885334349656,-0.0007560296826678095,-0.0005424516519110505,0.0004066253874154505,0.0003181577926266829,-0.0001709958387643049,0.0005238892814600684,4.187172922458482e-05,-0.0008766887336122293,-0.0018657560439453856,-0.0003553602526054366,-0.0004987912864283407,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0018074524201359176,-0.0002259795670807316,0.0008488239600809051,-0.0004702376318752165,-0.0005139731897532765,-0.00011237860775814221,-0.00021143622808979479,-0.00013995422920222816,-0.000563837566040698,-0.0010623221057706317,0.00043365317776777564,-0.00021943763749317422,-0.00044266071812270225,-0.000848290424341712,-0.00026455672051285304,0.00010808278939077657,-0.00034979671560403397,0.00021979973668645358,0.0002370661760855179,-0.00033527693445972723,-0.000712805765785089,-0.0007089024114688008,-0.0007235586927488086,0.0002753587181045544,0.00029474094699138335,-5.626081732238452e-05,0.00037276185132287135,7.778876122196942e-05,-0.0008287527614704621,-0.0017824280645980547,-0.0005216569754225075,-0.0007463758143752202,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0016731033007742382,-0.00027800373943192224,0.0010072460677775013,-0.0005152191056475848,-0.000559243056654931,-0.0005265135665411583,-0.0002497612257050799,-5.9215653398699914e-05,-0.0005914490645874729,-0.0012102756174791878,0.0002902857353461474,-2.2150977099080062e-05,-0.0004310112604867861,-0.0008600375639980765,-0.00035497741446147705,-3.146953569392083e-05,-0.0003400958606256168,9.309458117158704e-05,0.00017025735630191933,-0.00044707357183602204,-0.000211045609294487,-0.0008701124342621754,-0.0005350491349401673,0.0003570357650589489,0.00016246838501816747,2.5614491369677266e-05,0.00044678875043205785,-0.0001369028629521494,-0.0008383170465890346,-0.0016527077733957645,-0.0005735200181409116,-0.0006723404624117457,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0015906759695259185,-0.00035683857216659926,0.0006175722632814815,-0.0005661215726711905,-0.0004192691860741683,-0.00041217288683637515,-0.0003980857424042447,-2.9562077202234636e-06,-0.00044800926210966787,-0.001210269657640559,8.081956906472447e-05,-0.00040765662892751256,-0.0006165818909377613,-0.000986451189612842,-0.0001810797317079107,-0.00010014683549140265,-0.0002796622690343001,-7.008360886249952e-05,0.00022537039738564294,-0.0004839655746579801,-0.00020962275602263677,-0.001047303264525102,-0.0005056610792828158,0.00021681716743720641,0.00032955569357152686,-6.732850472410335e-05,0.0004072204033787995,-9.26340638188951e-05,-0.000799491562070435,-0.0018754307307180134,-0.0007823992309310476,-0.0006471662552740138,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0015892658088581682,-0.00031173720923271386,0.0007295134946756998,-0.000780466861460218,-0.0005083272432299737,-0.00038075461280684414,-0.00044376396307627104,6.583250060044157e-06,-0.0005584357060134786,-0.0012559906819225209,-4.322326050181159e-05,-0.0004444563197239624,-0.0006480049742414946,-0.001017697362826528,-3.5489402358387485e-05,-0.0001982971322564355,-0.00036245138019879103,-0.00024700558378083185,0.00020122228722815012,-0.0006316164431570808,-0.00046769896850832324,-0.0009757737995732637,-0.0006657040814357714,8.56523920831143e-05,1.4276080266683872e-05,-0.00021549382083288862,0.0002907365768143275,-0.00014264131860712706,-0.000684754002453909,-0.0018755900338214765,-0.0006117132459058968,-0.0010653805043481655,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0018085115899833025,-0.0003822964492556397,0.0006576459561969352,-0.000579182692752989,-0.0006534983548004832,-0.0006055441967381319,-0.0008548649661648934,-1.9388983636716835e-05,-0.0007377335807402529,-0.0012987442145554547,-7.148044828115372e-05,-0.00075355189028833,-0.0008844124774252742,-0.001109440680934169,0.00012789756601878463,-0.0008633316654075204,-0.00039528582374490523,-0.0002682769243107234,0.00012455896864512872,-0.0012747301151294476,-0.00019152225822503875,-0.0012128861034506294,-0.0005846576714786069,0.00025585749965627405,-0.00038850287900292095,-0.0007175175442410261,0.0005281266890324801,-0.0001465243058909206,-0.0009322778753856099,-0.0022696664961366405,-0.0007666020983429856,-0.001627908987762255,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0006625039821510922,-0.0021475058198011407,0.000862207623193289,-0.0010959042795535084,9.376175603342548e-05,-8.859274467496626e-05,-0.0003257264068205619,-7.26660166495703e-05,-0.0006118821079941849,-0.0013876276236587575,-0.00033933942256504656,-0.0010507298431450362,-0.001351411610646857,-0.0014330209153017915,-0.00021663550842385625,1.3834860616105387e-05,-0.0006428792061170202,0.002268616792919471,-0.0012999882468358384,0.00040235745335803394,-9.191144569532188e-05,-0.0008804413957097053,-0.0005708660371982847,0.000235797942602908,-0.0001613741799825431,-0.0006020321507725507,-9.100910694973632e-05,-0.0008220219077109019,-0.0014768636084900742,-0.004706598343812893,-0.0011484934383091212,0.0016791964087875038,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0030681255311712312,0.0018836787491789346,0.0002746541216906563,-0.000738075224855741,-0.0002249940788790541,-0.0007850069631885927,-0.0022579309694827506,0.0008259125781948937,-0.0002537291547860981,-0.001138922613149783,-0.0002723520719083833,-0.0011466246606370643,-0.0009464121275260001,-0.00127599755709441,0.00015260939356484898,0.0003544227181174076,0.0005082801872002731,0.0010395369174755402,-0.001455067181214348,0.0012843964975599931,0.0005780067795637229,-0.001151963534285876,-0.0003084682657266624,0.0001778659336186183,-0.00018648708468265468,-0.0007286279976091018,0.001730700161548464,-4.6805760800807285e-05,-0.000488520286521662,-0.002518890267692502,-0.0004919324059740225,-0.00016812139741839447,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0034956895143145646,0.005179671141669502,0.0024150783621344906,-0.00033191245426779056,0.00037488597360880695,0.00035007787111097926,3.092957956056015e-05,0.00012991270048429986,-0.0005774933158465629,-0.0013536655430617486,-0.00031992519318923537,-0.0005396427500560751,-0.0020394573206301086,0.0002470990370184987,-0.0022228197615435244,-0.0043858348158173684,0.00301069652703233,0.0035825370228001543,0.0003746300322805834,0.000703625283425067,0.002002356580889328,-0.0011765857897787953,0.0004042921378531092,0.0008312274677162146,0.00037050766283953533,0.00038155627443643746,-0.0003232114441681703,-0.001275552516833406,-0.002396912107196345,-0.0012884671430400895,-0.0013527788894999036,-0.002736132107312397,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-3.3651582945496217e-05,-0.002021187022752356,1.4864269682894323e-05,-0.002775261275407074,-0.0005892307447199639,-0.00048123858573157835,-0.0011423787797670338,0.0004123486935410232,-0.00011532701446750643,-0.00018368862867171578,0.00041943875121257614,-0.00043298024319086395,-0.00031421829823799973,-3.682455871101211e-05,0.0005901375921496864,0.0025433876979635128,-0.0014174881110627492,-0.0007454727369270675,-0.0015410102423342122,-5.3389463461415147e-05,0.0001536631096778772,-0.0020407460857568556,0.00012158619140004466,0.0011015927765943572,0.0004531595758648632,0.0005274489400104426,0.0004253002763732834,-0.0007215595195455266,-0.0009739110561217485,-0.001394406279094684,0.00015487635559950047,0.0009950076944986487,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0002750863969106916,7.030270619031343e-05,0.0017057426400063213,0.007140358140492844,0.0008668760615877779,0.0019490511596270577,0.0024766313210994747,-0.0004257352762015592,-0.0004422176644428169,-0.00041706037826592566,0.0006898968208433614,0.004201320118783394,0.0008744501337354969,0.0021686520384869763,0.0015550670712771565,0.002709826658112568,0.0006367045943649368,0.0008751123735306847,0.00040086953879436827,-0.0006972259077686744,0.0029068222469886655,0.003603015367765174,0.0015020712239679718,0.0015693434441143564,0.000871511082796212,0.000982701906104802,0.002067866875384223,0.0015426596900751338,-0.00013478387700578822,0.00397363670041806,0.0016183868914876897,0.0017497230918114412,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0006007843427019388,0.0004745259839120752,0.0016004628225672205,0.0025654118352587962,0.0005645849057748245,0.0013092254932610715,0.0012607317757436787,0.00016298920764044961,-0.00011002235946121382,-0.00039405701265884935,0.0004934743497909889,0.0017711212286177058,-0.001208134256801459,0.0054731738871040304,0.0015968123576155996,0.00219313660816165,0.0008710376708050759,0.0008918028851213097,0.0005088230050691906,-0.001486978749271536,0.0031405861201450227,0.002892513192483447,0.0006873222860552535,0.0011031763876449487,0.0007019132210396082,0.0005319866916353426,0.0007001275054026462,0.0002943381290027562,-0.0023241761022240485,0.008245965188397722,0.002016368945224854,0.0018564506392184314,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0002719857599298018,-0.00014773107316123804,0.0015201071239321225,0.0021650947476227755,-0.00018475020167062892,0.00042128643945096855,0.0005806013731198844,-6.9088006134042e-05,-0.0001738806219695793,-0.0007340530245472478,0.0005127317319932571,0.001420505442350481,0.000499409931125053,0.000865854098838625,0.0002809850187092986,0.001322692407377078,0.0002503309919336316,0.0005394701668470389,0.000589184164830862,-4.842312436600504e-05,0.0006498005380887006,0.0010411505356967834,-0.00015444560949640364,0.0005411999610196091,0.00020798819176871076,0.00033365597235885546,0.0005134612858915524,0.0004448609538749164,-0.0004983136656480636,0.0008374934267122194,0.00045937406271374085,0.000596443581826109,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0005489818993268787,-0.00011302664926000856,0.0013181055705426923,0.0009696333551983592,-0.0001479262101774479,0.00027584488199642167,9.614897730677026e-05,5.4813394710658233e-05,-0.00025604146301574373,-0.0006010579793097239,0.000648559347440561,0.0009916346520956736,0.00036123089200579294,0.0003795148781019565,-0.00032111020462610284,0.0008131516265929898,9.717642901734993e-05,0.0006099518550238761,0.0003382449007083604,0.00030617702265714556,-0.0001902311614876298,0.0005417483523111863,-0.0001251048493595668,0.0005753047998683047,2.559671657388333e-05,0.00011069601032342043,0.00046079493434598464,0.0002360468000209074,-0.000699277479445452,0.00047025688100194393,0.00029059153113968707,0.00041119602817470244,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0007020192792399575,-0.00011854377247368633,0.0011171503927582187,0.0005204307353059732,-0.00016997445314284,8.87238595206145e-05,0.0005172833200685113,1.0841124653738837e-05,-0.00033037921360707935,-0.0008455711675943703,0.0002984225455069501,0.0008092562245061798,0.0005252355223917041,0.00019090333183294556,-0.00020705005938336334,0.0008717234158315924,0.0001709802664971404,0.0005163698159459097,0.00039812104412554033,0.00017852087928898127,-3.273887839293941e-05,0.00024700071430581956,-0.0002488265314616158,0.0001601535783197795,4.855428695041169e-05,0.00024672248198834144,0.0005264948596434874,0.00023896966390944793,-0.0007350488065728431,0.0004405718333843438,4.628279030629095e-05,0.00036990825230624784,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0005990542371783307,-0.00021747495151552818,0.0011479030576098791,0.0005002796990860563,-0.00033755947983099007,0.0002584558057293267,0.0002220138623079515,-3.873918707563842e-05,-0.0004907355250112547,-0.0006166525807180508,0.00034429913745039883,0.0007908042118337283,0.00030674606644182653,0.0001297182346385961,-0.00012432592495954334,0.0005868461526735331,0.00016893201744047734,0.0004286188949777206,0.0003037093672134616,0.0002531983912469771,-0.0001381819695748738,4.578246824237294e-05,-0.00026350241133846745,0.0003930624055046823,0.00024033870424747537,0.0003481195740716245,0.0005109385340301919,0.00026004948097836205,-0.00039131644726417416,0.00016729668782835403,-4.804517182554515e-05,0.0004740061845601617,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0005556100056964803,-0.00017187099636092003,0.0011101793630634241,0.00033652553070990593,-0.00035069307148621475,6.248909831157292e-05,6.265544815601393e-05,-7.708561227192952e-05,-0.00028394389194879736,-0.0007339140195202809,0.00037647333365886995,0.0005165945505853468,0.00038576555756104225,4.243127915703262e-05,-0.0003625679731832693,0.0006311806298809865,-6.301648733398613e-05,0.0003715213708685462,0.00020437112366561468,0.0002084209414378221,-0.00016579038537520765,0.00012151209425390459,-0.00019758322731361786,0.00043720340323767025,0.00015033540112077885,0.00028313383461213947,0.00024644373459640925,0.00011464186099474809,-0.0006033604561729465,-0.00023303524384831286,-8.938648311588447e-05,0.00014112085520714577,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0005837559486052026,-0.00013865601841026568,0.0009859908613809704,0.00015890887005905053,-0.0002006257420906042,-8.14893614918025e-05,2.5737871600050852e-05,-6.468582625121367e-05,-0.0003019319516713928,-0.0006980913334621972,0.00025710052667348766,0.00045827484584289236,0.0003484648396438248,-0.0001307981801068256,-0.0001870324423654819,0.0005240263555153046,-0.00013281585893753736,0.0003423214946190947,0.0004179901863333052,0.0002267313876433678,0.00016431839081384897,7.0909161027869465e-06,-0.0002240705776984404,0.00037538961647690263,0.0002697500591514249,0.00023474083606130853,0.0003705366472493868,6.486029378083867e-05,-0.0006086676713223854,-0.00030416543023517156,-1.1507914743232521e-05,0.0002486967790379937,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0006918834811837476,-0.00019340457775082209,0.0009348252391065073,-4.302236576536896e-06,-0.0003175040325367769,-0.0002187764941229875,0.00016458388172232207,0.00010335018135829278,-0.0002700672716730407,-0.0007610204782859327,0.00022895869469712263,0.00045839254136716004,0.0004441192118169705,5.1080944240157186e-05,-0.0001110102497406418,0.0007292421360375843,5.507599825074461e-06,0.0002908709176452752,0.00021155442703106573,0.0002553890799709777,3.41197561581604e-06,-3.750878830187352e-05,-0.0002623457646728652,0.00024239642862334995,-2.5525977003298214e-05,0.00010525338805262786,0.0001833173016453236,6.196265912081756e-05,-0.0006607603906882355,-0.0002458558198168135,-4.2592018270659726e-05,0.00017379517041803724,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0005840073125161181,-0.00013864745320545227,0.0010059328554710336,6.717623960970806e-05,-0.00018922025363783215,5.7371393268370834e-05,0.0001657659163745464,-9.560061827107852e-05,-0.000494603823595949,-0.0008034039117267847,0.0002785227177385325,0.00028972196761755113,0.00019536943673257475,-6.53354115006368e-05,-6.31238232662097e-05,0.0004506086518697032,-0.00011440463416478755,0.00039460346394585926,0.0002416162227582551,-3.188019057395305e-05,-1.097749259168688e-05,-0.00012672320843206436,-0.00015041308629550206,0.00019976315811327032,-0.00019374934621967796,0.00015157972348423942,0.00030010649989969376,2.2243586583707365e-05,-0.00048465549341247214,-0.00036664300887903736,6.598336684152343e-05,0.0002061638475438151,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0006383231233175396,-0.0001944208867236521,0.0010498575425504965,0.0002570812716307291,-0.00030605114288489874,-9.233736146431851e-05,5.24885111354897e-05,-0.00010441568439161559,-0.00032238090782452507,-0.0006576803164209712,0.00023928503150314617,0.000275809557678215,0.0002514393202474632,-0.00010234347867730545,-7.186036558478803e-05,0.00037014415981266276,-4.4045309162093735e-05,0.0004813036017901371,0.0004255879639930315,-2.34854115382507e-05,5.960428000867265e-07,-0.00019825755305079263,-2.8012166318129454e-05,0.0002738628505930398,-0.0002296671384261477,0.00012071012602112321,0.0002758952474589955,0.0001271081895477594,-0.0006723725643671069,-0.0005133932733119523,-1.0825003386726157e-05,0.00010882774096641032,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0007859747674044861,-0.0001848391558317079,0.0009605627042923674,1.9919560335906818e-05,-0.000227206759661013,-0.00022192074407844956,0.0001583308510851689,-0.00011686871506135004,-0.000319317467553462,-0.0007519677627816341,0.00023577021302378617,0.00021039328320479893,0.00030667738699148556,-9.993553568332459e-05,-0.0002155890228947988,0.000363322216886769,-2.9355620166788152e-05,0.00044506812530774065,0.00034280393636241114,0.00014770676042220543,-0.00010172301812079023,-0.0002964418219830492,-0.0004910697550152554,0.0002506983368433632,-4.9211587081436146e-05,0.0003343816586129682,0.00017514080523550578,-4.440001327412059e-05,-0.0004786805179429993,-0.0004378723198697592,-0.00023367166446523917,5.1663448627666066e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0005716285367457622,-0.00022580841470946377,0.000834911768263436,-1.3833871029288914e-05,-0.0001722307538942879,-0.00014050701460544595,0.0001299409093815923,-6.741924910115364e-05,-0.00039127229476052595,-0.0006113425758565723,0.000295438832287647,0.00032141434481599185,2.4711291666838408e-05,-7.763200932981979e-05,-0.00013885692795293883,0.0004983076795979118,-6.933463717825124e-05,0.0004964224906066494,0.0002265899041866025,4.5569716651090315e-05,6.392269022739885e-05,-0.0003070868548080226,-0.00023515012215572366,0.00027078033321976296,-1.6409422054988884e-05,0.00015692414635958582,0.00034782265782950204,0.0001578334330839499,-0.00033845907380010355,-0.0005103785729437807,-3.824888997796284e-05,3.00719203201592e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0005882608805783088,-0.00025121863772705,0.0009821025099170614,-0.00014045031193247909,-0.0002776127115038424,-0.00012880425015017737,-0.0001137553753702052,-8.817479443200084e-05,-0.0003251325536048524,-0.0008490318239673693,0.00015704062462850503,0.00030895533990856963,0.0002358397553980135,-0.000166154853890666,-0.00015049100624958906,0.00033575511529224046,0.0001240295209477665,0.00035569459089792416,0.0003486647316467656,-5.874987863376539e-05,0.00017366845978306067,-0.00016403899043998703,-0.0001410177165333579,0.00026957457431023757,-0.000125816806201309,2.547367557866443e-05,0.0003821351099270254,-0.00021058045593848597,-0.0006709248367321695,-0.00047900355917069427,-7.939208985596223e-05,0.00015157978759841272,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0005932165596323607,-0.00020910313963605126,0.000829417871749638,-8.69192569227854e-05,-8.774050074851798e-05,-0.00014910521605247538,-0.00015669547106275978,4.428623129790773e-05,-0.0003667147231773411,-0.0006721418057122178,0.00011895561713161311,0.00020148760027449372,0.00010738248768823265,-4.352747871712781e-05,-4.893502039939104e-05,0.00039170512278836493,-1.5248007292352501e-05,0.0003707076630529406,1.3603702418108113e-05,-6.422237041184906e-05,6.425083326529206e-05,-8.791221750529987e-05,-0.00037128993304942333,0.00020467712567337842,-0.00027898767468674567,0.000152306679021978,0.00011021518348082552,-0.00011375324413708587,-0.000507043987650539,-0.0005487765540978151,-9.758926937456456e-05,-0.00012469961975696318,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0004619722752226646,-0.00018055128309955813,0.0009100745134394351,3.37136403686986e-05,-0.00028910969597922023,-0.00021422753612887154,8.454277860263494e-06,-0.00018148293880726485,-0.00039537546000664275,-0.000608168932654792,7.455194109990994e-05,0.00013890280498731275,-0.00017065797260564173,-0.00011846509908051424,-9.820305189416223e-05,0.00023593950683498555,-6.762545217815067e-05,0.0002537747924683533,0.00028277966091930646,4.3068773173139114e-05,3.356513699168317e-05,-0.0002670870339066592,-0.00019982595633852795,0.00018757996478399575,-6.481992903314732e-05,0.00011298603499045347,9.563956071262712e-05,0.00011870452580555932,-0.0005964269323758854,-0.0005791218152834739,-3.783271729944933e-05,-1.6665060434415865e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0004915340113629216,-5.313435799785233e-05,0.0010310924082361304,0.0001070154830961945,-0.00028044876264659587,-0.00015202836721790424,-0.00010401828687814532,-6.847103290456482e-05,-0.00032733302837805833,-0.000624782583915551,0.0001099567258515963,0.00019278624193539633,0.00011087550676905056,-0.00021075137257530634,-7.276888535583249e-05,0.00012670494121535438,3.0160428567694122e-05,0.00039374328273696763,0.0002766418853571582,6.410795013482321e-05,3.953365104507384e-05,-0.0003971417562629844,-0.0002066798580003168,0.00017652814251632848,-0.0002594723780877612,7.558077636507289e-06,0.0003722576201036668,-3.592941581339424e-05,-0.000561717256963274,-0.0005275527117542814,-2.886877536352344e-05,0.00014327444775979648,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.00044675196486956094,-0.00021661646221912378,0.000852756540649033,-5.485248558669472e-05,-0.00032467812831720296,-0.00020135319847462878,4.3227704930873946e-05,-0.00014900918004078303,-0.000341062018277486,-0.0008567545127118361,5.718870868433502e-05,0.00016444813602308495,0.00013748442710845285,-0.00012257240528761872,-9.97159910323633e-05,0.0001412961921705558,-0.00014869121421252977,0.0004171749309909373,0.00012863720763594579,5.7909650699133306e-06,-4.8008470146023524e-05,-0.0004913509049224885,-0.000105165322504518,0.0003930521731781448,-0.00026905365532999036,0.00015500827398791956,3.623130110237109e-05,-2.7267810218164256e-05,-0.0003633348292806261,-0.000426608768983851,2.863199705822241e-05,8.942970851171791e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0005090797393874618,-0.00013316690554527396,0.0006952650089341538,-2.121373174256465e-05,-0.00014350033568994204,-9.099772832803766e-05,-0.00026005590688904664,-0.00015509257244923484,-0.0003460738975707929,-0.000863532810719446,9.34571048446375e-05,0.00019355477442952788,9.215809846435068e-05,3.8851845656237566e-05,-9.89893853387373e-05,0.0002377299802264803,2.2706954993351006e-05,0.00036324708471399583,0.0004239179092808032,0.00011497829057639282,-8.576206853055202e-05,-0.00039761336460360745,-6.723492130666933e-05,0.00029565071851746217,-0.00024294695149574888,0.0002700549760099075,0.00015601335338201688,-0.00011384556358319267,-0.0007116010709674699,-0.0007781600429717801,-2.9537385207059798e-05,8.29180550585951e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0003671315286660353,-0.00016701268966858097,0.000900666507340495,-0.0002807062150671443,-5.3011081003534336e-05,-0.00011916314685626902,-7.35847362713529e-05,-8.92793910232587e-05,-0.00021072891165007504,-0.000573227494983488,9.455514336192287e-05,0.0001448183418243028,0.0001677162528924801,-0.00017776580163343734,-0.0001557087353046099,0.0003335562691468726,-0.00016175126055085904,0.000429037101533593,0.00039785603327239356,0.00011147037309680953,0.00015994015101975734,-0.0002728039889436763,-9.435083701503461e-05,0.0002602884185788274,-0.00026582711723142677,0.00012576866416720954,0.0001014235419999702,7.303867079835596e-06,-0.0006337205192285597,-0.0005292565013364817,-0.00022964026953578215,-9.845104218109058e-07,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0005839553009598455,-0.00023419132978675796,0.0008026972327688696,-0.0002954794920285271,-0.00026587584324913534,-0.0002724650596389312,-0.0001520258048930946,-7.423272152145152e-05,-0.0005086591597148507,-0.0005724314154499741,-7.360815509521788e-05,0.0003523011960502451,0.00011952864482163088,-0.0003382372415689255,-0.00017322865082332393,0.00026691235271088595,0.00017582439628176095,0.0004809240330892211,0.00016504516458532562,-4.883567307425678e-06,1.1902955495650846e-06,-0.00032082042567397543,-0.0001896372595963819,0.00015772344232614486,-0.000284210216763544,4.354039007995642e-05,0.00016219247290744505,-6.1252625734139544e-06,-0.0007185727724615951,-0.0007138301595154914,-0.00017296801734429797,6.127317202576122e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0005656084923404939,-0.00018734436922976204,0.0008388784469794147,-3.179393182310031e-05,-0.0002800329447344583,-0.00020303794854047586,-0.00015893971157402283,-0.00019173403518776602,-0.0005599708347703859,-0.0006095311071463972,2.2687227565430355e-05,0.00025418385643845873,0.00034796905587949683,-0.00024209894140885335,-0.00010930676488469135,0.00019154171464656682,-4.3932717914521436e-05,0.00042052757363317765,0.00014319753702530657,4.404119375366378e-05,0.00022111682490475183,-0.00038216665747990556,-0.0002052616139924933,6.481431925543332e-05,-0.00017760661706905072,9.041334307974485e-05,0.0001816423912782673,2.127521927416697e-05,-0.0004191259240853307,-0.0006520685297354547,-0.00016833306469623784,0.00010812857352324191,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0004262975008797537,-0.00012943978492200797,0.0009744984884618407,-0.0003004688695487318,-0.00013478691114296595,-0.00028223916781939845,-0.00035973418718921623,-5.6830478920959405e-05,-0.0004764342178514129,-0.0006626320679575941,0.00015662451285168195,9.53364729056077e-06,0.00010997549965968912,-0.0001940278171004723,-0.00014703709582935629,0.0002927001257280263,-8.122911661435323e-05,0.0004788940387378251,0.00040705654984931017,-5.0348330122297154e-05,0.00012767293445431154,-0.00028399481753650456,-0.00021852754339398673,6.804689301191174e-05,-0.00033163932735349284,0.0002106445194408724,3.0357902405610538e-05,2.6990447676580127e-06,-0.0005591838572698629,-0.0006431405123777024,-8.784255490159309e-05,6.938845507248838e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.00047109088061381463,1.6969888512006798e-06,0.0009224281102471917,-0.00016323522704753652,-0.0002279436396727622,-0.00020338832800065052,-9.754108973231956e-05,-0.00013622859044515158,-0.0003962224864167133,-0.0007190861649059227,3.9037459979175584e-05,0.0002796201531057017,0.0003425191063596408,-0.0005420849657821022,-2.216909687346622e-05,0.0003002425261071047,-2.1516096180582713e-05,0.0004195864442458598,0.0003122790045365076,2.69581710682153e-05,1.8867122522381422e-05,-0.00019289972520428214,-8.737032266562386e-05,0.0003346410294208608,-0.00024348632901004635,2.6498446513590048e-05,0.00011539322977582563,-4.7386792302566786e-05,-0.0004420136488221827,-0.0006524751274728441,-0.00037669494213253443,9.783296574797987e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0004327723847203601,-0.0003248946890281934,0.0009441373016571755,-0.00021065308050235038,-0.00013594274693010626,-0.00020155099495134892,5.8849494823378024e-05,-0.00020631760520097082,-0.0002554372209876515,-0.0007082752746362991,-5.121271288299712e-05,-3.1964448435254446e-05,3.366663625460212e-05,-0.0002656125231773127,-7.766145279457095e-05,0.00021588281115599115,-5.395075410552964e-05,0.000304486959479743,0.00030585391399868005,-9.181562060157458e-05,7.696911878635533e-05,-0.00030095327559986337,-0.0002251282495437567,0.00015536948695990234,-0.0003765945988293315,0.00015523740985494715,4.901564009827944e-05,-0.00011356223946030065,-0.0006504879135581088,-0.0007726903848207852,-4.053500142591323e-05,1.0150101830340656e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.00044132363271871133,-0.00011693718425963283,0.000852017599856231,-0.00044676526952797314,-0.00022669915594295255,-6.357369041454872e-05,-0.0002624367285835926,-0.00010330423663673801,-0.0003731124011145567,-0.0006748149772657005,-1.3331791485494081e-05,5.995001126997265e-05,0.00019673320120016543,-0.00025450492847125595,-0.00011215400459068258,0.0001651192929206623,0.00013526927103032647,0.00037223292950064893,0.0003056719446126588,0.00011280888242548768,0.00015167581858156976,-0.0002962057037174193,-0.00025705498949563365,6.876865030550938e-05,-0.0003056843455568365,3.7593726806329955e-05,0.00012494341150785318,-8.756151067255776e-05,-0.0006878346045306174,-0.0007361589418394129,-0.0004533463175047696,3.3874509481871955e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.00035892935297723893,-0.00023030747281858755,0.0009663186828140656,-0.00033629776160668695,-0.0002230580697364601,-0.0003211287505063174,-0.00013718124098818159,1.540037151993627e-05,-3.648267793828577e-05,-0.000679127498119761,0.00012425317164412679,0.0001714157936870009,0.00019587291854106942,-0.00022068116175873073,-2.991617636588663e-05,0.00010875328864592375,-2.0210097491994395e-05,0.000490563011700271,0.00026610900152589816,6.211854182670124e-05,0.0001492971270339429,-0.0005238677398959216,-0.00015369337409476788,7.843716584735279e-05,-0.00036598942026331687,0.00026404401778590557,1.9151686298312932e-05,-0.0002653828168611508,-0.0005370069438435629,-0.0006725185815795955,-0.00017157812188224256,-1.6380337943608592e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.000555557482624171,-0.0001429768859506653,0.000878652161488235,-0.0002222660045438383,-0.00042690392047824453,-0.0003670123168776006,0.00010015444742922013,-0.00018401850810813,-0.0004088704674011231,-0.0007387185514320074,0.00011786182237319625,4.039696785677074e-05,0.00021501337218635176,-0.0004490251865117122,-0.00018479327872990116,0.00011481783070535183,-0.00022036317342935644,0.00034759000931200776,0.00014673779852507807,7.166010152803244e-05,0.00024192757265116327,-0.00030714148704012246,-0.00013672504724457173,0.00016504464500937798,-0.00036191525689521135,0.00010388017599881048,-0.00011505088958816416,-0.00023577351557517692,-0.0006465501019333105,-0.000655067588790168,-0.00036810387032126134,1.8431987036185058e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0002953660903878784,-0.00028451187923861035,0.0009768603761136079,-0.00026730312693120755,-0.00035873475191854526,-0.0002628071476620495,-0.0003086484305514398,-1.2915279677525167e-05,-0.00029883657800491533,-0.0006787901991217712,9.357942452558896e-05,0.00020174974766348503,0.00016170722553667777,-0.00033794395240002126,-8.055450660758931e-06,0.00017672257350323438,-0.00010578460569000012,0.00037137822836391025,0.00026628434149683975,-0.0001551569133279633,0.00015172664252674804,-0.0002037827553149327,-0.00015217786501800433,0.00012357556868007044,-0.0004669753654082303,-5.579459568895856e-05,2.117705088558011e-05,-1.417362209546517e-07,-0.000490328794584156,-0.0006895634191446001,-0.00018827133272959924,0.00013665383322632302,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.00040853210360292206,-0.00020391125270644185,0.0009130510000363392,-0.0006188401442872191,-0.00035700271344174246,-0.0004584054537903938,-0.00016203957799069832,-0.00025739129891736123,-0.0005017836262609006,-0.0005690215405541053,1.623811035775409e-05,0.00011717836267312482,4.7668737830372244e-05,-0.00014478998595061806,9.800544116359266e-05,0.0002631059640232397,4.325245088886521e-05,0.0004374891840104145,0.00026421538220034753,0.00011396538530946215,0.00015579562603381314,-0.0005060891183200719,-0.00019662397122113007,0.0001474364822907046,-0.0004974460540138953,5.86667583558738e-08,3.7276731175663906e-05,-5.670970715449988e-05,-0.0005566381140013066,-0.0007274588110630155,-0.00017340852906500747,-5.746400220583285e-06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.00032877244004244255,-0.0001212130161249822,0.0009004013433264259,-0.0005361434695060925,-0.00031002322105483956,-0.0002449689343296276,-0.0002436918234108588,-0.00017002952603137827,-0.0004348393961696689,-0.0006705981290993191,-8.51316804686381e-05,6.876332993445938e-05,0.00011723343415940567,-0.00043827051544770084,7.393432818392396e-06,0.00016449429639705306,-9.588581136323908e-07,0.0005622382676475721,7.5172736371661e-05,-0.0002767514748270264,0.00014304835682194173,-0.00048256948017457075,-0.00013459182558720481,2.9686237204286375e-05,-0.00046213525838175227,0.00014480489207932263,-5.5853156110004334e-05,-0.0001863557665489496,-0.0006152507294146945,-0.000842634161173641,-5.996949126953815e-05,-1.2352012328948727e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0002103278487205308,-0.0003254861773960255,0.0008316363846106753,-0.0006914868574083921,-0.0004815983516568224,-0.0003463025991157066,-0.00023475627412530273,-0.000247334614742628,-0.00044353433333422794,-0.0007805815319872701,-8.819174569510217e-05,9.336852488120548e-05,2.1695536707499354e-05,-0.00024756216014302184,-6.860353199467692e-05,0.00018274078763913515,-8.902078827656862e-05,0.0004685487645631697,0.00019665211425385091,-0.00018577023478025094,8.579653268341001e-05,-0.00043171389310291196,-0.00026794445919168993,-6.823294264947361e-05,-0.0005258546289964582,0.00014154260429616918,-1.0508463201393223e-05,-0.00027918301639086275,-0.0005814441642864058,-0.0008104627959265018,-0.00020162850706826355,4.3919310732297814e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.00036730712260556485,-0.0004414434222521683,0.0009538315374213157,-0.0007146523307431547,-0.00045119034682751524,-0.0004676884504122052,-0.00034344676193380394,-0.00011538140690931372,-0.0004160769969132446,-0.0008543384187972266,3.804112311606615e-05,0.00020309445805047715,2.386349897313799e-05,-0.00017364842821464144,-0.00010782798828837343,0.00016591000650940008,-4.6392708963987756e-05,0.0004546774734475639,0.00028211926218079135,-1.578656676550125e-06,0.00016046746927738198,-0.000509581564314561,-0.00015557234556986624,4.3220369017120446e-05,-0.00028754542881524763,-4.235372878385877e-07,2.1391054646076054e-05,-0.00018969696765699486,-0.0007339771752391102,-0.0007304003208475258,-0.00011323849412898534,8.383082144538966e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.00033474962993081337,-0.0003081696240149321,0.000796568959242498,-0.0006983800589563355,-0.0004593701176242775,-0.00047756042930992493,-0.00028500037900171054,-0.00016156061515371087,-0.0004270274173753018,-0.0007578207695101219,0.0001300658506005625,4.5701998259845387e-05,0.00011277328008404031,-0.0003842029960702992,-4.2247843654073126e-05,0.00013967790200134048,5.0475046928589616e-05,0.0003248456318938164,0.00036434234725708493,-0.0001659755126256271,0.00022678345661600254,-0.0003643980929276768,-0.0003092232147460281,5.245731326137235e-05,-0.0006164539422535344,0.00012946229723771998,-0.00011794397752461401,-0.00015486170201746877,-0.0007267979702494884,-0.0008235088730317898,-0.00016726007885965296,-0.00011818623741474591,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0002564511647634156,-0.0003620507298459071,0.0008702507675796237,-0.0006566281294895954,-0.00040016840436471045,-0.0005676402717864055,-0.0002581352235237411,-0.00037081533274684563,-0.00041559757836568317,-0.0007332923803083735,7.005048621412599e-05,5.5704069208362817e-05,0.00022639275741490611,-0.000158454214572791,-0.00011892298293700193,0.00010166315412792342,-1.0145740584612309e-05,0.00043468569517220217,0.00011636693424303548,-1.814180310708554e-05,2.617742250034811e-05,-0.0004703323522608001,-0.00010167656871799762,2.557955357480485e-05,-0.0003725964174702086,1.929068276088733e-06,-0.00011357575183442838,-0.0002482351296567816,-0.0008029377137552737,-0.0007992550716043466,-0.00013867711373025205,-9.34922875050556e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-4.789081088259886e-05,-0.00020814638451100147,0.0006451806383040184,-0.0008164980339763828,-0.00034362400009847906,-0.0007141814821048457,-0.0002755054227194655,-0.0002352546040453034,-0.0004903704655707455,-0.0006334315204495879,-1.042689039536172e-05,7.958940849827648e-05,0.00014075898578163785,-1.2389367924010209e-05,2.464259970150672e-05,0.0002588391017085538,5.5433850312594895e-05,0.00040625675189016815,0.0002486321143962073,-0.0001418348730161704,-3.787811113363618e-05,-0.0003820546154832736,-0.00014975865894168756,-8.194767257754103e-05,-0.0003732921875301318,9.138910300356328e-05,4.010667668291934e-05,-0.000302721676807897,-0.0005584190684975376,-0.0006898244945623255,-9.332067701548567e-05,-0.0001556199567018412,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.00028593472781715773,-0.00028110016483593885,0.0009566561841007742,-0.0008572787673177523,-0.00039069072830195695,-0.0004878416781147573,-0.0003279479551675615,-0.00036935924904383247,-0.00044810816601344476,-0.0007929871646192695,-0.00013727576462688282,3.7132925118615546e-05,-0.00010803015194695104,-0.00024553365349740044,-5.452894045141874e-05,0.00011092287513213266,2.7128432136100255e-05,0.0004438251313370631,0.0004902984696152523,-9.10338107663464e-05,8.310643033409682e-05,-0.0004006452082771968,-0.00018404783840200267,0.00011575160482756147,-0.0003133607702418251,0.00015564686257731056,-6.599438328681684e-05,-0.00042315458759584044,-0.0007124862270218342,-0.0007701106090162111,-4.703684665250436e-05,-0.00013927711065445548,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.00017525190267024543,-0.0002007043275313102,0.0005907103631806891,-0.0006119989277407332,-0.00030181949386240344,-0.0004320297954919573,-0.00024710534193678755,-0.00018998332473786126,-0.00048392078436468647,-0.0006909180656835657,-4.032842786125058e-05,6.529355960022724e-05,0.00017136189353318432,-0.00023133216574003918,-8.457057417870763e-05,0.00019841388337861157,-0.00012519026186097408,0.0003148647016890829,0.0003903468592407553,4.4292541999545616e-05,2.5836630450548484e-06,-0.0004390440314172248,-4.076452523998784e-05,3.289953658604713e-05,-0.0003247476076056085,0.0001196903175446355,-4.397019253035859e-05,-0.00015749117004636878,-0.0007815217523060461,-0.0006588621668390038,-0.00012294905432031625,-2.5662970582999573e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0003040929413707244,-0.0003356535037141016,0.0009320947132669993,-0.0006405978501024509,-0.0003124446323186927,-0.0003213975451147163,-0.0003231268727520126,-0.00011126844373719475,-0.0004223389051367114,-0.0008247337530316187,-0.00017005136607799537,-6.671948023378841e-05,8.766867595419603e-05,-0.00016202256288210193,-7.26157698914613e-05,1.9347257007456105e-05,3.556303921662245e-05,0.0002188906358283922,0.0003132473852467054,3.177654837326704e-05,-0.00011460233397054212,-0.00039726301264790434,-0.00013044320348344016,0.00010601709900760894,-0.00040346494910608173,9.49774394202415e-05,-9.091055296902826e-05,-0.00026761204477660844,-0.0006712262077611615,-0.000603342842988254,-2.667622673011743e-05,-0.00038389491243665414,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.00012823091313700152,-0.0003191994782384613,0.0008826041336549707,-0.0005950873241620919,-0.00026028870549912723,-0.00038880920965456714,-0.00025758558429402593,-7.607974143312846e-05,-0.0005463958387615813,-0.0006298260267525718,-0.00016744408012624027,8.466559762549851e-06,0.00017149085199864357,-0.00021999774920004712,-3.0773634948895137e-05,1.2238733568754613e-05,-1.4182606213372572e-05,0.00037497656144105474,0.00022887509731114983,-6.526807625688836e-05,0.00018701831016131076,-0.00029849024236571023,-1.826236772785684e-05,-2.0045614474291045e-05,-0.00028449344269126193,7.711794799483152e-05,4.587463525640658e-05,-0.0003460394768054754,-0.0006501437832127698,-0.0004966060902082991,5.817894887171491e-05,-0.00016179128369597852,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0002760644983369242,-0.0004496777871825908,0.0006839848081658126,-0.0006021285536678792,-0.0001465533411647162,-0.0004316769218440905,-0.000265434209498659,-0.00022165265534677205,-0.0005327727915668,-0.0006514412524021499,0.00012540694016973641,0.00017648827749648386,0.00010344612650234836,-0.0002665529938644921,9.266176771856065e-05,0.00014355272645184488,2.406188320951369e-05,0.00039687789803120974,0.00023560453992395715,-3.0237408530454415e-05,2.253526757789904e-05,-0.00030556624518171885,-0.0001339826374722719,-6.668468908426339e-05,-0.0002758098230889794,3.9933824817034204e-05,-0.00016999195737120267,-0.0003266639336398487,-0.0006086230992530903,-0.0007357971538459933,-0.0002105209986722808,-0.00014659413536194875,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.00012092779950627506,-0.0002736687694745286,0.0006316924450392989,-0.0005637251182824823,-0.0002661227281857247,-0.00044883506860820974,-0.0002912920832555528,-0.0003093853514703394,-0.0005531601357646418,-0.0006854830002220376,-7.027613317569946e-05,-6.398515849786353e-05,6.12204473621083e-05,-0.00014597031553130593,-0.0001453770175529443,-7.009129175782e-05,-3.1184394692892984e-05,0.0003546493906103188,0.00030160669010634793,-9.952508228818272e-05,8.274939468700013e-05,-0.00045406180969883046,-8.001717463228624e-05,-6.859553738412723e-05,-0.00012291065128899311,1.136167753637904e-06,-0.00019701956777472385,-0.00011782546330733887,-0.0005044964550603498,-0.0004185225109464583,-4.2192803381718435e-05,-9.313786982275904e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.00032551543630949896,-0.00014343646376186402,0.0006110281708814742,-0.0005908953845235325,-0.0001684791033924206,-0.0003908516014594094,-0.00043544130813538077,-0.00023976943029569017,-0.0005882631068050424,-0.0005648723954777457,-0.0001405552813481878,7.901287532841836e-05,0.00020045230328457212,-0.00032930973475410284,-0.00014221364631330464,0.0002888271374874904,-3.877358321456436e-05,0.00044382177752319845,0.00037345975486839677,-0.00012789346531491943,0.000128111199750105,-0.0003873084873026,-0.00012041095549753703,-4.358450006649196e-05,-0.0005121679047415279,0.00017772700338266036,-0.0001373075646728238,-0.00021560236675502477,-0.0006093214316420314,-0.0005788274702071273,-4.561543352640037e-05,-0.00023916498944324412,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.00023019038484939475,-0.00037692150534371425,0.000630502142673705,-0.00045337054220940756,-1.607304231032098e-05,-0.00037995004375105865,-0.00037235915121191815,-0.00017137047726576045,-0.0003365706145849703,-0.0005516493976021931,-2.159721911100183e-05,-3.8526139951916765e-05,1.0857297492643165e-05,-0.00018098538984435012,3.2910042452816485e-05,5.184235853779258e-06,-5.723364728644577e-05,0.00019343890048654946,0.0003578272729632459,-8.425357537219864e-05,1.3490225811120685e-05,-0.0002996343186484766,2.2875740891686693e-05,-0.0001826071996286293,-0.0003732099112918586,-8.788143976665595e-05,-0.00025111385547915834,-0.0002092348810804225,-0.0007724641855685404,-0.00043902512886741685,-0.00034815826155835223,-0.00011807358171697719,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.00012677689528653078,-0.00016948282111791985,0.0006494110355927525,-0.0004525080975578222,-0.0003801333897463426,-0.00036252652589705096,-0.00039494573011552257,-0.0004210168229061087,-0.0004547573515720901,-0.0007869106415109615,-6.311139732355856e-05,0.00024327388611569106,-0.0001409153185743072,-0.0001756215319723718,0.0001215485562047277,-1.7160874810971068e-05,0.00011686798214561653,0.0003296345185490633,0.0003768754917792207,-0.0001732996343980374,1.302789970619001e-07,-0.0005427237215647288,9.260635070103733e-05,-9.546881650185577e-05,-0.000499566837475076,5.018073982005892e-05,-0.0002211107806099772,-0.0001741485927725357,-0.00046490708464666346,-0.0005640948280905351,-0.0002345187018529554,-0.0002752934282227994,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-6.0316731311666027e-05,-0.00023225224086744105,0.0007745386619433663,-0.0005875184866488812,-0.00015583826122028878,-0.00047095760955411897,-0.00047245513232711675,-0.00020673299449287214,-0.00038545539037558146,-0.0007838855830193178,-2.2059366289481988e-05,4.000430457344731e-06,0.00018247803006770863,-3.575011316489651e-05,4.087782577458744e-05,9.014278539560774e-06,-9.271679053037907e-05,0.000195326438741202,0.00040029939741462845,0.00019861431524117443,0.0001499395188110626,-0.0003704994610444967,-9.629088408662645e-05,-0.0003355151957731869,-0.00030781588896400025,0.00013965753256913233,-0.00022357592704080586,-0.0001568533569943033,-0.0004496107037572298,-0.0004139702177341279,-0.00019442870309375985,-0.00017579595366962807,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[2.1964122677544388e-05,-0.00019738747385697263,0.0007528941314844426,-0.00026879136426843583,-0.00017449359442377156,-0.0004633148556716465,-0.000453437142241195,-0.0002930204865954857,-0.0005609578889024856,-0.0007514342726628563,4.495010079359025e-05,0.00013198099837664836,0.00011435138824330624,-0.00011782085441356279,0.00013812904750527556,6.9560313617634e-05,-6.30697772733095e-05,0.00041185465575197325,0.0002689547634501369,-0.00015795327779511591,-5.661095544943906e-06,-0.0005000384703932961,-9.329326874652491e-05,-4.0354894442634e-05,-0.000350442350718609,0.00019313117029684643,-0.00019654655114149794,-0.0002905252835226599,-0.0006683534911119776,-0.0004009902220424993,-5.1529298914228047e-05,-0.00015645017202238593,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0001267346461690773,-0.0003901955912546159,0.0006595410602826989,-0.0007124903603429136,-0.00024259487136752076,-0.0006905345077841904,-0.0005121619435276532,-6.248916788600091e-05,-0.0006753573069457824,-0.0005826564249112249,-0.0002955773641632876,0.00012079352842888578,5.043234476644063e-05,-0.00016414262899516993,-8.366560187585529e-05,-7.315337427245547e-05,-0.00022648073230371787,0.00029042180953949833,0.000215143331789506,3.8442994673517335e-05,0.00011441012282250016,-0.000299233668334882,0.0001338547785712351,-3.0258114217064257e-05,-0.0004902563897121318,-6.126496379923716e-05,9.388988169461547e-05,-0.00038898250512268176,-0.0005167048079844174,-0.0005680359938925269,-0.00010964013867103558,-0.00037801884860207455,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-2.6797609470109344e-05,-0.00039797681189930183,0.000664180736798172,-0.00047322994935492565,-6.31961807499521e-05,-0.000366333784086143,-0.0005986875260636836,-0.0003814238193237991,-0.0005528728771181053,-0.0007784025777611801,-0.00012015364093423246,0.00011924012299117436,0.00016011476016782337,-0.0003474922627476799,-6.001907768702482e-05,-0.00011053132167905045,-4.73383503888948e-05,0.0004134372134042331,0.00024484518793665847,-0.00010898800955561987,0.00014535602060448602,-0.0002502610713291333,-6.051946363546884e-05,5.279456024104248e-05,-0.0004148199125289555,0.00012206204315649949,-0.0001261736776218685,-0.00033938005477883166,-0.0007369074082666521,-0.0005063299067436247,-0.00012280655079431168,-0.00017403260556566087,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[4.7083334788156036e-05,-0.0002708384884020721,0.0006204209304922621,-0.0006273882971045902,-0.00024953647001390813,-0.0003881750022460416,-0.0003901230891310749,-0.0002195315501177153,-0.0003484508822089756,-0.0005837570553526934,9.464959928458849e-05,5.2994911857927295e-05,0.0004339172448326607,-0.00033671537588354355,-9.831770843598041e-05,4.712604398922251e-05,4.3804976747210845e-05,0.0003120267309887049,0.00042518089247063433,-0.0002662294682703516,0.00014215857972089954,-0.00029420789436084336,-2.8158348106679086e-05,-2.5009544922956836e-05,-0.0005094784322446822,0.00022569098679201864,-0.00018143054127888746,-0.0003383855385848692,-0.0005912559370622774,-0.0006452614511040084,-0.0003054452536203265,-0.0002888747530034343,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-0.0001231873285627339,-0.00014522132149519758,0.0007110692303598043,-0.0005469708282221503,-8.982661659821238e-05,-0.0004508860162745032,-0.00042620180211159814,-0.00035313229457633975,-0.0003808898015846511,-0.0006411083202958988,-5.2424800873723775e-05,-0.00011943887129787465,0.000261893439044049,-0.0003064202106313938,2.908439773962284e-05,-2.679409005154026e-06,-0.00027400056788066447,0.00040496958683986715,0.00028719884749149615,3.368314972567849e-05,-4.286736555963327e-05,-0.0005600229437334732,-7.006732162545711e-05,-6.880819181420786e-05,-0.00015794902520188878,0.00015766038787001386,-0.00016280929294192238,-0.00031128817428192494,-0.0005723960872372449,-0.00037771828241218395,1.079886462597402e-05,-4.0408539289493e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-9.639721991553268e-05,-0.0002382221176669618,0.0006931148159940732,-0.0006589626554626282,-0.00028975476489626225,-0.0005787553861541402,-0.00037800029243924776,-0.0002727966718971179,-0.00038255750851750225,-0.0005149373812803527,-3.1663544618332296e-05,-8.046333414623686e-06,0.00012006788413433596,-0.00021760985616548056,7.133768925011899e-05,-6.71991934402468e-05,-0.00011553290070515779,0.00040667519225719053,0.00045261659856542957,-3.707366117473964e-05,-4.25054411507125e-05,-0.00021165741590761558,-0.00012332904153676425,-0.00012990559024158397,-0.00038842639155993924,0.000204523893175599,-7.869067279279816e-05,-0.00015810566717678871,-0.0006136796246953994,-0.00047506349308448754,-1.595548816780303e-05,-0.00013690480691996162,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[6.040390583309434e-05,-0.00018809319739056135,0.0004512073693467329,-0.0005631772066084554,-7.9463124341712e-05,-0.0006202472130051306,-0.000387976049531309,-0.00015834580536397094,-0.0005011805057663882,-0.000658941949999908,-7.75349055516301e-05,-5.095822563991349e-05,-4.973813935777171e-05,-1.2612255342571172e-05,0.00011329340221004259,-0.00015486613012823155,-0.00010630586784473521,0.000592620241019318,0.00044888557834385734,-0.00013767248887942518,0.00010007359097390108,-0.0003412720307863988,-0.00010188884534808687,2.5005602305131902e-05,-0.000331668138302818,-1.879979953786296e-06,-0.0001812645016510915,-0.000313914451830526,-0.0007396416692128459,-0.00047628038392480323,-3.177991464813128e-05,-0.00021777684025205005,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[-7.10096043579233e-05,-0.00014405321985314076,0.0006737637047891988,-0.0005075503152395201,-0.00016137288579508625,-0.00032829087164710103,-0.0004449855221954876,-0.00017581513890402016,-0.0005611852629358974,-0.0004437409563460659,-0.00011418623340564286,3.7276140214574306e-05,0.0003156770302098836,-7.309612606318591e-05,-0.00012549032769074698,2.0598304597681118e-05,1.4334205578067052e-05,0.0005364454268946548,0.0003095948504033637,-8.831659989262345e-05,2.3123298444681103e-05,-0.0004874243407466412,0.00014934882626712074,-0.0001412318190724056,-0.00047359860217642644,0.0001641859818038973,-0.00024117670478298426,-0.00039204097692465285,-0.0006910482313612817,-0.0005335548385799426,-0.00025133559333450565,-0.0002539620023691877,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[9.923004919528897e-05,-0.00022727119730958975,0.0005258806505054066,-0.00048292394966820753,-0.0001851048717909464,-0.0003821821664754389,-0.0005821564583275629,-0.000228216785028477,-0.0004265632175991755,-0.0005855264337781245,-0.0001614301499723156,3.853876891850612e-05,0.00015349276902262143,-0.00018112706142999773,-6.909368842327196e-05,-6.434947088610724e-05,8.230171935952596e-06,0.0004100492096339684,0.0002672330517014144,5.257470746792464e-05,0.00021990161244930893,-0.00046880505843097857,-7.161670404528243e-06,-3.6748300908891914e-05,-0.0004244263330992975,-5.138934950714275e-05,-0.0001924779866356352,-0.0003701660546284036,-0.0005333001640773867,-0.0004022397632898562,-0.0001617048353082636,-0.0002553380004813006,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[5.8779489939493416e-05,-0.0002561420999896693,0.00048492210730632636,-0.000775047243499344,-3.443567374414297e-05,-0.00039570994572651555,-0.0005245972747311306,-0.00017788722535956068,-0.0005567302351235767,-0.0005666358828469564,-5.269804759261965e-05,2.4910806896609666e-05,9.09068518351858e-05,-0.00025115629248071694,6.17220822894967e-05,-0.00022284409504130096,4.459799298879271e-06,0.0004062032979677359,0.00033914138626725895,1.6937272191380472e-05,0.00015847438442361078,-0.00045778098317888837,-0.00010196651870964951,6.6258508088175e-05,-0.0005813201623890612,-7.346703431766954e-06,4.40198329108465e-05,-0.00025936727800754454,-0.0006395647416217048,-0.0004816246359389328,-2.2640910177444972e-05,-0.00023367076681327477,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00016876571038464483,-0.00023768412158125756,0.0006158810580244829,-0.0005590734347393911,-0.00013713868582133817,-0.0004927350983300199,-0.00043952387322153234,-0.00028151912572685605,-0.0003888618287875865,-0.0004786387157766311,-5.071586743759575e-05,-0.00012937892542906523,-9.129705084269018e-05,-0.0002649023998694393,-2.2123047591475434e-06,0.00016016250432869726,7.709844434664916e-05,0.000500936851815704,0.00043598730944176544,-1.5083970959153371e-07,9.396847692666205e-05,-0.0003191117949614862,-7.763267860263721e-06,1.2012694841512733e-05,-0.00047118234973323733,2.6339001234351698e-05,-0.0001536537650276368,-0.00024497683087625543,-0.000557286532561394,-0.00030992794884658923,-0.00024594792150926147,-0.0002734163864134118,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0002090097916383876,-0.00025250033780463795,0.0007144051357945928,-0.0005520357486059003,-0.0001371067057929584,-0.00031031187047877496,-0.0005113908971438473,-0.0003064313883033774,-0.0005341999849132007,-0.0007126113846233276,-8.943458980980951e-05,-1.576334148022424e-05,0.00016281906508569907,-0.00016117880480574987,7.705378074125039e-05,-0.00013034587834549272,-8.275014409436415e-05,0.0004181228868994435,0.00041220674751795566,-0.00023046424657208547,6.667784380323323e-05,-0.0003169706189697971,6.269486911958174e-05,-0.00025140912989534423,-0.0004855098050293114,0.0002529087986678033,-0.00035039538847072557,-0.00019472543555954845,-0.0004819922267636911,-0.0003464404183044374,3.287349604810662e-05,-7.022784915711702e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0001587784475996266,-9.159198203891408e-05,0.0005690941849986467,-0.0006479795903102545,-0.00025290989306975514,-0.00032039851741483527,-0.0005393001095171343,-0.0002407299799723747,-0.00047321913612153156,-0.0004974633921613143,-0.0002015669312915318,3.678742315745605e-05,0.00019412828975567744,-0.00013272889825082036,6.287065404628234e-05,-0.0001527119361737523,-9.093352059913008e-05,0.00033902288324342086,0.00036799930783517563,-0.00012841301145699195,-1.5398415491806573e-05,-0.0001893550038075103,3.5641879523671815e-05,-7.006848925544695e-05,-0.0005768205043696137,0.0002645821315760116,-0.0003022384303544697,-0.00029309605881969484,-0.0006360881052293965,-0.0003285598777409554,3.071203976511902e-05,-0.00025259222448798527,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00012052288936736833,-0.00024166695311022985,0.00032627431450588443,-0.0006175906448378926,-6.560970275410155e-05,-0.00048386500525801276,-0.0006779711042979886,-0.00018805769568170917,-0.000526103283635145,-0.000661458560784139,-0.00018641339625172224,-3.840531614804863e-06,0.0002892293245743202,-0.00018137706541310897,-1.8291890965436243e-05,-3.2712744149978015e-05,4.3667414283758226e-05,0.00045904999500670095,0.00029373428253203605,8.330624551876998e-05,0.00035385949055003087,-0.00037226807979019006,-6.421132972734262e-05,8.244543828606943e-05,-0.00046329758767543386,-9.078039883808988e-05,-0.0003296534549952048,-0.00032328458734687466,-0.0005339567382592657,-0.00045674412504810694,-0.0002256447351960096,-0.0002456860211498335,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0001257690929729501,0.00010681337411684358,0.000373848527445377,-0.0005844599113051268,-0.00022734485564191348,-0.0005592228661420105,-0.0006967070466902394,-0.0002848447312605806,-0.00031265307302602216,-0.0004773489200619977,-0.00021137410760623128,-2.3073245675640883e-05,0.00018854376209520145,-0.00019950814892758672,-0.00020973505798279116,-0.0001368331301982654,-8.973372809693327e-05,0.0003762959651318714,0.00033838014334081014,-2.457118752709929e-05,0.000124504251943055,-0.00044647121855288834,1.806733259991337e-05,-3.258434762642578e-05,-0.0005431716082914198,2.776366996899163e-05,-0.0004454327734276192,-0.00031939333266611797,-0.0005021245598422356,-0.00029194965732234256,-9.091103843225022e-05,-0.0003111773677529185,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0003465951582904929,-0.00025084292644980444,0.0004803672326479692,-0.000475304556398376,-8.01739648770187e-05,-0.00040448757803430573,-0.00042019119294123584,-0.00014892326506488524,-0.0005980526551068846,-0.0005699473942663579,-0.00015676173083644347,-9.798610846873563e-05,0.00027489038416291396,-0.0001168322249936989,1.8978577772156358e-05,1.6175990794218886e-05,-0.00014081361030688952,0.0002953825960701612,0.00034591602588655374,-0.00023561235760607784,0.0002406520288127652,-0.00034895810686915465,2.836218428312804e-05,-7.422418266792629e-05,-0.0005345433892985673,0.00019628705483076093,-0.0003174072634873405,-0.00032146810384615904,-0.0004798959066567759,-0.00038391698763958523,-4.626512072660649e-05,-4.978147754302387e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[9.800973145356208e-05,-0.00018546055099084754,0.0003057310770320842,-0.000492361016585603,5.748118244208234e-05,-0.0005655668636187085,-0.0006589032494778721,-0.0001608271954060051,-0.0004566952123780225,-0.00045998888988881903,-0.0002782153926212279,1.7170472895256989e-06,0.0001889355124169639,-0.00018870635669476557,2.651536648335412e-05,-0.0002408569851721072,0.00022069723978997654,0.0003166804277043812,0.0004908139881440333,-0.000108651794579744,0.0003522713830104398,-0.0003532297685544786,7.808893515525789e-05,-1.0768392265441923e-05,-0.0005862465888089195,0.00015510188163569646,-0.00036940206737123783,-0.0003562166437926205,-0.0005247963982659966,-0.0004904590880578506,-0.00026207559292362905,-7.692519884316738e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00031260720335134185,-0.0002923715110178909,0.00036531263049621976,-0.0006838740313238141,4.510648474946916e-05,-0.0005389234687094188,-0.0005413025355899748,-0.00024116072208967847,-0.00035259850218540684,-0.00037539124182094634,-0.00036269073142218675,-0.00014817619168947123,0.00028461445633077583,-0.00036079139198420834,7.922234695250138e-05,-0.00022506938567243306,-0.00011726174655264926,0.0003807097900058672,0.0004375027909566318,0.0001356264129795296,9.459401699112584e-05,-0.0002174176355169194,0.0001576573644593597,-0.00011685606284820638,-0.0008506025134022335,-1.2200904588525505e-05,-0.0004927522835308463,-0.0002999574380861439,-0.0006397879591293153,-0.00025382341227711005,-0.00014794174488801521,-0.00031955681692505606,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.000278912068510452,-0.00020517702256941082,0.0003201434785566372,-0.0005102560800245837,-6.187135929033914e-05,-0.000519646559623254,-0.0005142642667477538,-0.00017742005483297265,-0.0004362951643958582,-0.00040116920758857783,-0.0003298046861994121,-5.095703456057221e-05,0.00022843581708370796,-0.0001514687602032129,-6.755360246279788e-06,-0.000203294473048575,2.8278502573815117e-05,0.0004742096751035256,0.000398887779523319,-9.118268629459796e-05,0.00015948630769109574,-0.0004412326952660199,0.00029382918788646486,-7.876957556068156e-05,-0.0006701056445750118,0.00019429670929608847,-0.0004114737456639542,-0.00030951599876607555,-0.0005220197046608555,-0.00036088577747771163,-7.202467729549759e-05,-0.00030916662716733444,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0004914016125684459,-0.00011324041304223492,0.0003874128488498927,-0.0007396491970438037,-0.00019055363933714062,-0.0006451355311655268,-0.0006774565951377675,-0.0002643950445009434,-0.00046686488935595574,-0.0004056306225392092,-0.0003247841948903729,-0.00011282792230430655,0.00023882887338768058,-0.00011643593298973688,0.00010523318303179709,-0.00032863623826686657,-0.0001236858169017506,0.0004095435646898148,0.0004494310812578244,4.41349140563144e-05,0.0002751477074118198,-0.0003308664913707982,0.00017431094218691318,1.7184916934064938e-05,-0.0008354280314803312,0.0002447921866398368,-0.0003485590702624786,-0.00044052864521710986,-0.0005961987977288607,-0.00034608000607835084,-0.00011110893924718625,-0.00024116717663603645,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00029091043661219916,-0.00012020243784596909,0.00043631370457147296,-0.0005650455825936822,7.929055615945884e-05,-0.0005402166686424092,-0.000663378975902701,-0.00016912482155078198,-0.0005012487298291202,-0.00035870711339607,-0.0002666046643173091,5.1366858523829545e-05,0.00019939263827888767,-0.00019645614399717033,-3.3870124492722384e-05,-0.0002516440768321882,0.00019974768336486996,0.00029159920908702257,0.0003506503547671338,-9.515417496826005e-05,0.00024422678831826505,-0.0004913806247987144,0.00015854614886436349,-4.247101203171687e-05,-0.0008287251994470255,-4.4881834024263836e-05,-0.0004240002275360583,-0.00033592853311023335,-0.0004842425557131864,-0.00021509364020203334,-6.308573498942717e-05,-6.6997159909381e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0004314373528789769,0.00014253023274677973,0.0004392270891128364,-0.0004973169217028359,-0.00020476957457561632,-0.001030657236622348,-0.0012102050312079947,3.078696361041641e-05,-0.00016836900317732952,-0.00046621826727100195,-0.00016157094005537926,0.00021436448818911547,7.397954021494308e-05,4.403951549942859e-05,3.1278371967567123e-06,-0.0001469758236505918,0.0002562280486824334,0.00042738291700698925,0.00037134690112001736,0.00024089411146875812,0.0004576649671560773,-0.00047880810781869386,0.00017709081195637,0.000402891309371714,-0.0006208289200963332,-1.8647427101238006e-05,-0.00020381827395893283,-0.0006420199886181627,-0.0004280505940105503,2.863659606113647e-05,-0.00015883793438921536,-5.651632240532906e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0003453895107239074,-0.0003911332881016465,0.00039463974872411885,-0.0009202815771434604,0.00018173180230333442,-0.0006347087741421027,-0.0005852211681576003,-0.00029152294356470955,-0.0005076474653479245,-0.0005024622067763114,-0.0005082211617521653,-0.00017486316128946728,0.00019186399833592992,-0.00028749269414333014,1.6634810854626943e-05,-0.00041702225800366793,-0.0002176433317967309,0.0003455055050335565,0.0004435217175107393,-4.500345976171145e-05,0.0003321792684135712,-0.0002734434468023276,0.00017972778461379965,-0.00026742974378572546,-0.00076693531431922,0.00013689879298480943,-0.0005924568205187999,-5.239359883447347e-05,-0.0007715204843342559,-0.00031929404447187467,-0.00036035348028642976,-0.00019058172695220543,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0005022715903283178,-0.0001896458600579903,0.00030703152647003454,-0.0010489323719372892,9.393734892399155e-06,-0.0005108169664912683,-0.0006834789340382727,-0.0002789731409759276,-0.0004470549035095754,-0.0002962006774711693,-0.00031054190347004607,-1.2939360504723629e-05,0.00023561255003749407,-0.0002950289075753143,1.5947709187392193e-05,-0.0005918873339805961,4.1509080428752835e-05,0.0004929042721547602,0.0005326880308626339,-1.3244737591101141e-05,0.0004112827266860012,-0.00030497438179739693,0.0002976797657719046,-0.00012381428799078387,-0.000723441533058096,0.00019352000333762635,-0.0005419526299473382,-0.00024407346040170632,-0.0006049041113027651,6.970974543080388e-06,-0.00014474521964324914,-0.00026733788161364974,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0006230705576738217,-7.18402263409693e-05,0.0003336142688732536,-0.0010026727251749247,7.431316286788088e-05,-0.0005874142533420311,-0.0006350425699708559,-9.28632337708658e-05,-0.0005481668504430029,-0.0005018527058564075,-0.00027105237818668453,-0.00021531964051136032,0.0003386313336794576,-0.00020942398450645607,0.00024232104343523567,-0.0004249490098772964,-0.0002977411631612361,0.000347864702313931,0.00040816610487486645,-0.00016999259558030886,4.73647738803051e-05,-0.00020694789067610673,0.00023386220663231384,-2.455424703978717e-05,-0.0009380738809722285,0.00014373578285325431,-0.0005102036243557469,-0.00034474671778654444,-0.0006233372720870243,7.726728685009544e-06,-0.0001645513414830437,-0.0003569587257755967,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0005785357986253753,-0.00019572812714886004,0.00025595943788298334,-0.0007406728168443406,0.00012920241922056568,-0.00048729774761873697,-0.0007809941247107125,-0.0002620480585347333,-0.00029091331367223967,-0.00032236353488292624,-0.0005403407929634134,-0.0003059976012872036,0.0001545046557502972,-0.0005180111728800781,0.00023048565071157636,-0.000356595559553125,-0.00023513056646721903,0.0002909583025909672,0.0006189902186511283,-0.0001382450086347068,0.0002164651836884165,-0.0003514514877534188,0.0002812142667493745,-0.00012494793709520328,-0.0008121521153169129,-3.5510253178190066e-05,-0.00044527497453385835,-0.000419232593302155,-0.0006004592306547486,-0.0002747363619623835,-0.0002152522853422177,-7.531834519642072e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0005228313033684049,-0.0002045148598238084,0.00021810118028564246,-0.0008189646201233614,7.473591014573433e-05,-0.000644965167083877,-0.0005985172849613756,-1.9833408051489412e-05,-0.000455816252452109,-0.00029080836375623427,-0.00043624519924906086,-0.00027959211618860355,0.00013751389138778932,-0.00029935998023774136,0.00023639625345958746,-0.00043516806587792187,0.0001163745598135857,0.00045211833649782147,0.0005520537739601546,-0.00017864888069646966,0.00035022477973129586,-0.00022605975986786177,0.0003429780812493777,-0.0002605650891935475,-0.0008025363850584329,8.3677705557208e-05,-0.00042498404370159605,-0.00044801427498392056,-0.0005815438140688383,-0.00017792942357426904,-0.00013095312185452176,-0.00021344459551866327,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0008505127065709217,-0.00034646920023970797,0.00041400089566279174,-0.0006615554949402713,0.00013307222431363248,-0.0005839378657413805,-0.0007690820380207519,-0.00030191227785686403,-0.0004229700739096136,-0.0003859811531195251,-0.00037036933107572603,-0.0002887972541496974,0.00026140738863821293,-0.00016950066962889934,0.0002539973271849773,-0.0005013349596879635,4.465880928977464e-05,0.0003929195080823843,0.00042336537987665995,-0.00016548465458831867,0.00022464310435493006,-0.0003669942521908915,0.00024855690479358455,-0.00030499079817320287,-0.0009582676700385811,0.00010659049501967448,-0.0005467931515244473,-0.0004319223995802808,-0.0006308649117945899,-0.0001408611958386213,-0.00017298862209545092,-0.00017478995619662775,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0007663304668111254,-0.00022334088254740648,0.0003383141965410754,-0.0007160554225839674,1.486146994928066e-05,-0.0006962355356150607,-0.0008673493914762778,-0.0002722278496567318,-0.0004341388700754764,-0.00033099065500217465,-0.000524789772743148,1.8802418629848496e-05,0.00023254976589327523,-0.0002689356293431656,-2.3767104225970718e-06,-0.00032597124770923636,-1.934397769827567e-05,0.0005525233799965963,0.00032332755398804987,-0.00019461859671737996,0.0005779101635688537,-0.0001643313421788461,0.0001825739125020961,-0.00032547206785545806,-0.0008711172452848951,-5.315231321531596e-05,-0.0007566257092942822,-0.00027310323662413713,-0.000521191236025947,2.120630234270519e-05,-0.0001689152654844871,-9.146381330249259e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0007176298070243021,-8.495109149744647e-05,0.00020725935995669298,-0.0008210852181291162,0.00036241623783516476,-0.0007461178128679526,-0.000773240322660922,-0.00024148844904161744,-0.0006327049557195434,-0.0002745333244485138,-0.000580287896840143,-0.00011559255079286851,0.00012619069197311524,-0.00012535689682954202,0.00011001001678307536,-0.0006983201119614845,0.00013179726732450234,0.0003528086048845921,0.00042157979173305845,8.454812329589824e-05,0.00041262911597195575,-0.00024361874592718392,0.0004730439230831664,-0.00014653173038864235,-0.0009763058234701575,0.00010192307521604019,-0.0005814286484190174,-0.00047097071033760403,-0.00046978534983540334,3.630755197065834e-05,-0.00015267355351039302,-0.0002762500867194555,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.000988279030766214,-0.00011193926359782437,0.00029753750582631064,-0.0008148316927400617,0.0003601439489822867,-0.000634625409329351,-0.0006064442609134052,-0.00026410445513789995,-0.0005803889795400082,-0.00041478464826818465,-0.000452456977858333,-0.00025467044155384424,0.0004337780652478681,-3.282409605403838e-05,0.0002985575820464406,-0.0005075817855816238,-3.312604948098758e-05,0.0005485878653588746,0.0004285376571582436,-0.00023695490846239718,0.00045753685567476887,-0.0001654970775008293,0.0002578295142839869,-0.00046783565535376816,-0.0009661608570589632,0.00031594675560288294,-0.0006697278826166209,-0.0006048073898651723,-0.0005348527660304528,8.806642550386435e-05,-7.12900672891079e-05,-0.000180849331604601,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0012799306586795387,-0.00011609891476018901,-0.00018961644061649648,-0.0009814035637777125,0.000334329517099425,-0.0008208328128141646,-0.0011041020591337413,-0.00018385037956405862,-0.0004243471326545066,-0.00021423107180025322,-0.0007238124916551552,-0.00029009999360125145,0.0004555145854380454,-0.00041165855124952847,0.00013039271871116218,-0.0006294888290698887,3.239798216444413e-05,0.0005619792408228531,0.0005423404403701303,0.00016347639177410642,0.0004854003784143098,-6.943137548379509e-05,0.00026136447349120435,-0.0003036407644245401,-0.0010161211835251923,2.707980970437988e-05,-0.0007039192541411862,-0.0004821165290331708,-0.00039951244770221014,-9.558740912239809e-05,-4.7295453984669565e-06,-0.00012833686657413442,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0012775381251695951,-0.00013947233706556453,8.57960276327696e-05,-0.0009239716458483726,0.0003692371243814757,-0.0008155057373946203,-0.0009154839722884558,-0.0004629308572952987,-0.000260701405798833,-0.0002015809797938111,-0.0006795102731709045,-0.0004130164083367261,0.00022859119241492074,-6.17517073677092e-05,0.0001294631858833774,-0.0007151638642497232,-4.111323820974658e-06,0.00036292272649656907,0.0006266471617784029,0.0001430436770840007,0.0006343304491662796,-0.00024353004110653722,0.0004381519898898443,-0.00029825212180703347,-0.0010856957437933251,3.230189969734512e-05,-0.0008949368587888032,-0.00039976762841360136,-0.000590168164218352,0.00020523154685717467,-2.9479384153754458e-05,-0.00015031850195480195,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0014300726748691314,-0.00026960544548765216,-6.837008438040438e-05,-0.001041008151036419,0.0003217820538118107,-0.0008119742443796754,-0.0009740010273442877,-0.00036820321634852335,-0.00045079556078906176,-0.00010935457771694364,-0.0006579096764415405,-0.0003708221009427662,0.000504458565957592,-0.00018279298624824988,0.00015697136762222725,-0.00080808629182061,1.7745323595333102e-06,0.0006547031894434473,0.00038513146012586865,7.55223892181788e-06,0.0005589304095644402,-0.00020072376445537493,0.0005630081201722845,-0.0005158598284388442,-0.001198716647073467,0.000192230140577904,-0.0010505197031753259,-0.0005147016716902768,-0.0005536509223027507,0.0002992349873082144,-0.0001253940693047762,-0.00017768965212242884,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0014581847210525186,-0.00011589271346896175,-8.071380897714929e-05,-0.0008540794919859743,0.00026833899791747204,-0.0009006218983920789,-0.0012100464131414006,-0.0005036984802006188,-0.0004206799913193579,4.043392514613556e-05,-0.0007708648306278983,-0.0004836910391176712,0.000548241468306125,-0.00019426762083596207,0.00021140021879910865,-0.000884995007174075,7.94664638636402e-06,0.0006789285127463915,0.0005767756524801427,-0.00012647241954257568,0.0005496540836719104,-0.0001501012512091369,0.0006481686814921488,-0.0004817397959536755,-0.001309917189123919,-6.6250345643248995e-06,-0.0008750669260404931,-0.0008697355646464645,-0.00048029027264835823,0.0002309526474765304,-0.00034650795601576646,-0.000264255418293878,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0017211000539813818,3.190772649854956e-06,-0.00011621853440412869,-0.0011462172904245999,0.0002282440259124972,-0.0008186239639777818,-0.0012140426704782784,-0.0004868916349729201,-0.00048481947980202124,7.679167543910561e-05,-0.0009291991979341632,-0.0004038805210967064,0.00010944335120906528,-6.212975389819267e-05,0.00034731774792678467,-0.0007740396324802827,4.7794141119790336e-05,0.0007619928079220518,0.0003242233270811773,0.0002137560045804198,0.0007339382965538509,-0.00026720901211104326,0.000669151481604884,-0.000545010510676317,-0.00149745343253369,-0.0001117261160056035,-0.00113663371092418,-0.0005853755367753632,-0.00030144784005726826,0.0006822016954354146,-9.273789013359384e-05,-0.0003724039135961214,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0018249717589373276,-0.0001403736170157726,-0.00021992990085104757,-0.001173904298906398,0.0005168708523663911,-0.0010016972748317634,-0.001236355146270936,-0.00047726624759000574,-0.00035798931081845514,-7.237269065960696e-05,-0.0009795028338387337,-0.0003190065322340252,0.0004528435526032611,-0.00016828024395198297,0.00045665757312268935,-0.0009605603017002391,-4.720039567336612e-05,0.0006218825803389131,0.0006089096811504705,-0.00012478941660572774,0.0008444995813996359,2.8287119579125107e-05,0.0008833668947008282,-0.000616354430853737,-0.001451084816979714,3.7958479922737515e-05,-0.0013667165211541429,-0.0008065722230412459,-0.0003924302449070133,0.0004787033437331477,9.59694583259698e-05,-0.00021284744730573545,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0020749538827026666,-4.442121119891714e-05,-0.00032069383053934204,-0.0011619149605477752,0.0005108628909621678,-0.0009093999634451748,-0.0014244214387301097,-0.0004318830997869261,-0.00035038217526620546,0.00025320838368016543,-0.0011779537257083066,-0.00029589203551460186,0.00045871012903274475,-0.0002105891937599181,0.00039671474133302865,-0.001135497952729861,0.00031408565040999726,0.0007560467109898113,0.0006771548147310826,2.351018392638523e-05,0.000704284504688797,8.793706226640073e-05,0.0006123464763972436,-0.0006954354386331992,-0.00197315654816118,0.0001162878915221385,-0.0012967732054968903,-0.0008300868163971171,-0.0003472664006947855,0.0006904704095619854,-0.00010739271689303027,-0.0002887988523467449,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0024166330701574246,-0.00015188657333792434,-0.00042907024120359696,-0.0014046191011593894,0.0004921480786678606,-0.0013300182888697208,-0.0014867895225878064,-0.0004982959222027247,-0.00019501439392798789,0.00038046993596855893,-0.001397614386964174,-0.0005651455350248425,0.0006009810953485246,-0.00018550813948663006,0.00029075132402410595,-0.0013399674311995633,0.00017395331577777385,0.0007975286735257204,0.0004299587054793174,-0.00014651441615777224,0.0008876947652255779,-0.00010739077399756951,0.0006881654739917199,-0.0006809119451912291,-0.002001157772207424,-0.00012026148523389359,-0.0016442605862907187,-0.0008167507416307069,-0.00044297243875973707,0.0006786243589031253,-1.3462238926531696e-05,-0.00023487060727009687,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.002943797137889329,-0.00012473131317269426,-0.0005193830468587561,-0.0013791188150560105,0.0009122650624724265,-0.0015396192537141503,-0.0017900637610565365,-0.0003361280162851087,-0.0005254485830386377,0.0005460010957437489,-0.0015401063075287922,-0.00055016461126936,0.0006841202579587884,-0.0003260038107102678,0.0005548219788249906,-0.0016234514731214382,-4.233144314989791e-05,0.0011771386376033769,0.0006220303808941401,0.00011478776473555708,0.0011013148123279045,0.000183219039675977,0.0009342037672630458,-0.001032552547843123,-0.002454138952505465,-0.0001303346661465638,-0.0015813171808019093,-0.0008147395935682632,-0.00020680513916946936,0.0006245179226621994,0.00013636729225054397,-0.0003220714032572056,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0037082581379819708,-5.8343890142610026e-05,-0.0008463569838835656,-0.001984776284122914,0.0009941373732552342,-0.0012425141993695097,-0.00212001539399512,-0.00047862830489107445,-0.0006576021312465436,0.0009018650738860242,-0.0017189664795653435,-0.0007298039774204611,0.0009798585246985935,-8.089179869602369e-05,0.0005650484125921212,-0.001801780643577292,1.989029782448534e-05,0.001192418989280261,0.0008670890772807461,-7.309531074110623e-05,0.0012770874422833728,4.430933663145023e-05,0.0012208009960697113,-0.0009561613244999013,-0.002666127911724338,-7.391433791082277e-05,-0.0020334907524979253,-0.001011481451584136,-0.00048660658694488337,0.0014258437283541012,0.00032333690405847616,-0.0002507752628957217,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.004506041633924975,-5.2669579031458564e-05,-0.0010487464022953205,-0.0019235645160633687,0.001003570553575649,-0.001418680758921324,-0.002625860967472475,-0.0007692727532509953,-0.0006758872756110795,0.0006781528837269521,-0.0022717125283971047,-0.0009214987155874936,0.0008177687206913917,-2.5327092303851308e-06,0.0009624863881706279,-0.002244350140732822,0.00018004405881281483,0.0014485721675036665,0.0010489002271619756,0.00014706672202899936,0.0015513955527768357,0.0005558050830361173,0.0014559905582710339,-0.0016384785539584321,-0.0032419478364864003,-4.995226151608755e-06,-0.002428316562899735,-0.001138780869072103,-0.0004583609034626021,0.0020006142307806346,0.0001067197885390719,-0.0001583327753101187,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.005969399711622752,-6.715598485654402e-05,-0.001514739964072108,-0.0024620403688691977,0.001410311637641187,-0.002333341228303388,-0.003068513746211793,-0.0009558788027794936,-0.0006478338051964616,0.0016447940877011404,-0.0032731306711613183,-0.0015345633657800441,0.0011426685490201409,-0.00011077916592650592,0.0012277780740568372,-0.0029780001931203563,8.01447299059032e-05,0.0016086580667406005,0.0015053281599232496,0.00016115557333212953,0.002223685240908513,0.00030705339675408103,0.0023762325958721436,-0.0019618189993614835,-0.004641570304983509,8.177952296420253e-05,-0.0035722950612218037,-0.0016892342309507867,-0.00018259734280306014,0.002645329239965179,6.69423488702792e-05,8.87555236046648e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00824943480624526,-0.0004723915738129578,-0.002059933867623648,-0.003863380384442113,0.0021945187395791335,-0.0033994857095492543,-0.004514518157334497,-0.0009820501182453663,-0.0012412960595850747,0.002257362830302699,-0.004493798833693013,-0.0022777865668890994,0.0014719689042839276,-0.00040585052112654255,0.001454921771579839,-0.004392464398242825,0.00022798643219177934,0.002784089803903623,0.0018011929451482117,-9.823811287366701e-05,0.0023141034092456205,0.001135026245210917,0.0032793488905741865,-0.0028228665431078047,-0.006247225846576851,-0.00016646058835320562,-0.005390886113231686,-0.002372115882911847,-0.00012200496619545637,0.00422087803728024,5.6845817336076256e-05,-0.0004166027163227668,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.011843649182962213,-0.0010372650236451755,-0.0027459650687356087,-0.006793375040524862,0.00519682670317198,-0.007370586259491748,-0.009023080586617169,-0.004806869925931095,-0.0038858632801635814,0.0016718903992965065,-0.007917264277293655,-0.004024168103312272,0.0005367635281382247,-0.0011899072744085146,0.002305326919043356,-0.007970915187990158,-0.0013115980885531446,0.0050438160985091865,0.0050116716080748904,-0.002666021617107856,0.004390249758829774,0.00026341509609881486,0.005527582758794092,-0.006391175847588189,-0.01109615825303382,-0.0010576769547954484,-0.011689750179336248,-0.004274238752273842,-0.0020680048517609374,0.00749874864791216,-0.0006773966715538332,-0.0005128382827658703,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]],\"type\":\"surface\",\"contours\":{\"z\":{\"project\":{\"z\":true},\"highlightcolor\":\"limegreen\",\"show\":true,\"usecolormap\":true}}}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"scene\":{\"camera\":{\"eye\":{\"x\":1.87,\"y\":0.88,\"z\":-0.64}}},\"margin\":{\"l\":65,\"r\":50,\"b\":65,\"t\":90},\"title\":{\"text\":\"Mt Bruno Elevation\"},\"autosize\":false,\"width\":800,\"height\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c44a9b8c-2bd2-4e1c-a86e-772256a1e093');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# fig = go.Figure(figsize=(24,12))\n",
        "\n",
        "fig = go.Figure(data=[go.Surface(z=z_act[0,:,:])])\n",
        "fig.update_traces(contours_z=dict(show=True, usecolormap=True,\n",
        "                                  highlightcolor=\"limegreen\", project_z=True))\n",
        "fig.update_layout(title='Mt Bruno Elevation', autosize=False,\n",
        "                  scene_camera_eye=dict(x=1.87, y=0.88, z=-0.64),\n",
        "                  width=800, height=800,\n",
        "                  margin=dict(l=65, r=50, b=65, t=90)\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKwMveP0hGOT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "wml3Sd1zhmLd",
        "outputId": "c49edd2c-d994-412c-b4d6-64f9cb2a7864"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "x = np.linspace(-1,1,100)\n",
        "y=x\n",
        "plt.scatter(z_op2, z_act[:,:128,:])\n",
        "plt.plot(x, y, '-r', label='y=x')\n",
        "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "plt.xlabel('Actual signal peaks height')\n",
        "plt.ylabel('Output signal peaks height')\n",
        "plt.title(label='Pearson Correalation',\n",
        "          fontweight=40,\n",
        "          fontsize = 40)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "KH5esSbfhmOV",
        "outputId": "8e8d533f-f2f2-475a-ed8b-292f20d19e31"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-117-d230452bd3f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnSignals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'nSignals' is not defined"
          ]
        }
      ],
      "source": [
        "nSignals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SJCETEPyzKN"
      },
      "outputs": [],
      "source": [
        "points = []\n",
        "temp_2d = np.zeros([130,122], dtype=np.float)\n",
        "for i in range(2):\n",
        "  temp_2d[1:129, 1:121] = z_act[i,:,:]\n",
        "  for j in range(1,129):\n",
        "    for k in range(1,33):\n",
        "      if (temp_2d[j,k]>temp_2d[j-1,k-1]) and (temp_2d[j,k]>temp_2d[j-1,k])and (temp_2d[j,k]>temp_2d[j-1,k+1]) and (temp_2d[j,k]>temp_2d[j,k-1]) and (temp_2d[j,k]>temp_2d[j,k+1]) and (temp_2d[j,k]>temp_2d[j+1,k-1]) and (temp_2d[j,k]>temp_2d[j+1,k]) and (temp_2d[j,k]>temp_2d[j+1,k+1]):\n",
        "        points.append([i,j-1,k-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdI2lvT92SjL",
        "outputId": "b2f2e075-a2de-48df-e752-fa95efd8822b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.02809409, 0.01565592, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.00844708, 0.00207817, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ],
      "source": [
        "temp_2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJg3yLR7Cqea",
        "outputId": "5fa0cb71-290a-4d4e-b52b-47e2c0931473"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "723"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "source": [
        "len(points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yk1-MuqV1Fg2",
        "outputId": "b14a9383-5a0a-41a8-f38d-ea018f343f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "723\n"
          ]
        }
      ],
      "source": [
        "z_op_1 = z_op2\n",
        "z_act_1 = z_act \n",
        "\n",
        "origin = [0,0,0]\n",
        "\n",
        "xyz = []\n",
        "xyz.append(origin)\n",
        "print(len(points))\n",
        "\n",
        "\n",
        "\n",
        "for xy in points:\n",
        "  flag = 0\n",
        "  for i in range(len(xyz)):\n",
        "    # print('hi')\n",
        "    if (z_act[xy[0],xy[1],xy[2]] > z_act[xyz[i][0],xyz[i][1],xyz[i][2]]) or (z_act[xy[0],xy[1],xy[2]] == z_act[xyz[i][0],xyz[i][1],xyz[i][2]]):\n",
        "      xyz.insert(i,xy)\n",
        "      flag = 1\n",
        "      break\n",
        "  if flag==0:\n",
        "    xyz.append(xy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSNu-YOOYEiB",
        "outputId": "128dea45-a336-440e-a082-d527f7f6ee5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "724"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ],
      "source": [
        "len(xyz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNI-4ueOeAN_"
      },
      "outputs": [],
      "source": [
        "# xyz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdYVyyWseIj-",
        "outputId": "4c3112f3-d74a-4453-bd5b-931850cfb96c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.0011311587309334715 -0.0006560437855005061\n"
          ]
        }
      ],
      "source": [
        "print(z_act[1, 92, 11], z_act[0, 10, 23])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SvrO3DghmQz"
      },
      "outputs": [],
      "source": [
        "for i in range(80):\n",
        "  for j in range(128):\n",
        "    for k in range(32):\n",
        "      # if (z_act[i,j,k]<0.1):\n",
        "      if [i,j,k] not in xyz:\n",
        "        z_op2[i,j,k] = 0\n",
        "        z_act[i,j,k] = 0\n",
        "# for i in range(79):\n",
        "#   for j in range(128):\n",
        "#     for k in range(32):\n",
        "#       if z_act[i,j,k] < 0:\n",
        "#         z_act[i,j,k] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "D1Af8b3ohmTP",
        "outputId": "394d31b8-e8ad-4f18-cda7-f56df9413158"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "x = np.linspace(0,1,100)\n",
        "y=x\n",
        "plt.scatter(z_op2, z_act[:,:128:,:])\n",
        "plt.plot(x, y, '-r', label='y=x')\n",
        "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "plt.xlabel('output signal peaks height')\n",
        "plt.ylabel('Actual signal peaks height')\n",
        "plt.title(label='Pearson Correalation',\n",
        "          fontweight=40,\n",
        "          fontsize = 40)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwNd_mT4l2JQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYWG1bdGYNu5",
        "outputId": "fbb09484-5272-4c11-ea99-f8a9c01495e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficient of Determination 0.8889300965569372\n",
            "Pearsons correlation: 0.945\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "from sklearn.metrics import r2_score \n",
        "# a =[1, 2, 3, 4, 5] \n",
        "# b =[1, 2.5, 3, 4.9, 5.1] \n",
        "R_square = r2_score(list(z_act.reshape(8192,)),list(z_op.reshape(8192,))) \n",
        "print('Coefficient of Determination', R_square) \n",
        "\n",
        "corr, _ = pearsonr(list(z_act.reshape(8192,)),list(z_op.reshape(8192,)))\n",
        "print('Pearsons correlation: %.3f' % corr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9w1K47dYNy1"
      },
      "outputs": [],
      "source": [
        "# stat = []\n",
        "# r_sq = []\n",
        "# for k in range(100):\n",
        "#   train_ip, target_2d, target_1d, nSignals = make_2d_mat(1)\n",
        "#   loss, acc = new_model.evaluate(train_ip, target_2d)\n",
        "#   # print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
        "\n",
        "#   output = new_model.predict(train_ip)\n",
        "#   z_op = np.real(output[:, :, :, 0])\n",
        "#   z_act = np.real(target_2d[:, :, :])\n",
        "#   points = []\n",
        "#   temp_2d = np.zeros([130,34], dtype=np.float)\n",
        "#   for i in range(2):\n",
        "#     temp_2d[1:129, 1:33] = z_act[i,:,:]\n",
        "#     for j in range(1,129):\n",
        "#       for k in range(1,33):\n",
        "#         if (temp_2d[j,k]>temp_2d[j-1,k-1]) and (temp_2d[j,k]>temp_2d[j-1,k])and (temp_2d[j,k]>temp_2d[j-1,k+1]) and (temp_2d[j,k]>temp_2d[j,k-1]) and (temp_2d[j,k]>temp_2d[j,k+1]) and (temp_2d[j,k]>temp_2d[j+1,k-1]) and (temp_2d[j,k]>temp_2d[j+1,k]) and (temp_2d[j,k]>temp_2d[j+1,k+1]):\n",
        "#           points.append([i,j-1,k-1])\n",
        "\n",
        "#   origin = [0,0,0]\n",
        "\n",
        "#   xyz = []\n",
        "#   xyz.append(origin)\n",
        "#   print(len(points))\n",
        "\n",
        "\n",
        "\n",
        "#   for xy in points:\n",
        "#     flag = 0\n",
        "#     for i in range(len(xyz)):\n",
        "#       # print('hi')\n",
        "#       if (z_act[xy[0],xy[1],xy[2]] > z_act[xyz[i][0],xyz[i][1],xyz[i][2]]) or (z_act[xy[0],xy[1],xy[2]] == z_act[xyz[i][0],xyz[i][1],xyz[i][2]]):\n",
        "#         xyz.insert(i,xy)\n",
        "#         flag = 1\n",
        "#         break\n",
        "#     if flag==0:\n",
        "#       xyz.append(xy)\n",
        "\n",
        "#   for i in range(2):\n",
        "#     for j in range(128):\n",
        "#       for k in range(32):\n",
        "#         # if (z_act[i,j,k]<0.1):\n",
        "#         if [i,j,k] not in xyz[:nSignals]:\n",
        "#           z_op[i,j,k] = 0\n",
        "#           z_act[i,j,k] = 0\n",
        "\n",
        "#   R_square = r2_score(list(z_act.reshape(8192,)),list(z_op.reshape(8192,))) \n",
        "#   # print('Coefficient of Determination', R_square) \n",
        "#   corr, _ = pearsonr(list(z_act.reshape(8192,)),list(z_op.reshape(8192,)))\n",
        "#   stat.append(corr)\n",
        "#   r_sq.append(R_square)\n",
        "\n",
        "# print(np.mean(stat))\n",
        "# print(np.mean(r_sq))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgaFsYXzYN1v"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_sCse08YN4X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7666b1d-fa65-43f3-eacf-be3f3db35ba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.getcwd()\n",
        "\n",
        "os.chdir('drive')\n",
        "\n",
        "os.chdir('MyDrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7cU33JDHvAe",
        "outputId": "a38626d0-fc15-4a56-9eeb-fb348edcc813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSI5EQISHy_Y",
        "outputId": "c50f8819-3672-4b7c-b1dd-97ffc7cf6b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'120100094 - 1.pdf'\n",
            " \u001b[0m\u001b[01;34m3Dexpts\u001b[0m/\n",
            "'Aadhar and Gas Connection Bill.pdf'\n",
            " Abhishek_Kumar_02.pdf\n",
            " Abhishek_Kumar_Blank_Template-18.pdf\n",
            "'Abhishek_Kumar_CDS (1).pdf'\n",
            "'Abhishek_Kumar_CDS (2).pdf'\n",
            " Abhishek_Kumar_CDS.pdf\n",
            "'Abhishek_Kumar_Resume (1).pdf'\n",
            " Abhishek_Kumar_resume.pdf\n",
            " Abhishek_Kumar_Resume.pdf\n",
            "'abhishek one page 1.pdf'\n",
            "'BPCL Resume_Part A_Engineers.DOCX'\n",
            "'BPCL Resume_Part A_Engineers.DOCX.gdoc'\n",
            "\u001b[01;34m'Colab Notebooks'\u001b[0m/\n",
            "\u001b[01;36m'Copy of hnco_3d'\u001b[0m@\n",
            " \u001b[01;34mDAV\u001b[0m/\n",
            " EDHRN_3D.h5\n",
            " Event.gsite\n",
            "\u001b[01;34m'Forms for use.GT(M)'\u001b[0m/\n",
            "'Forms for use.GT(M).rar'\n",
            " \u001b[01;34mhncacb_3d\u001b[0m/\n",
            " \u001b[01;34mhncaco_3d\u001b[0m/\n",
            " \u001b[01;36mhnco_3d\u001b[0m@\n",
            " \u001b[01;34mhnco_3d_1\u001b[0m/\n",
            " \u001b[01;34mhnco_3d_h\u001b[0m/\n",
            " \u001b[01;34mhncocacb_3d\u001b[0m/\n",
            "'IISc_Abhishek_Kumar_CDS (1).pdf'\n",
            "'IISc_Abhishek_Kumar_CDS (2).pdf'\n",
            "'IISc_Abhishek_Kumar_CDS (3).pdf'\n",
            "'IISc_Abhishek_Kumar_CDS (4).pdf'\n",
            " IISc_Abhishek_Kumar_CDS.pdf\n",
            " IISC_ID.pdf\n",
            " Introduction_to_RBMs.pdf\n",
            " lec1-handout.pdf\n",
            " lec25-handout.pdf\n",
            "\"Master's_Project_Abstarct.docx\"\n",
            " model_plot.png\n",
            "'New Doc 5_5.pdf'\n",
            "\u001b[01;34m'Night drive'\u001b[0m/\n",
            "\u001b[01;34m'pawna lake camping'\u001b[0m/\n",
            " Portfolio.gsite\n",
            "'proposal(17830_&_18208).pdf'\n",
            " proposal.pdf\n",
            " rec_spec.mat\n",
            "'Relieving Formalities   RESIGNATION - MR.ABHISHEK KUMAR (22146) MANAGEMENT TRAINEE MYSURU DEPOT. .msg'\n",
            " \u001b[01;34mresume\u001b[0m/\n",
            " \u001b[01;34msaved_model\u001b[0m/\n",
            " \u001b[01;34msaved_model_01\u001b[0m/\n",
            " \u001b[01;34msaved_model_1\u001b[0m/\n",
            " \u001b[01;34msaved_model_10\u001b[0m/\n",
            " \u001b[01;34msaved_model_10_1\u001b[0m/\n",
            " \u001b[01;34msaved_model_12\u001b[0m/\n",
            " \u001b[01;34msaved_model_ud_12\u001b[0m/\n",
            " \u001b[01;34msaved_model_ud_12_f\u001b[0m/\n",
            " \u001b[01;34msaved_model_ud_12_ff\u001b[0m/\n",
            " \u001b[01;34msaved_model_ud_12_final\u001b[0m/\n",
            " \u001b[01;34msaved_model_ud_25\u001b[0m/\n",
            " \u001b[01;34msaved_model_ud_25_1\u001b[0m/\n",
            " \u001b[01;34msaved_model_ud_25_f\u001b[0m/\n",
            " \u001b[01;34msaved_model_unet_25\u001b[0m/\n",
            " \u001b[01;34msaved_model_unet_25_1\u001b[0m/\n",
            " Scan_20190927_151104_001.jpg\n",
            " Scheduler_10.xlsx\n",
            " Scheduler_125.xlsx\n",
            " Scheduler_128x64.xlsx\n",
            " Scheduler_12.xlsx\n",
            " Scheduler_1.xlsx\n",
            " Scheduler.xlsx\n",
            "\u001b[01;34m'sk Mondal '\u001b[0m/\n",
            "'[Solutions Manual] Mechanics Of Materials - (3Rd Ed , By Beer, Johnston, & Dewolf).pdf'\n",
            "'Student Portfolio.gsite'\n",
            "'System for monitoring moving threads in textile machinery.gdoc'\n",
            " undersampled_Azurin.mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nmrglue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-v8TN4RH6S9",
        "outputId": "977e0858-df91-45a4-c641-465ad92c6e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nmrglue\n",
            "  Downloading nmrglue-0.9-py2.py3-none-any.whl (224 kB)\n",
            "\u001b[K     |████████████████████████████████| 224 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nmrglue) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from nmrglue) (1.4.1)\n",
            "Installing collected packages: nmrglue\n",
            "Successfully installed nmrglue-0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nmrglue as ng"
      ],
      "metadata": {
        "id": "TZ-Pyfq3eER9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic,data = ng.pipe.read('3Dexpts/cbcaconh_3d/data/test001.fid')"
      ],
      "metadata": {
        "id": "AgaSJhLcdjS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l-BjgMyd0VJ",
        "outputId": "1d7a7177-1b84-4958-ed9c-b6a9b305a307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 576)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYMFtwovd2cc",
        "outputId": "820dc6b2-4772-45ce-edd7-cad580316845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-352.1494   +2.93676758e+02j, -321.8401   +2.69882324e+02j,\n",
              "        -361.55737  +2.69970215e+02j, ...,   24.491806 +3.43650513e+01j,\n",
              "          44.360947 +2.71956787e+01j,   30.524933 +2.62573242e-01j],\n",
              "       [ -27.890625 -3.14898438e+02j, -228.29663  -1.62468262e+02j,\n",
              "        -170.99658  -1.88528809e+02j, ...,  -16.298843 +2.43219910e+01j,\n",
              "         -15.602783 +3.24124146e+01j,   -8.102188 +1.58103485e+01j],\n",
              "       [ 462.0913   +8.71982422e+01j,  464.3086   +7.57875977e+01j,\n",
              "         417.05542  +4.30283203e+01j, ...,   26.325378 +3.71196899e+01j,\n",
              "          45.15703  +4.42872314e+01j,   24.593811 +1.85956650e+01j],\n",
              "       ...,\n",
              "       [-231.02454  -5.79165039e+01j,   -1.5752563-1.06997070e+02j,\n",
              "         -27.947144 -6.37036133e+01j, ...,   -3.7349625-1.02151276e+02j,\n",
              "          -1.7664738-1.13435165e+02j,   -1.6202431-5.62449570e+01j],\n",
              "       [ 221.42737  +3.98259277e+02j,  295.26343  +3.99253906e+02j,\n",
              "         251.67175  +2.74902344e+02j, ...,    4.104141 -6.92031403e+01j,\n",
              "           4.6049995-9.63046112e+01j,    1.0903463-4.91942139e+01j],\n",
              "       [ 524.6975   -7.41967773e+02j,  539.8613   -6.70136719e+02j,\n",
              "         563.0711   -5.14394043e+02j, ...,  -32.813457 -9.04613190e+01j,\n",
              "         -34.931633 -1.00538315e+02j,  -20.508734 -5.01171112e+01j]],\n",
              "      dtype=complex64)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "files = []\n",
        "\n",
        "entries = Path('3Dexpts/cbcaconh_3d/data/')\n",
        "for entry in entries.iterdir():\n",
        "    # print(entry.name)\n",
        "    files.append(entry.name)"
      ],
      "metadata": {
        "id": "3TlhDC0KIuGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.sort()\n",
        "# files"
      ],
      "metadata": {
        "id": "zOGPwCkCegmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files[:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elqn1TeEfv5r",
        "outputId": "91fca303-846d-45a7-a4b0-04c128eebf3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test001.fid',\n",
              " 'test002.fid',\n",
              " 'test003.fid',\n",
              " 'test004.fid',\n",
              " 'test005.fid',\n",
              " 'test006.fid',\n",
              " 'test007.fid',\n",
              " 'test008.fid',\n",
              " 'test009.fid',\n",
              " 'test010.fid',\n",
              " 'test011.fid',\n",
              " 'test012.fid',\n",
              " 'test013.fid',\n",
              " 'test014.fid',\n",
              " 'test015.fid',\n",
              " 'test016.fid',\n",
              " 'test017.fid',\n",
              " 'test018.fid',\n",
              " 'test019.fid',\n",
              " 'test020.fid',\n",
              " 'test021.fid',\n",
              " 'test022.fid',\n",
              " 'test023.fid',\n",
              " 'test024.fid',\n",
              " 'test025.fid',\n",
              " 'test026.fid',\n",
              " 'test027.fid',\n",
              " 'test028.fid',\n",
              " 'test029.fid',\n",
              " 'test030.fid',\n",
              " 'test031.fid',\n",
              " 'test032.fid',\n",
              " 'test033.fid',\n",
              " 'test034.fid',\n",
              " 'test035.fid',\n",
              " 'test036.fid',\n",
              " 'test037.fid',\n",
              " 'test038.fid',\n",
              " 'test039.fid',\n",
              " 'test040.fid',\n",
              " 'test041.fid',\n",
              " 'test042.fid',\n",
              " 'test043.fid',\n",
              " 'test044.fid',\n",
              " 'test045.fid',\n",
              " 'test046.fid',\n",
              " 'test047.fid',\n",
              " 'test048.fid',\n",
              " 'test049.fid',\n",
              " 'test050.fid',\n",
              " 'test051.fid',\n",
              " 'test052.fid',\n",
              " 'test053.fid',\n",
              " 'test054.fid',\n",
              " 'test055.fid',\n",
              " 'test056.fid',\n",
              " 'test057.fid',\n",
              " 'test058.fid',\n",
              " 'test059.fid',\n",
              " 'test060.fid',\n",
              " 'test061.fid',\n",
              " 'test062.fid',\n",
              " 'test063.fid',\n",
              " 'test064.fid',\n",
              " 'test065.fid',\n",
              " 'test066.fid',\n",
              " 'test067.fid',\n",
              " 'test068.fid',\n",
              " 'test069.fid',\n",
              " 'test070.fid',\n",
              " 'test071.fid',\n",
              " 'test072.fid',\n",
              " 'test073.fid',\n",
              " 'test074.fid',\n",
              " 'test075.fid',\n",
              " 'test076.fid',\n",
              " 'test077.fid',\n",
              " 'test078.fid',\n",
              " 'test079.fid',\n",
              " 'test080.fid',\n",
              " 'xz001.fid']"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_kVsDEuYN6G"
      },
      "outputs": [],
      "source": [
        "fid_signal = np.zeros([80,576,120], dtype=complex)\n",
        "i=0\n",
        "for x in files[:-1]:\n",
        "  folder = \"3Dexpts/cbcaconh_3d/data/\"\n",
        "  x = folder + x\n",
        "  dic,data = ng.pipe.read(x)\n",
        "  fid_signal[i,:,:] = data.T\n",
        "  i=i+1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fid_signal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPDCMbILxDun",
        "outputId": "89face7d-069e-4148-b6ec-797f2d378b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 5.66016968e+02+1.70914221e+03j,\n",
              "          3.15825195e+01+8.56325684e+01j,\n",
              "         -3.68120850e+02+6.64927490e+02j, ...,\n",
              "         -8.04431152e+01+4.32006226e+01j,\n",
              "         -1.96698975e+02+6.29370422e+02j,\n",
              "         -1.38520508e+02-1.22472809e+02j],\n",
              "        [-9.85215820e+02+1.00564587e+03j,\n",
              "         -3.66333008e+01-4.72960205e+01j,\n",
              "         -9.10367554e+02+2.83710205e+02j, ...,\n",
              "         -9.57595215e+01-1.53866119e+02j,\n",
              "         -2.92991699e+02+6.28649963e+02j,\n",
              "         -2.81420898e+00-9.29815979e+01j],\n",
              "        [-7.84684326e+02-1.03887073e+03j,\n",
              "         -1.79924316e+01+6.01107178e+01j,\n",
              "         -8.36996216e+02-1.95852295e+02j, ...,\n",
              "         -3.82495117e+01-9.38364258e+01j,\n",
              "         -2.80633057e+02+4.89670563e+02j,\n",
              "          3.22412109e+01+6.70348511e+01j],\n",
              "        ...,\n",
              "        [-2.04473572e+01+2.98270264e+01j,\n",
              "          3.53002014e+01-2.30703735e+01j,\n",
              "         -1.45463257e+01+5.96391907e+01j, ...,\n",
              "          1.26327515e-01-1.06120033e+01j,\n",
              "          3.47506714e+00-3.45288277e+01j,\n",
              "         -4.87516403e+00+3.43904305e+00j],\n",
              "        [-4.84619141e-02+3.81983643e+01j,\n",
              "          3.79940186e+01-3.04320679e+01j,\n",
              "         -4.03594971e+00+6.50296326e+01j, ...,\n",
              "         -7.29613495e+00-8.06211472e+00j,\n",
              "          1.13015366e+01-4.31550751e+01j,\n",
              "         -2.74481926e+01+4.98739815e+00j],\n",
              "        [-1.76391602e+00+2.52427673e+01j,\n",
              "          2.11873474e+01-1.47608795e+01j,\n",
              "          3.11340332e-01+2.69634247e+01j, ...,\n",
              "         -6.62978840e+00-7.59696054e+00j,\n",
              "          4.91889572e+00-2.16254578e+01j,\n",
              "         -1.22641125e+01-4.76416874e+00j]],\n",
              "\n",
              "       [[-9.96947021e+01+6.39940796e+02j,\n",
              "         -9.48483887e+01+5.20893555e+01j,\n",
              "          3.07358154e+02-5.53581543e+01j, ...,\n",
              "         -9.04796753e+01+2.05139160e+01j,\n",
              "          4.69471375e+02+2.65393799e+02j,\n",
              "          1.34143219e+02-4.02050781e+00j],\n",
              "        [ 7.64783936e+01+4.88664551e+02j,\n",
              "         -2.33566528e+02+7.07631836e+01j,\n",
              "          2.73833252e+02-1.44823608e+02j, ...,\n",
              "          4.21697083e+01+1.97092285e+01j,\n",
              "          3.06108215e+02+2.77984863e+02j,\n",
              "          2.04614532e+02+1.02172852e+00j],\n",
              "        [ 1.46423340e+00+5.06364014e+02j,\n",
              "         -1.98265259e+02+3.94323730e+01j,\n",
              "          2.64647705e+02-1.00402466e+02j, ...,\n",
              "          1.03459473e+01+2.16362305e+01j,\n",
              "          3.34454315e+02+2.90095459e+02j,\n",
              "          1.86645447e+02+2.60166016e+01j],\n",
              "        ...,\n",
              "        [ 2.20961914e+01-1.32779846e+01j,\n",
              "         -4.55698853e+01+2.43480530e+01j,\n",
              "         -6.91664734e+01+2.45251465e+00j, ...,\n",
              "         -1.80756798e+01+7.53630066e+00j,\n",
              "         -3.31185532e+00+1.89625854e+01j,\n",
              "         -9.34094429e+00-2.23269157e+01j],\n",
              "        [ 1.88850098e+01-3.42075806e+01j,\n",
              "         -4.99751587e+01+3.34682007e+01j,\n",
              "         -6.33446350e+01-3.79284668e+00j, ...,\n",
              "         -1.99939919e+01+1.25336380e+01j,\n",
              "          5.06819344e+00+1.35730515e+01j,\n",
              "         -9.29780960e-01-1.28046074e+01j],\n",
              "        [ 1.82556458e+01-2.26743164e+01j,\n",
              "         -1.98239288e+01+1.77466736e+01j,\n",
              "         -3.15197906e+01+6.06384277e-02j, ...,\n",
              "         -1.37245274e+01+9.30154705e+00j,\n",
              "          6.30141449e+00+3.35140610e+00j,\n",
              "         -3.55684566e+00-7.68923759e+00j]],\n",
              "\n",
              "       [[-1.38415564e+03+2.48793457e+02j,\n",
              "         -4.14453613e+02-5.43964844e+01j,\n",
              "          4.32518677e+02-2.16494141e+02j, ...,\n",
              "         -9.42824707e+01-9.64732971e+01j,\n",
              "         -6.42585449e+01-1.05223267e+03j,\n",
              "         -1.71586426e+02-2.10399170e+02j],\n",
              "        [-1.51201453e+03+3.66242676e+01j,\n",
              "         -2.33088135e+02-4.05869141e+01j,\n",
              "          5.25874390e+02-1.07143555e+02j, ...,\n",
              "         -1.14638184e+02-3.47489441e+02j,\n",
              "         -1.63745117e+00-9.28501282e+02j,\n",
              "         -1.90834473e+02-3.10851288e+02j],\n",
              "        [-1.47412292e+03-3.04023926e+02j,\n",
              "         -2.57390869e+02-4.03381348e+01j,\n",
              "          4.78786499e+02-1.99683594e+02j, ...,\n",
              "         -8.45085449e+01-2.96712311e+02j,\n",
              "          2.98337402e+01-8.88401489e+02j,\n",
              "         -1.73766602e+02-3.32394409e+02j],\n",
              "        ...,\n",
              "        [ 6.45175171e+01+1.24401978e+02j,\n",
              "         -1.93551636e+00+5.25900574e+01j,\n",
              "         -3.28926392e+01+1.72877197e+01j, ...,\n",
              "         -1.44411011e+01+1.71793404e+01j,\n",
              "         -1.17070293e+01+2.13322315e+01j,\n",
              "         -3.32192459e+01+1.53647423e+01j],\n",
              "        [ 4.68192749e+01+1.27241913e+02j,\n",
              "         -1.88552856e+01+4.98881836e+01j,\n",
              "         -4.09884949e+01+1.95554810e+01j, ...,\n",
              "         -1.10957451e+01+1.95911255e+01j,\n",
              "         -3.34775085e+01+2.10023403e+01j,\n",
              "         -3.60003700e+01+1.56851349e+01j],\n",
              "        [ 2.11025696e+01+6.34604950e+01j,\n",
              "         -1.05852509e+01+2.44987183e+01j,\n",
              "         -1.63158417e+01+2.79173279e+00j, ...,\n",
              "         -2.37241554e+00+7.25427628e+00j,\n",
              "         -2.01665154e+01+1.48815069e+01j,\n",
              "         -1.49487762e+01+9.22541714e+00j]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 2.08210938e+02-1.00800964e+03j,\n",
              "          7.67133789e+01-4.13341064e+01j,\n",
              "          1.52010498e+02+1.95248535e+02j, ...,\n",
              "         -4.08965973e+02-3.89501953e+00j,\n",
              "         -2.08117432e+02+1.39106934e+02j,\n",
              "         -5.72260132e+01+8.39790039e+01j],\n",
              "        [ 2.64056641e+02-1.16985181e+03j,\n",
              "          1.10736816e+02-1.25706055e+02j,\n",
              "          2.12497314e+02+1.32192383e+02j, ...,\n",
              "         -3.75613922e+02-3.99531250e+01j,\n",
              "         -4.39948792e+02+1.34914062e+02j,\n",
              "          1.11947601e+02+6.09238281e+01j],\n",
              "        [ 3.13214600e+02-1.20532312e+03j,\n",
              "          1.00917969e+02-1.06776855e+02j,\n",
              "          2.17867432e+02+1.63141357e+02j, ...,\n",
              "         -3.87983246e+02-8.49208984e+01j,\n",
              "         -3.98233826e+02-6.19189453e+00j,\n",
              "          4.98515472e+01+1.33474121e+02j],\n",
              "        ...,\n",
              "        [-7.70649719e+01+5.42438965e+01j,\n",
              "         -2.30308533e+01+3.49717255e+01j,\n",
              "         -1.93668213e+01-4.34139252e+00j, ...,\n",
              "          5.35254478e-01+7.36113663e+01j,\n",
              "         -9.43657112e+00+1.62094936e+01j,\n",
              "         -1.03710651e+00-1.00383766e+02j],\n",
              "        [-1.10523041e+02+7.50171204e+01j,\n",
              "         -2.65667419e+01+4.33096237e+01j,\n",
              "         -3.25229492e+01+5.52540588e+00j, ...,\n",
              "          3.50389957e+00+8.60506821e+01j,\n",
              "         -1.73158913e+01+8.09894562e-01j,\n",
              "          5.55814743e-01-1.13576309e+02j],\n",
              "        [-5.98259506e+01+3.96673813e+01j,\n",
              "         -1.43988037e+01+2.47893944e+01j,\n",
              "         -2.20082397e+01-5.33027649e+00j, ...,\n",
              "          1.47952795e+00+4.17006989e+01j,\n",
              "         -1.14073029e+01-2.53585815e-01j,\n",
              "         -1.66141033e-01-5.31888428e+01j]],\n",
              "\n",
              "       [[-9.74964844e+02-1.14375000e+02j,\n",
              "          1.92452148e+02-2.76970703e+02j,\n",
              "          4.15825195e+02+6.03585449e+02j, ...,\n",
              "         -3.09665527e+02-3.90988892e+02j,\n",
              "         -5.27916504e+02-5.78036255e+02j,\n",
              "         -1.57740234e+02+3.13063965e+01j],\n",
              "        [-1.01342725e+03-1.39810791e+02j,\n",
              "          2.70591309e+02-1.23456299e+02j,\n",
              "          2.31177246e+02+4.41330078e+02j, ...,\n",
              "         -1.95393555e+02-1.36604614e+01j,\n",
              "         -4.40275391e+02-8.13386108e+02j,\n",
              "         -1.71351562e+02-5.00545654e+01j],\n",
              "        [-1.02325146e+03-3.41246826e+02j,\n",
              "          2.59896973e+02-1.58636230e+02j,\n",
              "          2.50158203e+02+4.55107666e+02j, ...,\n",
              "         -2.11619629e+02-2.94979248e+01j,\n",
              "         -4.24959961e+02-7.05612061e+02j,\n",
              "         -1.57796387e+02-2.57001343e+01j],\n",
              "        ...,\n",
              "        [ 1.61511230e+00+1.28162384e+01j,\n",
              "          8.16810608e+01+6.71309967e+01j,\n",
              "         -1.62961853e+02-9.95000000e+01j, ...,\n",
              "          4.74755859e+00-1.69445877e+01j,\n",
              "         -2.96915436e+01+4.80033417e+01j,\n",
              "         -1.31764679e+01-2.76338615e+01j],\n",
              "        [ 1.79063110e+01+1.76139069e+01j,\n",
              "          9.26634521e+01+8.25534058e+01j,\n",
              "         -1.86391296e+02-1.13438217e+02j, ...,\n",
              "          1.10511017e+01-2.55998783e+01j,\n",
              "         -2.31581573e+01+6.84017792e+01j,\n",
              "         -1.21828461e+01-3.32430649e+01j],\n",
              "        [ 1.20264893e+01+8.91925049e+00j,\n",
              "          4.20936127e+01+3.57936249e+01j,\n",
              "         -9.38397598e+01-5.01609497e+01j, ...,\n",
              "          9.23345184e+00-1.34014931e+01j,\n",
              "         -1.10887451e+01+2.55041809e+01j,\n",
              "         -7.07077026e-01-1.52701626e+01j]],\n",
              "\n",
              "       [[-3.52149414e+02+2.93676758e+02j,\n",
              "         -2.78906250e+01-3.14898438e+02j,\n",
              "          4.62091309e+02+8.71982422e+01j, ...,\n",
              "         -2.31024536e+02-5.79165039e+01j,\n",
              "          2.21427368e+02+3.98259277e+02j,\n",
              "          5.24697510e+02-7.41967773e+02j],\n",
              "        [-3.21840088e+02+2.69882324e+02j,\n",
              "         -2.28296631e+02-1.62468262e+02j,\n",
              "          4.64308594e+02+7.57875977e+01j, ...,\n",
              "         -1.57525635e+00-1.06997070e+02j,\n",
              "          2.95263428e+02+3.99253906e+02j,\n",
              "          5.39861328e+02-6.70136719e+02j],\n",
              "        [-3.61557373e+02+2.69970215e+02j,\n",
              "         -1.70996582e+02-1.88528809e+02j,\n",
              "          4.17055420e+02+4.30283203e+01j, ...,\n",
              "         -2.79471436e+01-6.37036133e+01j,\n",
              "          2.51671753e+02+2.74902344e+02j,\n",
              "          5.63071106e+02-5.14394043e+02j],\n",
              "        ...,\n",
              "        [ 2.44918060e+01+3.43650513e+01j,\n",
              "         -1.62988434e+01+2.43219910e+01j,\n",
              "          2.63253784e+01+3.71196899e+01j, ...,\n",
              "         -3.73496246e+00-1.02151276e+02j,\n",
              "          4.10414124e+00-6.92031403e+01j,\n",
              "         -3.28134575e+01-9.04613190e+01j],\n",
              "        [ 4.43609467e+01+2.71956787e+01j,\n",
              "         -1.56027832e+01+3.24124146e+01j,\n",
              "          4.51570282e+01+4.42872314e+01j, ...,\n",
              "         -1.76647377e+00-1.13435165e+02j,\n",
              "          4.60499954e+00-9.63046112e+01j,\n",
              "         -3.49316330e+01-1.00538315e+02j],\n",
              "        [ 3.05249329e+01+2.62573242e-01j,\n",
              "         -8.10218811e+00+1.58103485e+01j,\n",
              "          2.45938110e+01+1.85956650e+01j, ...,\n",
              "         -1.62024307e+00-5.62449570e+01j,\n",
              "          1.09034634e+00-4.91942139e+01j,\n",
              "         -2.05087337e+01-5.01171112e+01j]]])"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fid_signal.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43V-sfuRg-P_",
        "outputId": "ff2884d7-fadd-4992-a347-7fcd6d909292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 576, 120)"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyXfpGwSYN9R"
      },
      "outputs": [],
      "source": [
        "fid_1 = fid_signal[:,:120,:32]\n",
        "\n",
        "fid_1 = np.fft.fft(fid_1,axis=0)\n",
        "fid_1 = np.fft.fft(fid_1,axis=1)\n",
        "fid_1 = np.fft.fft(fid_1,axis=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fid_2 = np.real(fid_1)\n",
        "print(fid_2.shape)\n",
        "fid_2 = fid_2/np.max(np.abs(fid_2))\n",
        "\n",
        "# train1[i*NP:(i+1)*NP,:,:] = np.real(fid_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIukcycw0cNx",
        "outputId": "59a41d83-7cba-4c73-c591-a925823b66b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80, 120, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvYv7la4Yb0X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe845339-05c3-4fd9-d74d-31cb360fe880"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 120, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "tar_1 = np.multiply(fid_signal[:,:120,:32],mul_arr)\n",
        "tar_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tar_1 = np.fft.fft(tar_1,axis=0)\n",
        "tar_1 = np.fft.fft(tar_1,axis=1)\n",
        "tar_1 = np.fft.fft(tar_1,axis=2)"
      ],
      "metadata": {
        "id": "WufEntTpQxmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tar_2 = np.real(tar_1)\n",
        "print(tar_2.shape)\n",
        "tar_2 = tar_2/np.max(np.abs(tar_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTfdXCjT04gw",
        "outputId": "235ef8ea-46f6-4edc-d84c-71707b3c4792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80, 120, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aqsiyO1l04jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GpBU0_2a04mT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TzX5M6GU04ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XJ5ASt6X04rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QOTPUjG304tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GsrxfZSA04vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HRlPBKQi04xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZNlbf3ym04zt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "real_3D_CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPstGtlaZ5txOQNzAKj0ar+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}