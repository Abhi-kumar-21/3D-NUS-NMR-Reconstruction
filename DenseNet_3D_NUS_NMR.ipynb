{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhi-kumar-21/3D-NUS-NMR-Reconstruction/blob/main/DenseNet_3D_NUS_NMR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_CjXFnejdnc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YutEYcTpkTif"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "from time import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from sklearn import preprocessing\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Conv3D, MaxPooling3D\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "#Parallelization library\n",
        "from multiprocessing import Pool, Manager, Process\n",
        "import threading\n",
        "\n",
        "from warnings import filterwarnings\n",
        "filterwarnings(action='ignore', category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "316GjOQvkY1o",
        "outputId": "b8a974fe-daa0-4036-e121-6f7d89a3d320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = pd.read_excel('/content/drive/My Drive/Scheduler.xlsx')\n",
        "\n",
        "arr = df.to_numpy().astype('int')\n",
        "\n",
        "mul_arr = np.zeros((128,32),'float')\n",
        "for d in arr:\n",
        "  mul_arr[d[0],d[1]] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hDeedybekY-q"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YxRia8pIkZBz"
      },
      "outputs": [],
      "source": [
        "def make_fid(freqs, freqs1, freqs2, r2s, ints, noise=False):\n",
        "    \n",
        "  retval=np.zeros( (NP, NP1, NP2) , dtype=np.complex)\n",
        "  \n",
        "  # Time samples\n",
        "  samp_time = np.linspace(0.,(NP-1.)/SW,NP)\n",
        "  samp_time1 = np.linspace(0.,(NP1-1.)/SW1,NP1)\n",
        "  samp_time2 = np.linspace(0.,(NP2-1.)/SW2,NP2)\n",
        "  \n",
        "  K = np.max([len(freqs), len(freqs2), len(freqs2), len(r2s), len(ints)])\n",
        "  for n in range(NP):\n",
        "    for n1 in range(NP1):\n",
        "      for n2 in range(NP2):\n",
        "        val = 0.\n",
        "        for s in range(K):\n",
        "          val+= (np.exp((1j*2*np.pi*freqs[s] - r2s[s])*samp_time[n])*\n",
        "                  np.exp((1j*2*np.pi*freqs1[s] - r2s[s])*samp_time1[n1])*\n",
        "                  np.exp((1j*2*np.pi*freqs2[s] - r2s[s])*samp_time2[n2])*\n",
        "                  ints[s])\n",
        "        retval[n,n1,n2]=val\n",
        "\n",
        "  return retval\n",
        "\n",
        "\n",
        "def make_sine_combinations():\n",
        "\n",
        "  # Number of Signals\n",
        "  nSignals = random.randint(50,NSignals+1)  \n",
        "  # print(nSignals)\n",
        "\n",
        "  # Frequencies\n",
        "  freqs = np.random.random(nSignals)*SW\n",
        "  freqs1 = np.random.random(nSignals)*SW1\n",
        "  freqs2 = np.random.random(nSignals)*SW2\n",
        "\n",
        "  # Transverse relaxation rate\n",
        "  r2s = np.random.random(nSignals)*(5) + (1/100)\n",
        "\n",
        "  #Intensity = amplitude\n",
        "  ints = np.random.random(nSignals)*5 + 1\n",
        "\n",
        "  # FID creation\n",
        "  ff = make_fid(freqs,freqs1,freqs2,r2s,ints,NoiseLevel)\n",
        "\n",
        "  temp_realPart = np.real(ff)\n",
        "  temp = np.abs(temp_realPart[0,0,0])\n",
        "  ff = ff/temp\n",
        "\n",
        "  return ff\n",
        "\n",
        "\n",
        "def make_2d_mat(b_size):\n",
        "    \n",
        "  # Training matrix\n",
        "  target = np.zeros([b_size*NP, NP1*NP2], dtype=np.float)       # For Target\n",
        "  train = np.zeros([b_size*NP, NP1, NP2], dtype=np.float)      # For CNN\n",
        "  train1 = np.zeros([b_size*NP, NP1, NP2], dtype=np.float)     # For test_fft\n",
        "  train_1 = np.zeros([b_size*NP, NP1*NP2], dtype=np.float)      # For DNN\n",
        "\n",
        "  # Matix concatenation (training)\n",
        "  for i in range(b_size):\n",
        "    ff = make_sine_combinations()\n",
        "    train_ff = ff\n",
        "\n",
        "    ff = np.fft.fft(ff,axis=0)\n",
        "    ff = np.fft.fft(ff,axis=1)\n",
        "    ff = np.fft.fft(ff,axis=2)\n",
        "\n",
        "    ff = ff/np.max(np.abs(ff))\n",
        "\n",
        "    train1[i*NP:(i+1)*NP,:,:] = np.real(ff)\n",
        "\n",
        "    for j in range(NP):\n",
        "      train_ff[j,:,:] = np.multiply(train_ff[j,:,:],mul_arr)\n",
        "      index = (i*NP)+j\n",
        "      target[index,:] = np.real(ff[j]).reshape(NP1*NP2)\n",
        "    \n",
        "    train_ff = np.fft.fft(train_ff,axis=0)\n",
        "    train_ff = np.fft.fft(train_ff,axis=1)\n",
        "    train_ff = np.fft.fft(train_ff,axis=2)\n",
        "\n",
        "    train_ff = train_ff/np.max(np.abs(train_ff))\n",
        "\n",
        "    train[i*NP:(i+1)*NP,:,:] = np.real(train_ff)\n",
        "    \n",
        "    for j in range(NP):\n",
        "      index = (i*NP)+j\n",
        "      train_1[index,:] = np.real(train_ff[j]).reshape(NP1*NP2)\n",
        "\n",
        "  return train, train1, target\n",
        "\n",
        "N = 5000\n",
        "NP = 2        # Direct dimension\n",
        "NP1 = 128     # Indirect Dimension 1\n",
        "NP2 = 64      # Indirect Dimension 1\n",
        "SW = 1000\n",
        "SW1 = 10000\n",
        "SW2 = 4000\n",
        "NoiseLevel = 0\n",
        "NSignals = 25\n",
        "dataIn = []\n",
        "dataOut = []\n",
        "epochs = 12\n",
        "batch_size = 32\n",
        "val_split = 0.05\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bISDK5mQkIiV"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Conv2D, Conv3D, DepthwiseConv2D, SeparableConv2D, Conv3DTranspose\n",
        "from keras.layers import Flatten, MaxPool2D, AvgPool2D, GlobalAvgPool2D, UpSampling2D, BatchNormalization\n",
        "from keras.layers import Concatenate, Add, Dropout, ReLU, Lambda, Activation, LeakyReLU, PReLU \n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "from time import time\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0sCPZ15McfE-"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Densenet Network Architecture\n",
        "\n",
        "def densenet(img_shape, n_classes, f=32):\n",
        "  repetitions = 6, 12, 24, 16\n",
        "  \n",
        "  def bn_rl_conv(x, f, k=1, s=1, p='same'):\n",
        "    x = BatchNormalization()(x)\n",
        "    x = tf.keras.activations.tanh(x)\n",
        "    # x = ReLU()(x)\n",
        "    x = Conv2D(f, k, strides=s, padding=p)(x)\n",
        "    return x\n",
        "  \n",
        "  \n",
        "  def dense_block(tensor, r):\n",
        "    for _ in range(r):\n",
        "      x = bn_rl_conv(tensor, 4*f)\n",
        "      x = bn_rl_conv(x, f, 3)\n",
        "      tensor = Concatenate()([tensor, x])\n",
        "    return tensor\n",
        "  \n",
        "  \n",
        "  def transition_block(x):\n",
        "    x = bn_rl_conv(x, K.int_shape(x)[-1] // 2)\n",
        "    x = AvgPool2D(2, strides=1, padding='same')(x)\n",
        "    return x\n",
        "  \n",
        "  \n",
        "  input = Input(img_shape)\n",
        "  \n",
        "  x = Conv2D(64, 3, strides=1, padding='same')(input)\n",
        "  x = MaxPool2D(3, strides=1, padding='same')(x)\n",
        "  \n",
        "  for r in repetitions:\n",
        "    d = dense_block(x, r)\n",
        "    x = transition_block(d)\n",
        "\n",
        "  \n",
        "  output = Conv2D(1, 1, activation='tanh')(d)\n",
        "  \n",
        "  model = Model(input, output)\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "input_shape = 128, 64, 1\n",
        "n_classes = 4096\n",
        "\n",
        "K.clear_session()\n",
        "model = densenet(input_shape, n_classes)\n",
        "# model.summary()\n",
        "\n",
        "# Compile the model\n",
        "def get_lr_metric(optimizer):\n",
        "    def lr(y_true, y_pred):\n",
        "        return optimizer.lr\n",
        "    return lr\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
        "lr_metric = get_lr_metric(optimizer)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"loss\",\n",
        "                              factor=0.8,\n",
        "                              patience=9,\n",
        "                              min_lr=0.0001\n",
        ")\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QasXvcPkZEv"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FbcFdyH0l14q"
      },
      "outputs": [],
      "source": [
        "def dothing(x1_train, fids, fids_flat, i):\n",
        "    x1, fids_1, fids_2 = make_2d_mat(16)\n",
        "    print(\"yolo\")\n",
        "    # print(x1[0,:,:,:], fids_2[0,:])\n",
        "    # print(x1.shape, fids_1.shape)\n",
        "    fids.append(fids_1)\n",
        "    x1_train.append(x1)\n",
        "    fids_flat.append(fids_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0O3e8E5l174"
      },
      "outputs": [],
      "source": [
        "num_threads = 16\n",
        "\n",
        "for n_datasets in range(100):\n",
        "    # print(n_datasets)\n",
        "    with Manager() as manager:\n",
        "        # L = manager.list()  # <-- can be shared between processes.\n",
        "        x1_train = manager.list()\n",
        "        fids = manager.list()\n",
        "        fids_flat = manager.list()\n",
        "        processes = []\n",
        "        for i in range(num_threads):\n",
        "            # p = Process(target=dothing, args=(x1_train, fids, fids_flat, i))  # Passing the list\n",
        "            p = threading.Thread(target=dothing, args=(x1_train, fids, fids_flat, i))\n",
        "            # print(p)\n",
        "            # processes.append(p)\n",
        "            p.start()\n",
        "            processes.append(p)\n",
        "        for p in processes:\n",
        "            p.join()\n",
        "        x1_train = np.vstack(x1_train)\n",
        "        fids = np.vstack(fids)\n",
        "        fids_flat = np.vstack(fids_flat)\n",
        "      \n",
        "    print(f\"This is the iteration number{n_datasets}\")\n",
        "    print(x1_train.shape, fids.shape)\n",
        "    print(x1_train[0,:,:], fids[0,:,:])\n",
        "\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x1_train, fids, test_size=0.2)\n",
        "\n",
        "    history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), batch_size=10)\n",
        "\n",
        "    loss = np.log10(history.history[\"loss\"])\n",
        "    val_loss = np.log10(history.history['val_loss'])\n",
        "    epochs = range(1, len(loss) + 1)\n",
        "    plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    print(loss)\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    plt.plot(epochs, acc, 'y', label='Training acc')\n",
        "    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    del x1_train, fids, fids_flat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGbMufwgl1-1",
        "outputId": "125a8904-2e1c-4f27-bd48-2755649d43bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1uKF1itnl4wj"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# from google.colab import drive\n",
        "\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# os.getcwd()\n",
        "\n",
        "# os.chdir('drive')\n",
        "\n",
        "# os.chdir('MyDrive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jaLFDyDFl7OY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUFOKWL-EZu9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDpGo0nsDXwH"
      },
      "outputs": [],
      "source": [
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return NMSE(y_true, y_pred)\n",
        "\n",
        "def NMSE(y_true, y_pred):\n",
        "    a = K.sqrt(K.sum(K.square(y_true - y_pred)))\n",
        "    b = K.sqrt(K.sum(K.square(y_true)))\n",
        "    return a / b\n",
        "model = tf.keras.models.load_model(os.path.join( \"EDHRN_3D.h5\"), custom_objects={'bce_dice_loss':bce_dice_loss, 'NMSE':NMSE})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JDLbPZDl9fm"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOMBoC7OmqYl"
      },
      "outputs": [],
      "source": [
        "new_model = tf.keras.models.load_model('saved_model_1/my_model_1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPoMtsiHm05W"
      },
      "outputs": [],
      "source": [
        "new_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRbIiDcsBdXg"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yC2B-mgBTqv"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4ILjnmBnAYz"
      },
      "outputs": [],
      "source": [
        "def make_fid(freqs, freqs1, freqs2, r2s, ints, noise=False):\n",
        "    \n",
        "  retval=np.zeros( (NP, NP1, NP2) , dtype=np.complex)\n",
        "  \n",
        "  # Time samples\n",
        "  samp_time = np.linspace(0.,(NP-1.)/SW,NP)\n",
        "  samp_time1 = np.linspace(0.,(NP1-1.)/SW1,NP1)\n",
        "  samp_time2 = np.linspace(0.,(NP2-1.)/SW2,NP2)\n",
        "  \n",
        "  K = np.max([len(freqs), len(freqs2), len(freqs2), len(r2s), len(ints)])\n",
        "  for n in range(NP):\n",
        "    for n1 in range(NP1):\n",
        "      for n2 in range(NP2):\n",
        "        val = 0.\n",
        "        for s in range(K):\n",
        "          val+= (np.exp((1j*2*np.pi*freqs[s] - r2s[s])*samp_time[n])*\n",
        "                  np.exp((1j*2*np.pi*freqs1[s] - r2s[s])*samp_time1[n1])*\n",
        "                  np.exp((1j*2*np.pi*freqs2[s] - r2s[s])*samp_time2[n2])*\n",
        "                  ints[s])\n",
        "        retval[n,n1,n2]=val\n",
        "\n",
        "  return retval\n",
        "\n",
        "\n",
        "def make_sine_combinations():\n",
        "\n",
        "  # Number of Signals\n",
        "  nSignals = 80 #random.randint(200,NSignals+1)  \n",
        "  # print(nSignals)\n",
        "\n",
        "  # Frequencies\n",
        "  freqs = np.random.random(nSignals)*SW\n",
        "  freqs1 = np.random.random(nSignals)*SW1\n",
        "  freqs2 = np.random.random(nSignals)*SW2\n",
        "\n",
        "  # Transverse relaxation rate\n",
        "  r2s = np.random.random(nSignals)*(5) + (1/100)\n",
        "\n",
        "  #Intensity = amplitude\n",
        "  ints = np.random.random(nSignals)*600000 + 100000\n",
        "\n",
        "  # FID creation\n",
        "  ff = make_fid(freqs,freqs1,freqs2,r2s,ints,NoiseLevel)\n",
        "\n",
        "  temp_realPart = np.real(ff)\n",
        "  temp = np.abs(temp_realPart[0,0,0])\n",
        "  ff = ff/temp\n",
        "\n",
        "  return ff, nSignals\n",
        "\n",
        "\n",
        "def make_2d_mat(b_size):\n",
        "    \n",
        "  # Training matrix\n",
        "  target = np.zeros([b_size*NP, NP1*NP2], dtype=np.float)       # For Target\n",
        "  train = np.zeros([b_size*NP, NP1, NP2], dtype=np.float)      # For CNN\n",
        "  train1 = np.zeros([b_size*NP, NP1, NP2], dtype=np.float)     # For test_fft\n",
        "  train_1 = np.zeros([b_size*NP, NP1*NP2], dtype=np.float)      # For DNN\n",
        "\n",
        "  # Matix concatenation (training)\n",
        "  for i in range(b_size):\n",
        "    ff, nSignals = make_sine_combinations()\n",
        "    train_ff = ff\n",
        "\n",
        "    ff = np.fft.fft(ff,axis=0)\n",
        "    ff = np.fft.fft(ff,axis=1)\n",
        "    ff = np.fft.fft(ff,axis=2)\n",
        "\n",
        "    ff = ff/np.max(np.abs(ff))\n",
        "\n",
        "    train1[i*NP:(i+1)*NP,:,:] = np.real(ff)\n",
        "    # train1[i*NP:(i+1)*NP,1,:,:] = np.imag(ff)\n",
        "\n",
        "    for j in range(NP):\n",
        "      train_ff[j,:,:] = np.multiply(train_ff[j,:,:],mul_arr)\n",
        "      # index = (i*(j+1))+j\n",
        "      index = (i*NP)+j\n",
        "      # till_index = NP1*NP2\n",
        "      target[index,:] = np.real(ff[j]).reshape(NP1*NP2)\n",
        "      # target[index,till_index:2*till_index] = np.imag(ff[j]).reshape(NP1*NP2)\n",
        "    \n",
        "    train_ff = np.fft.fft(train_ff,axis=0)\n",
        "    train_ff = np.fft.fft(train_ff,axis=1)\n",
        "    train_ff = np.fft.fft(train_ff,axis=2)\n",
        "\n",
        "    train_ff = train_ff/np.max(np.abs(train_ff))\n",
        "\n",
        "    train[i*NP:(i+1)*NP,:,:] = np.real(train_ff)\n",
        "    # train[i*NP:(i+1)*NP,1,:,:] = np.imag(train_ff)\n",
        "    \n",
        "    for j in range(NP):\n",
        "      index = (i*NP)+j\n",
        "      # till_index = NP1*NP2\n",
        "      train_1[index,:] = np.real(train_ff[j]).reshape(NP1*NP2)\n",
        "      # train_1[index,till_index:2*till_index] = np.imag(train_ff[j]).reshape(NP1*NP2)\n",
        "\n",
        "  return train, train1, target, nSignals\n",
        "\n",
        "N = 5000\n",
        "NP = 2        # Direct dimension\n",
        "NP1 = 120     # Indirect Dimension 1\n",
        "NP2 = 32      # Indirect Dimension 1\n",
        "SW = 1000\n",
        "SW1 = 10000\n",
        "SW2 = 4000\n",
        "NoiseLevel = 0\n",
        "NSignals = 250\n",
        "dataIn = []\n",
        "dataOut = []\n",
        "epochs = 12\n",
        "batch_size = 32\n",
        "val_split = 0.05\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ph-qDh5LisMj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5encqgEcDfGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvvNwm3f8jbS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f62c72a0-4c30-4662-fa97-9f85d19e1a57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras = 2.8.0\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import keras\n",
        "from keras import backend as K\n",
        "print(\"Keras = {}\".format(keras.__version__))\n",
        "import tensorflow as tf\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
        "import numpy as np\n",
        "import pylab\n",
        "import sys\n",
        "import math\n",
        "from tensorflow.python.keras.backend import set_session \n",
        "# import keras.backend.tensorflow_backend as KTF\n",
        "from keras.models import load_model\n",
        "from sklearn import metrics\n",
        "#from model_logic2 import *\n",
        "#from generator2 import *\n",
        "import scipy.io as sio\n",
        "# from keras.utils import plot_model\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
        "\n",
        "# config = tf.ConfigProto(allow_soft_placement=True)\n",
        "# config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
        "#config.gpu_options.allow_growth = True\n",
        "# session = tf.Session(config = config)\n",
        "# KTF.set_session(session)\n",
        "\n",
        "# sys.setrecursionlimit(2000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B830iZxSuoFh"
      },
      "outputs": [],
      "source": [
        "train, target, target_1d, nSignals = make_2d_mat(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ip = np.zeros([80,128,120])\n",
        "target_2d = np.zeros([80,128,120])"
      ],
      "metadata": {
        "id": "IG593-KIP-sY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hSxf_Elg1aiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_ip[:,:120,:32] = train\n",
        "# target_2d[:,:120,:32] = target\n",
        "train_ip[:,:120,:32] = tar_2\n",
        "target_2d[:,:120,:32] = fid_2"
      ],
      "metadata": {
        "id": "2zrrV8sjQKDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(train_ip[:,:120,:], target_2d[:,:120,:])\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
        "\n",
        "\n",
        "output = model.predict(train_ip[:,:120,:])"
      ],
      "metadata": {
        "id": "RyETZWuxQKGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkSWHfBBKYSI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fk8gcyaCl2Bt"
      },
      "outputs": [],
      "source": [
        "loss, acc = new_model.evaluate(train_ip[:,:,:32], target_2d[:,:,:32])\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
        "\n",
        "\n",
        "output1 = new_model.predict(train_ip[:,:,:32])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuSCyYl4gRT2"
      },
      "outputs": [],
      "source": [
        "train_ip.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVS-oVEygT0e"
      },
      "outputs": [],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWHdUUcYgYXQ"
      },
      "outputs": [],
      "source": [
        "target_2d.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3eljk-GnKvi"
      },
      "outputs": [],
      "source": [
        "# z1 = azur[:,:,:,0]\n",
        "# z = luo[:,:,:,0]\n",
        "z = np.real(train_ip[:, :, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZxq6fFel2EK"
      },
      "outputs": [],
      "source": [
        "# X = np.arange(128,dtype=int)\n",
        "# Y = np.arange(32,dtype=int)\n",
        "X = np.arange(120,dtype=int)\n",
        "Y = np.arange(120,dtype=int)\n",
        "X,Y = np.meshgrid(X,Y)\n",
        "print(X)\n",
        "print(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5pEmCv5nAXX"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# fig = go.Figure(figsize=(24,12))\n",
        "\n",
        "fig = go.Figure(data=[go.Surface(z=z[38,:,:])])\n",
        "fig.update_traces(contours_z=dict(show=True, usecolormap=True,\n",
        "                                  highlightcolor=\"lightyellow\", project_z=True))\n",
        "fig.update_layout(title='Mt Bruno Elevation', autosize=False,\n",
        "                  scene_camera_eye=dict(x=1.87, y=0.88, z=-0.64),\n",
        "                  width=800, height=800,\n",
        "                  margin=dict(l=65, r=50, b=65, t=90)\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arXeGxqGl2Gs"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rddVS_MMn7kE"
      },
      "outputs": [],
      "source": [
        "z_op = np.real(output[:, :, :, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GV6bG73oWmD"
      },
      "outputs": [],
      "source": [
        "z_op.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYtxET4csZHw"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsqUDwLPn7qk"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# fig = go.Figure(figsize=(24,12))\n",
        "\n",
        "fig = go.Figure(data=[go.Surface(z=z_op[20,:,:])])\n",
        "fig.update_traces(contours_z=dict(show=True, usecolormap=True,\n",
        "                                  highlightcolor=\"limegreen\", project_z=True))\n",
        "fig.update_layout(title='Mt Bruno Elevation', autosize=False,\n",
        "                  scene_camera_eye=dict(x=1.87, y=0.88, z=-0.64),\n",
        "                  width=800, height=800,\n",
        "                  margin=dict(l=65, r=50, b=65, t=90)\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z_op1 = np.real(output1[:, :, :, 0])"
      ],
      "metadata": {
        "id": "FeiNufBbXmdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z_op2 = np.zeros([80,128,120])\n",
        "z_op2[:,:,:32] = z_op1[:,:,:]\n",
        "z_op2.shape"
      ],
      "metadata": {
        "id": "r78QCBeFXmaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# fig = go.Figure(figsize=(24,12))\n",
        "\n",
        "fig = go.Figure(data=[go.Surface(z=z_op2[20,:,:])])\n",
        "fig.update_traces(contours_z=dict(show=True, usecolormap=True,\n",
        "                                  highlightcolor=\"limegreen\", project_z=True))\n",
        "fig.update_layout(title='Mt Bruno Elevation', autosize=False,\n",
        "                  scene_camera_eye=dict(x=1.87, y=0.88, z=-0.64),\n",
        "                  width=800, height=800,\n",
        "                  margin=dict(l=65, r=50, b=65, t=90)\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "VLfeMEKwXmXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AVXBGfK0XmRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRY-y9-7n7tS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jI2YW-gEhGGe"
      },
      "outputs": [],
      "source": [
        "z_act = np.real(target_2d[:, :, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW42rwfphGJt",
        "outputId": "64bc93e6-35ba-4574-ad79-75f0087a8e83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 128, 120)"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ],
      "source": [
        "z_act.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbUwsBD_hGL-"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# fig = go.Figure(figsize=(24,12))\n",
        "\n",
        "fig = go.Figure(data=[go.Surface(z=z_act[0,:,:])])\n",
        "fig.update_traces(contours_z=dict(show=True, usecolormap=True,\n",
        "                                  highlightcolor=\"limegreen\", project_z=True))\n",
        "fig.update_layout(title='Mt Bruno Elevation', autosize=False,\n",
        "                  scene_camera_eye=dict(x=1.87, y=0.88, z=-0.64),\n",
        "                  width=800, height=800,\n",
        "                  margin=dict(l=65, r=50, b=65, t=90)\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKwMveP0hGOT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wml3Sd1zhmLd"
      },
      "outputs": [],
      "source": [
        "x = np.linspace(-1,1,100)\n",
        "y=x\n",
        "plt.scatter(z_op2, z_act[:,:128,:])\n",
        "plt.plot(x, y, '-r', label='y=x')\n",
        "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "plt.xlabel('Actual signal peaks height')\n",
        "plt.ylabel('Output signal peaks height')\n",
        "plt.title(label='Pearson Correalation',\n",
        "          fontweight=40,\n",
        "          fontsize = 40)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KH5esSbfhmOV"
      },
      "outputs": [],
      "source": [
        "nSignals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SJCETEPyzKN"
      },
      "outputs": [],
      "source": [
        "points = []\n",
        "temp_2d = np.zeros([130,122], dtype=np.float)\n",
        "for i in range(2):\n",
        "  temp_2d[1:129, 1:121] = z_act[i,:,:]\n",
        "  for j in range(1,129):\n",
        "    for k in range(1,33):\n",
        "      if (temp_2d[j,k]>temp_2d[j-1,k-1]) and (temp_2d[j,k]>temp_2d[j-1,k])and (temp_2d[j,k]>temp_2d[j-1,k+1]) and (temp_2d[j,k]>temp_2d[j,k-1]) and (temp_2d[j,k]>temp_2d[j,k+1]) and (temp_2d[j,k]>temp_2d[j+1,k-1]) and (temp_2d[j,k]>temp_2d[j+1,k]) and (temp_2d[j,k]>temp_2d[j+1,k+1]):\n",
        "        points.append([i,j-1,k-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdI2lvT92SjL",
        "outputId": "b2f2e075-a2de-48df-e752-fa95efd8822b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.02809409, 0.01565592, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.00844708, 0.00207817, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ],
      "source": [
        "temp_2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJg3yLR7Cqea"
      },
      "outputs": [],
      "source": [
        "len(points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yk1-MuqV1Fg2"
      },
      "outputs": [],
      "source": [
        "z_op_1 = z_op2\n",
        "z_act_1 = z_act \n",
        "\n",
        "origin = [0,0,0]\n",
        "\n",
        "xyz = []\n",
        "xyz.append(origin)\n",
        "print(len(points))\n",
        "\n",
        "\n",
        "\n",
        "for xy in points:\n",
        "  flag = 0\n",
        "  for i in range(len(xyz)):\n",
        "    # print('hi')\n",
        "    if (z_act[xy[0],xy[1],xy[2]] > z_act[xyz[i][0],xyz[i][1],xyz[i][2]]) or (z_act[xy[0],xy[1],xy[2]] == z_act[xyz[i][0],xyz[i][1],xyz[i][2]]):\n",
        "      xyz.insert(i,xy)\n",
        "      flag = 1\n",
        "      break\n",
        "  if flag==0:\n",
        "    xyz.append(xy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSNu-YOOYEiB"
      },
      "outputs": [],
      "source": [
        "len(xyz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNI-4ueOeAN_"
      },
      "outputs": [],
      "source": [
        "# xyz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdYVyyWseIj-"
      },
      "outputs": [],
      "source": [
        "print(z_act[1, 92, 11], z_act[0, 10, 23])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SvrO3DghmQz"
      },
      "outputs": [],
      "source": [
        "for i in range(80):\n",
        "  for j in range(128):\n",
        "    for k in range(32):\n",
        "      # if (z_act[i,j,k]<0.1):\n",
        "      if [i,j,k] not in xyz:\n",
        "        z_op2[i,j,k] = 0\n",
        "        z_act[i,j,k] = 0\n",
        "# for i in range(79):\n",
        "#   for j in range(128):\n",
        "#     for k in range(32):\n",
        "#       if z_act[i,j,k] < 0:\n",
        "#         z_act[i,j,k] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1Af8b3ohmTP"
      },
      "outputs": [],
      "source": [
        "x = np.linspace(0,1,100)\n",
        "y=x\n",
        "plt.scatter(z_op2, z_act[:,:128:,:])\n",
        "plt.plot(x, y, '-r', label='y=x')\n",
        "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "plt.xlabel('output signal peaks height')\n",
        "plt.ylabel('Actual signal peaks height')\n",
        "plt.title(label='Pearson Correalation',\n",
        "          fontweight=40,\n",
        "          fontsize = 40)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwNd_mT4l2JQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYWG1bdGYNu5",
        "outputId": "fbb09484-5272-4c11-ea99-f8a9c01495e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficient of Determination 0.8889300965569372\n",
            "Pearsons correlation: 0.945\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "from sklearn.metrics import r2_score \n",
        "# a =[1, 2, 3, 4, 5] \n",
        "# b =[1, 2.5, 3, 4.9, 5.1] \n",
        "R_square = r2_score(list(z_act.reshape(8192,)),list(z_op.reshape(8192,))) \n",
        "print('Coefficient of Determination', R_square) \n",
        "\n",
        "corr, _ = pearsonr(list(z_act.reshape(8192,)),list(z_op.reshape(8192,)))\n",
        "print('Pearsons correlation: %.3f' % corr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9w1K47dYNy1"
      },
      "outputs": [],
      "source": [
        "# stat = []\n",
        "# r_sq = []\n",
        "# for k in range(100):\n",
        "#   train_ip, target_2d, target_1d, nSignals = make_2d_mat(1)\n",
        "#   loss, acc = new_model.evaluate(train_ip, target_2d)\n",
        "#   # print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
        "\n",
        "#   output = new_model.predict(train_ip)\n",
        "#   z_op = np.real(output[:, :, :, 0])\n",
        "#   z_act = np.real(target_2d[:, :, :])\n",
        "#   points = []\n",
        "#   temp_2d = np.zeros([130,34], dtype=np.float)\n",
        "#   for i in range(2):\n",
        "#     temp_2d[1:129, 1:33] = z_act[i,:,:]\n",
        "#     for j in range(1,129):\n",
        "#       for k in range(1,33):\n",
        "#         if (temp_2d[j,k]>temp_2d[j-1,k-1]) and (temp_2d[j,k]>temp_2d[j-1,k])and (temp_2d[j,k]>temp_2d[j-1,k+1]) and (temp_2d[j,k]>temp_2d[j,k-1]) and (temp_2d[j,k]>temp_2d[j,k+1]) and (temp_2d[j,k]>temp_2d[j+1,k-1]) and (temp_2d[j,k]>temp_2d[j+1,k]) and (temp_2d[j,k]>temp_2d[j+1,k+1]):\n",
        "#           points.append([i,j-1,k-1])\n",
        "\n",
        "#   origin = [0,0,0]\n",
        "\n",
        "#   xyz = []\n",
        "#   xyz.append(origin)\n",
        "#   print(len(points))\n",
        "\n",
        "\n",
        "\n",
        "#   for xy in points:\n",
        "#     flag = 0\n",
        "#     for i in range(len(xyz)):\n",
        "#       # print('hi')\n",
        "#       if (z_act[xy[0],xy[1],xy[2]] > z_act[xyz[i][0],xyz[i][1],xyz[i][2]]) or (z_act[xy[0],xy[1],xy[2]] == z_act[xyz[i][0],xyz[i][1],xyz[i][2]]):\n",
        "#         xyz.insert(i,xy)\n",
        "#         flag = 1\n",
        "#         break\n",
        "#     if flag==0:\n",
        "#       xyz.append(xy)\n",
        "\n",
        "#   for i in range(2):\n",
        "#     for j in range(128):\n",
        "#       for k in range(32):\n",
        "#         # if (z_act[i,j,k]<0.1):\n",
        "#         if [i,j,k] not in xyz[:nSignals]:\n",
        "#           z_op[i,j,k] = 0\n",
        "#           z_act[i,j,k] = 0\n",
        "\n",
        "#   R_square = r2_score(list(z_act.reshape(8192,)),list(z_op.reshape(8192,))) \n",
        "#   # print('Coefficient of Determination', R_square) \n",
        "#   corr, _ = pearsonr(list(z_act.reshape(8192,)),list(z_op.reshape(8192,)))\n",
        "#   stat.append(corr)\n",
        "#   r_sq.append(R_square)\n",
        "\n",
        "# print(np.mean(stat))\n",
        "# print(np.mean(r_sq))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgaFsYXzYN1v"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_sCse08YN4X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7666b1d-fa65-43f3-eacf-be3f3db35ba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.getcwd()\n",
        "\n",
        "os.chdir('drive')\n",
        "\n",
        "os.chdir('MyDrive')"
      ],
      "metadata": {
        "id": "E7cU33JDHvAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "oSI5EQISHy_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nmrglue"
      ],
      "metadata": {
        "id": "4-v8TN4RH6S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nmrglue as ng"
      ],
      "metadata": {
        "id": "TZ-Pyfq3eER9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic,data = ng.pipe.read('3Dexpts/cbcaconh_3d/data/test001.fid')"
      ],
      "metadata": {
        "id": "AgaSJhLcdjS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "4l-BjgMyd0VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "MYMFtwovd2cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "files = []\n",
        "\n",
        "entries = Path('3Dexpts/cbcaconh_3d/data/')\n",
        "for entry in entries.iterdir():\n",
        "    # print(entry.name)\n",
        "    files.append(entry.name)"
      ],
      "metadata": {
        "id": "3TlhDC0KIuGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.sort()\n",
        "# files"
      ],
      "metadata": {
        "id": "zOGPwCkCegmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files[:]"
      ],
      "metadata": {
        "id": "elqn1TeEfv5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_kVsDEuYN6G"
      },
      "outputs": [],
      "source": [
        "fid_signal = np.zeros([80,576,120], dtype=complex)\n",
        "i=0\n",
        "for x in files[:-1]:\n",
        "  folder = \"3Dexpts/cbcaconh_3d/data/\"\n",
        "  x = folder + x\n",
        "  dic,data = ng.pipe.read(x)\n",
        "  fid_signal[i,:,:] = data.T\n",
        "  i=i+1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fid_signal"
      ],
      "metadata": {
        "id": "TPDCMbILxDun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fid_signal.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43V-sfuRg-P_",
        "outputId": "ff2884d7-fadd-4992-a347-7fcd6d909292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 576, 120)"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyXfpGwSYN9R"
      },
      "outputs": [],
      "source": [
        "fid_1 = fid_signal[:,:120,:32]\n",
        "\n",
        "fid_1 = np.fft.fft(fid_1,axis=0)\n",
        "fid_1 = np.fft.fft(fid_1,axis=1)\n",
        "fid_1 = np.fft.fft(fid_1,axis=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fid_2 = np.real(fid_1)\n",
        "print(fid_2.shape)\n",
        "fid_2 = fid_2/np.max(np.abs(fid_2))\n",
        "\n",
        "# train1[i*NP:(i+1)*NP,:,:] = np.real(fid_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIukcycw0cNx",
        "outputId": "59a41d83-7cba-4c73-c591-a925823b66b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80, 120, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvYv7la4Yb0X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe845339-05c3-4fd9-d74d-31cb360fe880"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 120, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "tar_1 = np.multiply(fid_signal[:,:120,:32],mul_arr)\n",
        "tar_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tar_1 = np.fft.fft(tar_1,axis=0)\n",
        "tar_1 = np.fft.fft(tar_1,axis=1)\n",
        "tar_1 = np.fft.fft(tar_1,axis=2)"
      ],
      "metadata": {
        "id": "WufEntTpQxmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tar_2 = np.real(tar_1)\n",
        "print(tar_2.shape)\n",
        "tar_2 = tar_2/np.max(np.abs(tar_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTfdXCjT04gw",
        "outputId": "235ef8ea-46f6-4edc-d84c-71707b3c4792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80, 120, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aqsiyO1l04jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GpBU0_2a04mT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TzX5M6GU04ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XJ5ASt6X04rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QOTPUjG304tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GsrxfZSA04vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HRlPBKQi04xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZNlbf3ym04zt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DenseNet_3D_NUS_NMR.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPqFyry219OgI8g7RObVeDX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}